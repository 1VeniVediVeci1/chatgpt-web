import * as dotenv from 'dotenv'
import OpenAI from 'openai'
import jwt_decode from 'jwt-decode'
import { GoogleGenAI } from '@google/genai'
import type { AuditConfig, KeyConfig, UserInfo } from '../storage/model'
import { Status } from '../storage/model'
import { convertImageUrl } from '../utils/image'
import type { TextAuditService } from '../utils/textAudit'
import { textAuditServices } from '../utils/textAudit'
import { getCacheApiKeys, getCacheConfig, getOriginConfig } from '../storage/config'
import { sendResponse } from '../utils'
import { hasAnyRole, isNotEmptyString } from '../utils/is'
import type { JWT, ModelConfig } from '../types'
import { getChatByMessageId, updateRoomChatModel } from '../storage/mongo'
import type { ChatMessage, ChatResponse, MessageContent, RequestOptions } from './types'
import * as fs from 'node:fs/promises'
import * as path from 'node:path'
import { generateMessageId } from '../utils/id-generator'
import { abortablePromise, isAbortError } from './abortable'
import { webSearch } from '../utils/webSearch'

type GeminiPart = {
  text?: string
  inlineData?: {
    mimeType: string
    data: string
  }
}

const MODEL_CONFIGS: Record<string, { supportTopP: boolean; defaultTemperature?: number }> = {
  'gpt-5-search-api': { supportTopP: false, defaultTemperature: 0.8 },
}

const UPLOAD_DIR = path.resolve(process.cwd(), 'uploads')

async function ensureUploadDir() {
  try {
    await fs.access(UPLOAD_DIR)
  }
  catch {
    await fs.mkdir(UPLOAD_DIR, { recursive: true })
  }
}

function stripTypePrefix(key: string): string {
  return key.replace(/^(img:|txt:)/, '')
}

function isTextFile(filename: string): boolean {
  if (filename.startsWith('txt:')) return true
  if (filename.startsWith('img:')) return false
  const realName = stripTypePrefix(filename)
  const ext = path.extname(realName).toLowerCase()
  const textExtensions = ['.txt', '.md', '.json', '.csv', '.js', '.ts', '.py', '.java', '.html', '.css', '.xml', '.yml', '.yaml', '.log', '.ini', '.config']
  return textExtensions.includes(ext)
}

function isImageFile(filename: string): boolean {
  if (filename.startsWith('img:')) return true
  if (filename.startsWith('txt:')) return false
  const realName = stripTypePrefix(filename)
  const ext = path.extname(realName).toLowerCase()
  const imageExtensions = ['.png', '.jpg', '.jpeg', '.webp', '.gif', '.heic', '.bmp']
  return imageExtensions.includes(ext)
}

async function getFileBase64(filename: string): Promise<{ mime: string; data: string } | null> {
  try {
    const realFilename = stripTypePrefix(filename)
    const filePath = path.join(UPLOAD_DIR, realFilename)
    await fs.access(filePath)
    const buffer = await fs.readFile(filePath)
    const ext = path.extname(realFilename).toLowerCase().replace('.', '')
    let mime = 'image/png'
    if (ext === 'jpg' || ext === 'jpeg') mime = 'image/jpeg'
    else if (ext === 'webp') mime = 'image/webp'
    else if (ext === 'gif') mime = 'image/gif'
    else if (ext === 'heic') mime = 'image/heic'
    else if (ext === 'bmp') mime = 'image/bmp'
    return { mime, data: buffer.toString('base64') }
  }
  catch (e) {
    console.error(`[File Read Error] ${filename}:`, e)
    return null
  }
}

dotenv.config()

const API_DEBUG = process.env.API_DEBUG === 'true'
const API_DEBUG_MAX_TEXT = Number(process.env.API_DEBUG_MAX_TEXT ?? 800)

function trunc(s: any, n = API_DEBUG_MAX_TEXT): string {
  const str = typeof s === 'string' ? s : JSON.stringify(s ?? '')
  if (!str) return ''
  return str.length > n ? `${str.slice(0, n)}...(truncated,total=${str.length})` : str
}

function safeJson(obj: any): string {
  try { return JSON.stringify(obj, null, 2) }
  catch (e: any) { return `[Unserializable: ${e?.message ?? e}]` }
}

function summarizeGeminiParts(parts: any[]) {
  return (parts ?? []).map((p, idx) => ({
    idx,
    hasText: typeof p?.text === 'string',
    textLen: typeof p?.text === 'string' ? p.text.length : 0,
    textPreview: typeof p?.text === 'string' ? trunc(p.text) : undefined,
    hasInlineData: !!p?.inlineData,
    inlineMime: p?.inlineData?.mimeType,
    inlineB64Len: typeof p?.inlineData?.data === 'string' ? p.inlineData.data.length : 0,
  }))
}

function summarizeGeminiContents(contents: any[]) {
  return (contents ?? []).map((c, idx) => ({
    idx, role: c?.role, parts: summarizeGeminiParts(c?.parts),
  }))
}

function summarizeOpenAIMessages(messages: any[]) {
  return (messages ?? []).map((m, idx) => {
    const content = m?.content
    let contentType: string = typeof content
    let contentLen = 0
    let contentPreview: string | undefined
    if (typeof content === 'string') { contentLen = content.length; contentPreview = trunc(content) }
    else if (Array.isArray(content)) {
      contentType = 'array'; contentLen = content.length
      contentPreview = trunc(content.map((p: any) => ({
        type: p?.type, textLen: typeof p?.text === 'string' ? p.text.length : undefined,
        hasImageUrl: !!p?.image_url?.url,
        imageUrlType: typeof p?.image_url?.url === 'string'
          ? (p.image_url.url.startsWith('data:') ? 'dataUrl' : (p.image_url.url.startsWith('http') ? 'http' : 'other'))
          : undefined,
      })))
    }
    else if (content === null) { contentType = 'null'; contentLen = 0; contentPreview = 'null' }
    else { contentType = 'object'; contentPreview = trunc(content) }
    return { idx, role: m?.role, contentType, contentLen, contentPreview }
  })
}

function debugLog(...args: any[]) {
  if (!API_DEBUG) return
  console.log(...args)
}

// ===================== ËÅîÁΩëÊêúÁ¥¢ =====================
type SearchPlan = {
  action: 'search' | 'stop'
  query?: string
  reason?: string
}

type SearchRound = {
  query: string
  items: Array<{ title: string; url: string; content: string }>
  note?: string
}

function safeParseJsonFromText(text: string): any | null {
  if (!text) return null
  const s = String(text).trim()
  try { return JSON.parse(s) } catch { }
  const i = s.indexOf('{')
  const j = s.lastIndexOf('}')
  if (i >= 0 && j > i) {
    try { return JSON.parse(s.slice(i, j + 1)) } catch { }
  }
  return null
}

function formatSearchRoundsForPlanner(rounds: SearchRound[]): string {
  if (!rounds.length) return 'ÔºàÊó†Ôºâ'
  return rounds.map((r, idx) => {
    const top = (r.items || []).slice(0, 5).map((it, i) => {
      const n = `${idx + 1}.${i + 1}`
      return `- [${n}] ${String(it.title || '').trim()}\n  ${String(it.url || '').trim()}\n  ${String(it.content || '').replace(/\s+/g, ' ').trim()}`
    }).join('\n')
    const note = r.note ? `\nÔºàÊ≥®Ôºö${r.note}Ôºâ` : ''
    return `Á¨¨${idx + 1}ËΩÆ query="${r.query}"\n${top || 'ÔºàÊó†ÁªìÊûúÔºâ'}${note}`
  }).join('\n\n')
}

async function planNextSearchAction(params: {
  openai: OpenAI
  model: string
  userQuestion: string
  rounds: SearchRound[]
  abortSignal?: AbortSignal
}): Promise<SearchPlan> {
  const { openai, model, userQuestion, rounds, abortSignal } = params

  const plannerSystem = [
    '‰Ω†ÊòØ"ËÅîÁΩëÊêúÁ¥¢ËßÑÂàíÂô®"„ÄÇ‰Ω†ÁöÑ‰ªªÂä°ÊòØÂ∏ÆÂä©ÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢òÔºå‰ΩÜÂè™Âú®ÂøÖË¶ÅÊó∂ÊâçËÅîÁΩëÊêúÁ¥¢„ÄÇ',
    '', '‰Ω†‰ºöÁúãÂà∞ÔºöÁî®Êà∑ÈóÆÈ¢ò + Â∑≤ËøõË°åÁöÑÊêúÁ¥¢ËΩÆÊ¨°‰∏éÁªìÊûúÊëòË¶Å„ÄÇ',
    '‰Ω†ÈúÄË¶ÅËæìÂá∫‰∏•Ê†º JSONÔºà‰∏çË¶ÅËæìÂá∫Â§ö‰ΩôÊñáÂ≠óÔºâ„ÄÇ',
    '', 'JSON schemaÔºö',
    '{ "action": "search" | "stop", "query": string, "reason": string }',
    '', 'ËßÑÂàôÔºö',
    '- Â¶ÇÊûúÂ∑≤Êúâ‰ø°ÊÅØË∂≥Â§üÊîØÊíëÂõûÁ≠îÔºöaction="stop"',
    '- Â¶ÇÊûúÈúÄË¶ÅÁªßÁª≠ÊêúÁ¥¢Ôºöaction="search"ÔºåÁªôÂá∫Êõ¥Â•ΩÁöÑ queryÔºàÊõ¥ÂÖ∑‰Ωì„ÄÅÂåÖÂê´ÂÖ≥ÈîÆÂÆû‰Ωì/Êó∂Èó¥/ÈôêÂÆöËØçÔºâ',
    '- query ‰∏çË¶ÅÂ§™ÈïøÔºàÂª∫ËÆÆ 6~16 ‰∏™ËØç/‰∏≠Ëã±ÊñáÂùáÂèØÔºâ',
    '- Â¶ÇÊûú‰∏ä‰∏ÄËΩÆÁªìÊûúÊó†ÂÖ≥ÔºåËØ∑ÊòæÂºèÊç¢‰∏Ä‰∏™ËßíÂ∫¶ÊàñÂä†ÂÖ•Êõ¥Âº∫ÈôêÂÆöËØç',
    '- ÂåπÈÖçÁî®Êà∑ËØ≠Ë®ÄËæìÂá∫Ôºàquery ÂèØ‰∏≠Ëã±Ê∑∑ÂêàÔºâ',
  ].join('\n')

  const plannerUser = [
    `Áî®Êà∑ÈóÆÈ¢òÔºö${userQuestion}`, '',
    'Â∑≤ËøõË°åÁöÑÊêúÁ¥¢‰∏éÁªìÊûúÊëòË¶ÅÔºö',
    formatSearchRoundsForPlanner(rounds), '',
    'Áé∞Âú®ËØ∑ÂÜ≥ÂÆöÔºöÊòØÂê¶ÈúÄË¶ÅÁªßÁª≠ÊêúÁ¥¢ÔºüÂ¶ÇÊûúÈúÄË¶ÅÔºåËØ∑ÁªôÂá∫Êñ∞ÁöÑ query„ÄÇ',
  ].join('\n')

  try {
    const resp = await openai.chat.completions.create({
      model, temperature: 0,
      messages: [
        { role: 'system', content: plannerSystem },
        { role: 'user', content: plannerUser },
      ],
      response_format: { type: 'json_object' } as any,
      stream: false,
    } as any, { signal: abortSignal })
    const text = resp.choices?.[0]?.message?.content ?? ''
    const obj = safeParseJsonFromText(text)
    if (!obj) return { action: 'stop', reason: 'planner json parse failed' }
    return obj as SearchPlan
  }
  catch {
    const resp = await openai.chat.completions.create({
      model, temperature: 0,
      messages: [
        { role: 'system', content: plannerSystem },
        { role: 'user', content: `${plannerUser}\n\nÂè™ËæìÂá∫ JSONÔºå‰∏çË¶ÅËæìÂá∫ÂÖ∂ÂÆÉÊñáÊú¨„ÄÇ` },
      ],
      stream: false,
    } as any, { signal: abortSignal })
    const text = resp.choices?.[0]?.message?.content ?? ''
    const obj = safeParseJsonFromText(text)
    if (!obj) return { action: 'stop', reason: 'planner json parse failed' }
    return obj as SearchPlan
  }
}

async function runIterativeWebSearch(params: {
  openai: OpenAI
  plannerModels: string[]
  userQuestion: string
  maxRounds: number
  maxResults: number
  abortSignal?: AbortSignal
  provider?: 'searxng' | 'tavily'
  searxngApiUrl?: string
  tavilyApiKey?: string
  onProgress?: (status: string) => void
}): Promise<SearchRound[]> {
  const {
    openai, plannerModels, userQuestion, maxRounds, maxResults,
    abortSignal, provider, searxngApiUrl, tavilyApiKey, onProgress,
  } = params

  const rounds: SearchRound[] = []
  const usedQueries = new Set<string>()

  for (let i = 0; i < maxRounds; i++) {
    onProgress?.(`üîç ÊêúÁ¥¢ËßÑÂàí‰∏≠ÔºàÁ¨¨ ${i + 1}/${maxRounds} ËΩÆÔºâ...`)

    let plan: SearchPlan | null = null
    for (const m of plannerModels) {
      try {
        plan = await planNextSearchAction({ openai, model: m, userQuestion, rounds, abortSignal })
        break
      }
      catch (e) {
        if (API_DEBUG) debugLog('[SearchPlanner] model failed:', m, (e as any)?.message ?? e)
      }
    }

    if (!plan) { onProgress?.('‚úÖ ÊêúÁ¥¢ËßÑÂàíÂÆåÊàêÔºàÊó†ÈúÄÊêúÁ¥¢Ôºâ'); break }
    if (plan.action !== 'search') { onProgress?.(`‚úÖ ÊêúÁ¥¢ÂÆåÊàêÔºö${plan.reason || '‰ø°ÊÅØÂ∑≤Ë∂≥Â§ü'}`); break }

    const q = String(plan.query || '').trim()
    if (!q) break
    if (usedQueries.has(q)) { onProgress?.('‚ö†Ô∏è ÂÖ≥ÈîÆËØçÈáçÂ§çÔºåÂÅúÊ≠¢ÊêúÁ¥¢'); break }
    usedQueries.add(q)

    onProgress?.(`üåê Ê≠£Âú®ÊêúÁ¥¢Ôºö„Äå${q}„Äç...`)

    try {
      const r = await webSearch(q, { maxResults, signal: abortSignal, provider, searxngApiUrl, tavilyApiKey })
      const items = (r.results || []).slice(0, maxResults).map(it => ({
        title: String(it.title || ''), url: String(it.url || ''), content: String(it.content || ''),
      }))
      rounds.push({ query: q, items })
      onProgress?.(`üìÑ Á¨¨ ${i + 1} ËΩÆÊêúÁ¥¢ÂÆåÊàêÔºåËé∑Âæó ${items.length} Êù°ÁªìÊûú`)
    }
    catch (e: any) {
      rounds.push({ query: q, items: [], note: e?.message ?? String(e) })
      onProgress?.(`‚ùå ÊêúÁ¥¢Â§±Ë¥•Ôºö${e?.message ?? String(e)}`)
      break
    }
  }

  if (!rounds.length) onProgress?.('‚ÑπÔ∏è Ê®°ÂûãÂà§Êñ≠Êó†ÈúÄËÅîÁΩëÊêúÁ¥¢ÔºåÁõ¥Êé•ÂõûÁ≠î')
  else onProgress?.(`‚úÖ ÊêúÁ¥¢ÂÖ®ÈÉ®ÂÆåÊàêÔºàÂÖ± ${rounds.length} ËΩÆÔºâÔºåÊ≠£Âú®ÁîüÊàêÂõûÁ≠î...`)

  return rounds
}

function formatAggregatedSearchForAnswer(rounds: SearchRound[]): string {
  if (!rounds.length) return ''

  let n = 0
  const lines: string[] = []
  const refLines: string[] = []

  lines.push('„ÄêËÅîÁΩëÊêúÁ¥¢ÁªìÊûú„Äë')

  rounds.forEach((r, idx) => {
    lines.push(`ÔºàÁ¨¨${idx + 1}ËΩÆÂÖ≥ÈîÆËØçÔºö${r.query}Ôºâ`)
    if (!r.items?.length) {
      lines.push('ÔºàÊó†ÁªìÊûúÔºâ')
      if (r.note) lines.push(`ÔºàÊ≥®Ôºö${r.note}Ôºâ`)
      lines.push('')
      return
    }
    for (const it of r.items) {
      n++
      lines.push(`[${n}] ${String(it.title || '').trim()}`)
      lines.push(`URL: ${String(it.url || '').trim()}`)
      lines.push(`ÂÜÖÂÆπ: ${String(it.content || '').trim()}`)
      lines.push('')
      refLines.push(`[${n}] ${String(it.title || '').trim()} - ${String(it.url || '').trim()}`)
    }
    if (r.note) { lines.push(`ÔºàÊ≥®Ôºö${r.note}Ôºâ`); lines.push('') }
  })

  lines.push('')
  lines.push('„ÄêÂèÇËÄÉÊù•Ê∫êÂàóË°®„Äë')
  lines.push(...refLines)
  lines.push('')
  lines.push('„ÄêÂõûÁ≠îË¶ÅÊ±Ç„Äë')
  lines.push('- Âü∫‰∫é‰ª•‰∏äÊù•Ê∫êÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢ò„ÄÇ')
  lines.push('- ÂºïÁî®Ê†ºÂºèÂøÖÈ°ª‰∏∫ markdown ÈìæÊé•Ôºö[ÁºñÂè∑](url)Ôºå‰æãÂ¶Ç [1](https://example.com)„ÄÇ')
  lines.push('- ÂèØ‰ª•ÂêåÊó∂ÂºïÁî®Â§ö‰∏™Êù•Ê∫êÔºåÁî®ÈÄóÂè∑ÂàÜÈöîÔºö[1](url1), [2](url2)„ÄÇ')
  lines.push('- Âú®ÂõûÁ≠îÊú´Â∞æÔºåÂàóÂá∫ÊâÄÊúâÂºïÁî®ËøáÁöÑÂèÇËÄÉÊù•Ê∫êÔºåÊ†ºÂºèÔºö')
  lines.push('  ## ÂèÇËÄÉÊù•Ê∫ê')
  lines.push('  - [Ê†áÈ¢ò](url)')
  lines.push('- Ëã•Êù•Ê∫ê‰∏çË∂≥‰ª•ÊîØÊåÅÁªìËÆ∫ÔºåËØ∑ÊòéÁ°ÆËØ¥Êòé„ÄÇ')

  return lines.join('\n')
}

function appendTextToMessageContent(content: MessageContent, appendix: string): MessageContent {
  if (!appendix?.trim()) return content
  if (typeof content === 'string') return `${content}\n\n${appendix}`
  if (Array.isArray(content)) {
    const idx = (content as any[]).findIndex(p => p?.type === 'text' && typeof p?.text === 'string')
    if (idx >= 0) {
      const arr = [...(content as any[])]
      arr[idx] = { ...(arr[idx] || {}), text: `${arr[idx].text}\n\n${appendix}` }
      return arr as any
    }
    return [{ type: 'text', text: appendix }, ...(content as any[])] as any
  }
  return content
}
// ===================== ËÅîÁΩëÊêúÁ¥¢ END =====================

const ErrorCodeMessage: Record<string, string> = {
  401: 'Êèê‰æõÈîôËØØÁöÑAPIÂØÜÈí•',
  403: 'ÊúçÂä°Âô®ÊãíÁªùËÆøÈóÆÔºåËØ∑Á®çÂêéÂÜçËØï',
  502: 'ÈîôËØØÁöÑÁΩëÂÖ≥',
  503: 'ÊúçÂä°Âô®ÁπÅÂøôÔºåËØ∑Á®çÂêéÂÜçËØï',
  504: 'ÁΩëÂÖ≥Ë∂ÖÊó∂',
  500: 'ÊúçÂä°Âô®ÁπÅÂøôÔºåËØ∑Á®çÂêéÂÜçËØï',
}

let auditService: TextAuditService
const _lockedKeys: { key: string; lockedTime: number }[] = []

const DATA_URL_IMAGE_CAPTURE_RE = /data:(image\/[a-zA-Z0-9.+-]+);base64,([A-Za-z0-9+/=]+)/g
const MARKDOWN_IMAGE_RE = /!$$[^$$]*]$\s*([^)]+?)\s*$/g
const UPLOADS_URL_RE = /(\/uploads\/[^)\s>"']+\.(?:png|jpe?g|webp|gif|bmp|heic))/gi
const HTML_IMAGE_RE = /<img[^>]*\ssrc=["']([^"']+)["'][^>]*>/gi
const DATA_URL_IMAGE_RE = /data:image\/[a-zA-Z0-9.+-]+;base64,[A-Za-z0-9+/=]+/g

async function replaceDataUrlImagesWithUploads(text: string): Promise<{ text: string; saved: Array<{ mime: string; filename: string; bytes: number }> }> {
  if (!text) return { text: '', saved: [] }
  const saved: Array<{ mime: string; filename: string; bytes: number }> = []
  let out = ''; let lastIndex = 0
  const matches = text.matchAll(DATA_URL_IMAGE_CAPTURE_RE)
  for (const m of matches) {
    const full = m[0]; const mime = m[1]; const base64 = m[2]; const idx = m.index ?? -1
    if (idx < 0) continue
    out += text.slice(lastIndex, idx)
    const buffer = Buffer.from(base64, 'base64')
    const ext = mime.split('/')[1] || 'png'
    const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`
    const filePath = path.join(UPLOAD_DIR, filename)
    await fs.writeFile(filePath, buffer)
    saved.push({ mime, filename, bytes: buffer.length })
    out += `/uploads/${filename}`
    lastIndex = idx + full.length
  }
  out += text.slice(lastIndex)
  return { text: out, saved }
}

type SavedUpload = { mime: string; filename: string; bytes: number }
type DataUrlCache = Map<string, string>

function parseDataUrlImage(dataUrl: string): { mime: string; base64: string } | null {
  const m = /^data:(image\/[a-zA-Z0-9.+-]+);base64,([A-Za-z0-9+/=\s]+)$/.exec(dataUrl)
  if (!m) return null
  const mime = m[1] || 'image/png'
  const base64 = (m[2] || '').replace(/\s+/g, '')
  if (!base64) return null
  return { mime, base64 }
}

function mimeToExt(mime: string): string {
  const t = (mime || '').toLowerCase()
  if (t === 'image/jpeg' || t === 'image/jpg') return 'jpg'
  if (t === 'image/png') return 'png'
  if (t === 'image/webp') return 'webp'
  if (t === 'image/gif') return 'gif'
  if (t === 'image/bmp') return 'bmp'
  if (t === 'image/heic') return 'heic'
  return t.split('/')[1] || 'png'
}

async function saveDataUrlImageToUploads(dataUrl: string, cache?: DataUrlCache): Promise<{ url: string; saved: SavedUpload } | null> {
  try {
    if (!dataUrl?.startsWith('data:image/')) return null
    if (cache?.has(dataUrl)) { const url = cache.get(dataUrl)!; return { url, saved: { mime: 'image/*', filename: path.basename(url), bytes: 0 } } }
    const parsed = parseDataUrlImage(dataUrl); if (!parsed) return null
    await ensureUploadDir()
    const buffer = Buffer.from(parsed.base64, 'base64')
    const ext = mimeToExt(parsed.mime)
    const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`
    const filePath = path.join(UPLOAD_DIR, filename)
    await fs.writeFile(filePath, buffer)
    const url = `/uploads/${filename}`
    cache?.set(dataUrl, url)
    return { url, saved: { mime: parsed.mime, filename, bytes: buffer.length } }
  }
  catch (e) { console.error('[saveDataUrlImageToUploads] failed:', e); return null }
}

async function normalizeMessageContentDataUrlsToUploads(content: MessageContent, cache?: DataUrlCache): Promise<{ content: MessageContent; saved: SavedUpload[] }> {
  const savedAll: SavedUpload[] = []
  if (typeof content === 'string') { const replaced = await replaceDataUrlImagesWithUploads(content); savedAll.push(...replaced.saved); return { content: replaced.text, saved: savedAll } }
  if (Array.isArray(content)) {
    const newParts: any[] = []
    for (const p of content as any[]) {
      if (p?.type === 'text' && typeof p.text === 'string') { const replaced = await replaceDataUrlImagesWithUploads(p.text); savedAll.push(...replaced.saved); newParts.push({ ...p, text: replaced.text }); continue }
      if (p?.type === 'image_url' && typeof p.image_url?.url === 'string') {
        const u = p.image_url.url as string
        if (u.startsWith('data:image/')) { const r = await saveDataUrlImageToUploads(u, cache); if (r?.url) { savedAll.push(r.saved); newParts.push({ ...p, image_url: { ...p.image_url, url: r.url } }); continue } }
        newParts.push(p); continue
      }
      newParts.push(p)
    }
    return { content: newParts as any, saved: savedAll }
  }
  return { content, saved: savedAll }
}

async function normalizeUrlsDataUrlsToUploads(urls: string[], cache?: DataUrlCache): Promise<{ urls: string[]; saved: SavedUpload[] }> {
  const out: string[] = []; const savedAll: SavedUpload[] = []
  for (const u of urls || []) {
    if (typeof u === 'string' && u.startsWith('data:image/')) { const r = await saveDataUrlImageToUploads(u, cache); if (r?.url) { out.push(r.url); savedAll.push(r.saved) } else { out.push(u) } }
    else { out.push(u) }
  }
  return { urls: out, saved: savedAll }
}

function shortUrlForLog(u: string): string {
  if (!u) return ''
  if (u.startsWith('data:image/')) { const mime = u.match(/^data:(image\/[a-zA-Z0-9.+-]+);base64,/)?.[1] ?? 'image/*'; return `dataUrl(${mime},len=${u.length})` }
  return u.length > 200 ? `${u.slice(0, 200)}...(len=${u.length})` : u
}

function extractImageUrlsFromText(text: string): { cleanedText: string; urls: string[] } {
  if (!text) return { cleanedText: '', urls: [] }
  const urls: string[] = []; let cleaned = text
  cleaned = cleaned.replace(MARKDOWN_IMAGE_RE, (_m, inside) => { const raw = String(inside ?? '').trim(); if (raw) { const firstToken = raw.split(/\s+/)[0] || ''; const url = firstToken.replace(/^<|>$/g, '').trim(); if (url) urls.push(url) }; return '[Image]' })
  cleaned = cleaned.replace(HTML_IMAGE_RE, (_m, url) => { if (url) urls.push(url); return '[Image]' })
  const rawDataUrls = cleaned.match(DATA_URL_IMAGE_RE); if (rawDataUrls?.length) urls.push(...rawDataUrls); cleaned = cleaned.replace(DATA_URL_IMAGE_RE, '[Image]')
  const uploadUrls = cleaned.match(UPLOADS_URL_RE); if (uploadUrls?.length) urls.push(...uploadUrls); cleaned = cleaned.replace(UPLOADS_URL_RE, '[Image]')
  return { cleanedText: cleaned, urls }
}

async function extractImageUrlsFromMessageContent(content: MessageContent): Promise<{ cleanedText: string; urls: string[] }> {
  const urls: string[] = []; let cleanedText = ''
  if (typeof content === 'string') { const r = extractImageUrlsFromText(content); cleanedText = r.cleanedText; urls.push(...r.urls); if (!cleanedText?.trim() && urls.length) cleanedText = '[Image]'; return { cleanedText, urls } }
  if (Array.isArray(content)) {
    for (const p of content as any[]) {
      if (p?.type === 'text' && p.text) { const r = extractImageUrlsFromText(p.text); if (r.cleanedText) cleanedText += (cleanedText ? '\n' : '') + r.cleanedText; if (r.urls.length) urls.push(...r.urls) }
      else if (p?.type === 'image_url' && p.image_url?.url) { urls.push(p.image_url.url); cleanedText += (cleanedText ? '\n' : '') + '[Image]' }
    }
    if (!cleanedText?.trim() && urls.length) cleanedText = '[Image]'; return { cleanedText, urls }
  }
  return { cleanedText: '', urls: [] }
}

function dedupeUrlsPreserveOrder(urls: string[]): string[] { const seen = new Set<string>(); const out: string[] = []; for (const u of urls) { if (!u) continue; if (seen.has(u)) continue; seen.add(u); out.push(u) }; return out }

async function imageUrlToGeminiInlinePart(urlStr: string): Promise<GeminiPart | null> {
  if (urlStr.startsWith('data:')) { const [header, base64Data] = urlStr.split(','); if (!header || !base64Data) return null; const mimeMatch = header.match(/:(.*?);/); const mimeType = mimeMatch ? mimeMatch[1] : 'image/png'; return { inlineData: { mimeType, data: base64Data } } }
  if (urlStr.includes('/uploads/')) { const filename = path.basename(urlStr); const fileData = await getFileBase64(filename); if (!fileData) return null; return { inlineData: { mimeType: fileData.mime, data: fileData.data } } }
  return null
}

type ImageBinding = { tag: string; source: 'current_user' | 'last_ai' | 'prev_user' | 'prev_ai'; url: string }
type HistoryMessageMeta = { role: 'user' | 'model'; cleanedText: string; urls: string[]; messageId: string }

function applyImageBindingsToCleanedText(cleanedText: string, urls: string[], bindings: ImageBinding[]): string {
  const map = new Map<string, string>(); for (const b of bindings) map.set(b.url, b.tag)
  let out = cleanedText || ''; for (const u of urls) { const tag = map.get(u); const token = tag ? `[${tag}]` : '[Image]'; out = out.replace('[Image]', token) }
  if (!out.trim() && urls.length) out = urls.map(u => (map.get(u) ? `[${map.get(u)}]` : '[Image]')).join(' ')
  return out
}

async function buildGeminiHistoryFromLastMessageId(params: { lastMessageId?: string; maxContextCount: number; forGeminiImageModel: boolean }): Promise<{ metas: HistoryMessageMeta[]; allUrls: string[] }> {
  const { lastMessageId: startId, maxContextCount, forGeminiImageModel } = params
  const metasRev: HistoryMessageMeta[] = []; const urlsRev: string[] = []
  let lastMessageId = startId
  for (let i = 0; i < maxContextCount; i++) {
    if (!lastMessageId) break; const msg = await getMessageById(lastMessageId); if (!msg) break
    const role = (msg.role === 'assistant' ? 'model' : 'user') as 'user' | 'model'
    if (forGeminiImageModel) { const { cleanedText, urls } = await extractImageUrlsFromMessageContent(msg.text); if (urls.length) urlsRev.push(...urls); metasRev.push({ role, cleanedText: cleanedText?.trim() ? cleanedText : (urls.length ? '[Image]' : '[Empty]'), urls, messageId: msg.id }) }
    else { metasRev.push({ role, cleanedText: typeof msg.text === 'string' ? msg.text : '[Complex Content]', urls: [], messageId: msg.id }) }
    lastMessageId = msg.parentMessageId
  }
  return { metas: metasRev.reverse(), allUrls: dedupeUrlsPreserveOrder(urlsRev.reverse()) }
}

function getLastNByRole(metas: HistoryMessageMeta[], role: 'user' | 'model', n: number): HistoryMessageMeta[] { const out: HistoryMessageMeta[] = []; for (let i = metas.length - 1; i >= 0; i--) { if (metas[i].role !== role) continue; out.push(metas[i]); if (out.length >= n) break }; return out }

function selectRecentTwoRoundsImages(metas: HistoryMessageMeta[], currentUrls: string[]): ImageBinding[] {
  const lastModels = getLastNByRole(metas, 'model', 2); const lastUsers = getLastNByRole(metas, 'user', 1)
  const groups = [
    { source: 'current_user' as const, tagPrefix: 'U0', urls: currentUrls },
    { source: 'last_ai' as const, tagPrefix: 'A0', urls: lastModels[0]?.urls ?? [] },
    { source: 'prev_user' as const, tagPrefix: 'U1', urls: lastUsers[0]?.urls ?? [] },
    { source: 'prev_ai' as const, tagPrefix: 'A1', urls: lastModels[1]?.urls ?? [] },
  ]
  const seen = new Set<string>(); const bindings: ImageBinding[] = []
  for (const g of groups) { let idx = 0; for (const u of g.urls) { if (!u) continue; if (seen.has(u)) continue; seen.add(u); idx += 1; bindings.push({ tag: `${g.tagPrefix}_${idx}`, source: g.source, url: u }) } }
  return bindings
}

const IMAGE_SOURCE_LABEL: Record<ImageBinding['source'], string> = {
  current_user: 'Êú¨Ê¨°Áî®Êà∑Ê∂àÊÅØ', last_ai: 'ÊúÄËøë‰∏ÄÊù°AIÂõûÂ§ç', prev_user: '‰∏ä‰∏ÄÊ¨°Áî®Êà∑Ê∂àÊÅØ', prev_ai: 'ÂÄíÊï∞Á¨¨‰∫åÊù°AIÂõûÂ§ç',
}
export async function initApi(key: KeyConfig, {
  model, maxContextCount, temperature, top_p, abortSignal, content, systemMessage, lastMessageId, isImageModel,
}: any) {
  const config = await getCacheConfig()
  const OPENAI_API_BASE_URL = isNotEmptyString(key.baseUrl) ? key.baseUrl : config.apiBaseUrl
  const openai = new OpenAI({
    baseURL: OPENAI_API_BASE_URL, apiKey: key.key, maxRetries: 0, timeout: config.timeoutMs,
  })

  const modelConfig = MODEL_CONFIGS[model] || { supportTopP: true }
  const finalTemperature = modelConfig.defaultTemperature ?? temperature
  const shouldUseTopP = modelConfig.supportTopP

  const messages: OpenAI.ChatCompletionMessageParam[] = []
  for (let i = 0; i < maxContextCount; i++) {
    if (!lastMessageId) break
    const message = await getMessageById(lastMessageId)
    if (!message) break
    let safeContent = message.text as string
    if (typeof safeContent === 'string') safeContent = safeContent.replace(DATA_URL_IMAGE_RE, '[Image Data Removed]')
    messages.push({ role: message.role as any, content: safeContent })
    lastMessageId = message.parentMessageId
  }
  if (systemMessage) messages.push({ role: 'system', content: systemMessage })
  messages.reverse()
  messages.push({ role: 'user', content })

  const enableStream = !isImageModel
  const options: OpenAI.ChatCompletionCreateParams = {
    model, stream: enableStream, stream_options: enableStream ? { include_usage: true } : undefined, messages,
  }
  options.temperature = finalTemperature
  if (shouldUseTopP) options.top_p = top_p

  try {
    const siteCfg = config.siteConfig
    const reasoningModelsStr = siteCfg?.reasoningModels || ''
    const reasoningEffort = siteCfg?.reasoningEffort || 'medium'
    const reasoningModelList = reasoningModelsStr.split(/[,Ôºå]/).map(s => s.trim()).filter(Boolean)
    const isReasoningModel = reasoningModelList.includes(model)
    if (isReasoningModel && reasoningEffort && reasoningEffort !== 'none')
      (options as any).reasoning_effort = reasoningEffort
  }
  catch (e) { console.error('[OpenAI] set reasoning_effort failed:', e) }

  if (API_DEBUG) {
    debugLog('====== [OpenAI Request Debug] ======')
    debugLog('[baseURL]', OPENAI_API_BASE_URL)
    debugLog('[model]', model)
    debugLog('[isImageModel]', !!isImageModel)
    debugLog('[messagesSummary]', safeJson(summarizeOpenAIMessages(messages)))
    debugLog('====== [OpenAI Request Debug End] ======')
  }

  const apiResponse = await openai.chat.completions.create(options, { signal: abortSignal })
  return apiResponse
}

type ProcessThread = { key: string; userId: string; roomId: number; abort: AbortController; messageId: string }
const processThreads: ProcessThread[] = []
const makeThreadKey = (userId: string, roomId: number) => `${userId}:${roomId}`

async function chatReplyProcess(options: RequestOptions): Promise<{ message: string; data: ChatResponse; status: string }> {
  const userId = options.user._id.toString()
  const messageId = options.messageId
  const roomId = options.room.roomId
  const abort = new AbortController()
  const customMessageId = generateMessageId()
  const threadKey = makeThreadKey(userId, roomId)

  const existingIdx = processThreads.findIndex(t => t.key === threadKey)
  if (existingIdx > -1) { processThreads[existingIdx].abort.abort(); processThreads.splice(existingIdx, 1) }
  processThreads.push({ key: threadKey, userId, abort, messageId, roomId })

  await ensureUploadDir()
  const model = options.room.chatModel
  const key = await getRandomApiKey(options.user, model, options.room.accountId)
  const maxContextCount = options.user.advanced.maxContextCount ?? 20

  if (!key) {
    const idx = processThreads.findIndex(d => d.key === threadKey)
    if (idx > -1) processThreads.splice(idx, 1)
    throw new Error('Ê≤°ÊúâÂØπÂ∫îÁöÑ apikeys ÈÖçÁΩÆÔºåËØ∑ÂÜçËØï‰∏ÄÊ¨°„ÄÇ')
  }

  updateRoomChatModel(userId, options.room.roomId, model)

  // ‚úÖ Ëß£ÊûÑÊó∂Êää process ÊîπÂêç‰∏∫ processCbÔºåÈÅøÂÖçÈÅÆËîΩÂÖ®Â±Ä process.env
  const { message, uploadFileKeys, lastContext, process: processCb, systemMessage, temperature, top_p } = options

  processCb?.({
    id: customMessageId, text: '', role: 'assistant',
    conversationId: lastContext?.conversationId, parentMessageId: lastContext?.parentMessageId, detail: undefined,
  })

  let content: MessageContent = message
  let fileContext = ''
  const globalConfig = await getCacheConfig()
  const imageModelsStr = globalConfig.siteConfig.imageModels || ''
  const imageModelList = imageModelsStr.split(/[,Ôºå]/).map(s => s.trim()).filter(Boolean)
  const isImage = imageModelList.some(m => model.includes(m))
  const isGeminiImageModel = isImage && model.includes('gemini')

  if (uploadFileKeys && uploadFileKeys.length > 0) {
    const textFiles = uploadFileKeys.filter(k => isTextFile(k))
    const imageFiles = uploadFileKeys.filter(k => isImageFile(k))

    if (textFiles.length > 0) {
      for (const fileKey of textFiles) {
        try {
          const filePath = path.join(UPLOAD_DIR, stripTypePrefix(fileKey))
          await fs.access(filePath)
          const fileContent = await fs.readFile(filePath, 'utf-8')
          fileContext += `\n\n--- File Start: ${stripTypePrefix(fileKey)} ---\n${fileContent}\n--- File End ---\n`
        }
        catch (e) { console.error(`Error reading text file ${fileKey}`, e); fileContext += `\n\n[System Error: File ${fileKey} not found or unreadable]\n` }
      }
    }

    const finalMessage = message + (fileContext ? `\n\nAttached Files content:\n${fileContext}` : '')

    if (imageFiles.length > 0) {
      content = [{ type: 'text', text: finalMessage }]
      for (const uploadFileKey of imageFiles) {
        content.push({ type: 'image_url', image_url: { url: await convertImageUrl(stripTypePrefix(uploadFileKey)) } })
      }
    }
    else { content = finalMessage }
  }

  // =========================
  // ‚úÖ ËÅîÁΩëÊêúÁ¥¢ÔºàÂ§öËΩÆÔºöÊ®°ÂûãÂÜ≥ÂÆöÊòØÂê¶ÊêúÁ¥¢„ÄÅÊòØÂê¶Ë∞ÉÊï¥ÂÖ≥ÈîÆËØçÔºâ
  // =========================
  const allowSearch = globalConfig.siteConfig?.webSearchEnabled === true
  const finalSearchMode = allowSearch && options.searchMode === true && !isImage

  if (finalSearchMode) {
    try {
      const plannerModelCfg = String(globalConfig.siteConfig?.webSearchPlannerModel ?? '').trim()
      const plannerModelEnv = String(process.env.WEB_SEARCH_PLANNER_MODEL ?? '').trim()
      const plannerModelName = plannerModelCfg || plannerModelEnv || model

      // ‚úÖ planner ÂèØ‰ª•Áî®Áã¨Á´ãÁöÑ keyÔºà‰ªéÊâÄÊúâÂèØÁî® key ÈáåÊâæËÉΩË∑ë plannerModel ÁöÑ keyÔºâ
      let plannerKey = key
      if (plannerModelName !== model) {
        const candidateKey = await getRandomApiKey(options.user, plannerModelName)
        if (candidateKey) plannerKey = candidateKey
      }

      const PLANNER_BASE_URL = isNotEmptyString(plannerKey.baseUrl) ? plannerKey.baseUrl : globalConfig.apiBaseUrl
      const plannerOpenai = new OpenAI({
        baseURL: PLANNER_BASE_URL, apiKey: plannerKey.key, maxRetries: 0, timeout: globalConfig.timeoutMs,
      })

      const maxRounds = Math.max(1, Math.min(6, Number(globalConfig.siteConfig?.webSearchMaxRounds ?? process.env.WEB_SEARCH_MAX_ROUNDS ?? 3)))
      const maxResults = Math.max(1, Math.min(10, Number(globalConfig.siteConfig?.webSearchMaxResults ?? process.env.WEB_SEARCH_MAX_RESULTS ?? 5)))

      const plannerModels = [plannerModelName, model].filter((v, i, arr) => Boolean(v) && arr.indexOf(v) === i)

      const searchProvider = globalConfig.siteConfig?.webSearchProvider as any
      const searchSearxngUrl = String(globalConfig.siteConfig?.searxngApiUrl ?? '').trim() || undefined
      const searchTavilyKey = String(globalConfig.siteConfig?.tavilyApiKey ?? '').trim() || undefined

      // ‚úÖ ËøõÂ∫¶Êé®ÈÄÅ
      const progressMessages: string[] = []

      const rounds = await runIterativeWebSearch({
        openai: plannerOpenai,
        plannerModels,
        userQuestion: message,
        maxRounds,
        maxResults,
        abortSignal: abort.signal,
        provider: searchProvider,
        searxngApiUrl: searchSearxngUrl,
        tavilyApiKey: searchTavilyKey,
        onProgress: (status: string) => {
          progressMessages.push(status)
          const progressText = progressMessages.join('\n')
          processCb?.({
            id: customMessageId, text: progressText, role: 'assistant',
            conversationId: lastContext?.conversationId, parentMessageId: lastContext?.parentMessageId, detail: undefined,
          })
        },
      })

      const ctx = formatAggregatedSearchForAnswer(rounds)
      if (ctx) content = appendTextToMessageContent(content, ctx)

      if (API_DEBUG) {
        debugLog('====== [WebSearch Debug] ======')
        debugLog('[enabled]', true, '[plannerModel]', plannerModelName, '[plannerKeyRemark]', plannerKey.remark ?? '(current)')
        debugLog('[roundCount]', rounds.length)
        debugLog('====== [WebSearch Debug End] ======')
      }
    }
    catch (e: any) {
      if (isAbortError(e, abort.signal)) throw e
      console.error('[WebSearch] failed:', e?.message ?? e)
    }
  }

  try {
    // =========================
    // ‚ë† GeminiÔºàÂõæÁâáÊ®°ÂûãÔºâ
    // =========================
    if (isGeminiImageModel) {
      const baseUrl = isNotEmptyString(key.baseUrl) ? key.baseUrl.replace(/\/+$/, '') : undefined
      const dataUrlCache: DataUrlCache = new Map()
      const normalizedCurrent = await normalizeMessageContentDataUrlsToUploads(content, dataUrlCache)
      content = normalizedCurrent.content

      const { metas } = await buildGeminiHistoryFromLastMessageId({
        lastMessageId: lastContext.parentMessageId, maxContextCount, forGeminiImageModel: true,
      })

      const metasNormalized: HistoryMessageMeta[] = []
      for (const m of metas) { const nu = await normalizeUrlsDataUrlsToUploads(m.urls || [], dataUrlCache); metasNormalized.push({ ...m, urls: nu.urls }) }

      const { cleanedText: currentCleanedText, urls: currentUrlsRaw } = await extractImageUrlsFromMessageContent(content)
      const currentUrlsNorm = await normalizeUrlsDataUrlsToUploads(currentUrlsRaw || [], dataUrlCache)
      const currentUrls = currentUrlsNorm.urls

      const bindings = selectRecentTwoRoundsImages(metasNormalized, currentUrls)

      const history = metasNormalized.map(m => {
        const labeled = applyImageBindingsToCleanedText(m.cleanedText, m.urls, bindings)
        return { role: m.role, parts: [{ text: labeled || '[Empty]' }] }
      })

      const userInstructionBase = (currentCleanedText && currentCleanedText.trim()) ? currentCleanedText.trim() : 'ËØ∑ÁªßÁª≠ÁîüÊàê/‰øÆÊîπÂõæÁâá„ÄÇ'
      const labeledUserInstruction = applyImageBindingsToCleanedText(userInstructionBase, currentUrls, bindings)

      const inputParts: GeminiPart[] = []
      if (bindings.length) {
        const mapText = bindings.map(b => `${b.tag}=${IMAGE_SOURCE_LABEL[b.source]}(${shortUrlForLog(b.url)})`).join('\n')
        inputParts.push({ text: `„ÄêÊúÄËøë‰∏§ËΩÆÂõæÁâáÊò†Â∞ÑË°®„Äë\n${mapText}\n` })
      }
      for (const b of bindings) {
        inputParts.push({ text: `„Äê${b.tag}ÔΩú${IMAGE_SOURCE_LABEL[b.source]}„Äë` })
        const imgPart = await imageUrlToGeminiInlinePart(b.url)
        if (imgPart) inputParts.push(imgPart)
        else inputParts.push({ text: `ÔºàËØ•ÂõæÁâáÊó†Ê≥ï‰ª•ÂÜÖËÅîÊñπÂºè‰∏ä‰º†Ôºö${shortUrlForLog(b.url)}Ôºâ` })
      }
      inputParts.push({ text: `„ÄêÁºñËæëÊåá‰ª§„Äë${labeledUserInstruction}` })

      const ai = new GoogleGenAI({ apiKey: key.key, ...(baseUrl ? { httpOptions: { baseUrl } } : {}) })
      const contents = [...history, { role: 'user', parts: inputParts }]

      const response = await abortablePromise(
        ai.models.generateContent({
          model, contents,
          config: {
            responseModalities: ['TEXT', 'IMAGE'],
            imageConfig: { aspectRatio: '16:9', imageSize: '4K' },
            ...(systemMessage ? { systemInstruction: systemMessage } as any : {}),
          } as any,
        } as any),
        abort.signal,
      )

      if (!response.candidates || response.candidates.length === 0) throw new Error('[Gemini] Empty candidates.')

      let text = ''
      const parts = response.candidates?.[0]?.content?.parts ?? []

      for (const part of parts as any[]) {
        if (part?.text) { const rawText = part.text as string; const replaced = await replaceDataUrlImagesWithUploads(rawText); text += replaced.text }
        const inline = part?.inlineData; const inlineB64 = inline?.data
        if (inlineB64) {
          const mime = inline.mimeType || 'image/png'; const base64 = inlineB64 as string
          const buffer = Buffer.from(base64, 'base64')
          const ext = mime.split('/')[1] || 'png'
          const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`
          const filePath = path.join(UPLOAD_DIR, filename)
          await fs.writeFile(filePath, buffer)
          const prefix = text ? '\n\n' : ''
          text += `${prefix}![Generated Image](/uploads/${filename})`
        }
      }

      if (!text) text = '[Gemini] Success but no text/image parts returned.'

      processCb?.({
        id: customMessageId, text, role: 'assistant',
        conversationId: lastContext.conversationId, parentMessageId: lastContext.parentMessageId, detail: undefined,
      })

      return sendResponse({
        type: 'Success',
        data: {
          object: 'chat.completion',
          choices: [{ message: { role: 'assistant', content: text }, finish_reason: 'stop', index: 0, logprobs: null }],
          created: Date.now(), conversationId: lastContext.conversationId, model, text, id: customMessageId, detail: {},
        },
      })
    }

    // =========================
    // ‚ë° OpenAI
    // =========================
    const api = await initApi(key, {
      model, maxContextCount, temperature, top_p, content,
      abortSignal: abort.signal, systemMessage, lastMessageId: lastContext.parentMessageId, isImageModel: isImage,
    })

    let text = ''
    let chatIdRes = customMessageId
    let modelRes = ''
    let usageRes: any

    if (isImage) {
      const response = api as any
      const choice = response.choices[0]
      let rawContent = choice.message?.content || ''
      modelRes = response.model; usageRes = response.usage

      if (rawContent && !rawContent.startsWith('![') && (rawContent.startsWith('http') || rawContent.startsWith('data:image')))
        text = `![Generated Image](${rawContent})`
      else text = rawContent

      processCb?.({
        id: customMessageId, text, role: choice.message.role || 'assistant',
        conversationId: lastContext.conversationId, parentMessageId: lastContext.parentMessageId,
        detail: {
          choices: [{ finish_reason: 'stop', index: 0, logprobs: null, message: choice.message }],
          created: response.created, id: response.id, model: response.model, object: 'chat.completion', usage: response.usage,
        } as any,
      })
    }
    else {
      for await (const chunk of api as AsyncIterable<OpenAI.ChatCompletionChunk>) {
        text += chunk.choices[0]?.delta.content ?? ''
        chatIdRes = customMessageId; modelRes = chunk.model; usageRes = usageRes || chunk.usage
        processCb?.({
          ...chunk, id: customMessageId, text, role: chunk.choices[0]?.delta.role || 'assistant',
          conversationId: lastContext.conversationId, parentMessageId: lastContext.parentMessageId,
        })
      }
    }

    return sendResponse({
      type: 'Success',
      data: {
        object: 'chat.completion',
        choices: [{ message: { role: 'assistant', content: text }, finish_reason: 'stop', index: 0, logprobs: null }],
        created: Date.now(), conversationId: lastContext.conversationId, model: modelRes, text, id: chatIdRes,
        detail: { usage: usageRes && { ...usageRes, estimated: false } },
      },
    })
  }
  catch (error: any) {
    if (isAbortError(error, abort.signal)) throw error

    const code = error.statusCode
    if (code === 429 && (error.message.includes('Too Many Requests') || error.message.includes('Rate limit'))) {
      if (options.tryCount++ < 3) {
        _lockedKeys.push({ key: key.key, lockedTime: Date.now() })
        await new Promise(resolve => setTimeout(resolve, 2000))
        const index = processThreads.findIndex(d => d.key === threadKey)
        if (index > -1) processThreads.splice(index, 1)
        return await chatReplyProcess(options)
      }
    }

    globalThis.console.error(error)

    if (Reflect.has(ErrorCodeMessage, code))
      return sendResponse({ type: 'Fail', message: ErrorCodeMessage[code] })

    return sendResponse({ type: 'Fail', message: error.message ?? 'Please check the back-end console' })
  }
  finally {
    const index = processThreads.findIndex(d => d.key === threadKey)
    if (index > -1) processThreads.splice(index, 1)
  }
}

// ‚úÖ ‰øÆÊîπÔºöÊîØÊåÅ roomId
export function abortChatProcess(userId: string, roomId: number) {
  const key = makeThreadKey(userId, roomId)
  const index = processThreads.findIndex(d => d.key === key)
  if (index <= -1) return
  const messageId = processThreads[index].messageId
  processThreads[index].abort.abort()
  processThreads.splice(index, 1)

  if (API_DEBUG) {
    debugLog('====== [Abort Debug] ======')
    debugLog('[userId]', userId, '[roomId]', roomId, '[messageId]', messageId)
    debugLog('====== [Abort Debug End] ======')
  }

  return messageId
}

export function initAuditService(audit: AuditConfig) {
  if (!audit || !audit.options || !audit.options.apiKey || !audit.options.apiSecret) return
  const Service = textAuditServices[audit.provider]
  auditService = new Service(audit.options)
}

async function containsSensitiveWords(audit: AuditConfig, text: string): Promise<boolean> {
  if (audit.customizeEnabled && isNotEmptyString(audit.sensitiveWords)) {
    const textLower = text.toLowerCase()
    const notSafe = audit.sensitiveWords.split('\n').filter(d => textLower.includes(d.trim().toLowerCase())).length > 0
    if (notSafe) return true
  }
  if (audit.enabled) {
    if (!auditService) initAuditService(audit)
    return await auditService.containsSensitiveWords(text)
  }
  return false
}

async function chatConfig() {
  const config = await getOriginConfig() as ModelConfig
  return sendResponse<ModelConfig>({ type: 'Success', data: config })
}
async function getMessageById(id: string): Promise<ChatMessage | undefined> {
  const isPrompt = id.startsWith('prompt_')
  const chatInfo = await getChatByMessageId(isPrompt ? id.substring(7) : id)

  if (!chatInfo)
    return undefined

  const parentMessageId = isPrompt
    ? chatInfo.options.parentMessageId
    : `prompt_${id}`

  if (chatInfo.status !== Status.Normal)
    return parentMessageId ? getMessageById(parentMessageId) : undefined

  if (isPrompt) {
    let promptText = chatInfo.prompt
    const allFileKeys = chatInfo.images || []
    const textFiles = allFileKeys.filter(k => isTextFile(k))
    const imageFiles = allFileKeys.filter(k => isImageFile(k))

    if (textFiles.length > 0) {
      let fileContext = ''
      for (const fileKey of textFiles) {
        try {
          const filePath = path.join(UPLOAD_DIR, stripTypePrefix(fileKey))
          const fileContent = await fs.readFile(filePath, 'utf-8')
          fileContext += `\n\n--- Context File: ${stripTypePrefix(fileKey)} ---\n${fileContent}\n--- End File ---\n`
        }
        catch { }
      }
      promptText += (fileContext ? `\n\n[Attached Files History]:\n${fileContext}` : '')
    }

    if (promptText && typeof promptText === 'string')
      promptText = promptText.replace(DATA_URL_IMAGE_RE, '[Image Data Removed]')

    let content: MessageContent = promptText

    if (imageFiles.length > 0) {
      content = [{ type: 'text', text: promptText }]
      for (const image of imageFiles) {
        content.push({
          type: 'image_url',
          image_url: { url: await convertImageUrl(stripTypePrefix(image)) },
        })
      }
    }

    if (API_DEBUG) {
      debugLog('------ [getMessageById Prompt Debug] ------')
      debugLog('[id]', id, '[parent]', parentMessageId)
      debugLog('[promptTextLen]', typeof promptText === 'string' ? promptText.length : -1)
      debugLog('[promptTextPreview]', trunc(promptText))
      debugLog('[imageFiles]', imageFiles)
      debugLog('[textFiles]', textFiles)
      debugLog('------------------------------------------')
    }

    return {
      id,
      conversationId: chatInfo.options.conversationId,
      parentMessageId,
      role: 'user',
      text: content,
    }
  }
  else {
    let responseText = chatInfo.response || ''
    if (responseText && typeof responseText === 'string')
      responseText = responseText.replace(DATA_URL_IMAGE_RE, '[Image History]')

    if (API_DEBUG) {
      debugLog('------ [getMessageById Assistant Debug] ------')
      debugLog('[id]', id, '[parent]', parentMessageId)
      debugLog('[responseLen]', typeof responseText === 'string' ? responseText.length : -1)
      debugLog('[responsePreview]', trunc(responseText))
      debugLog('---------------------------------------------')
    }

    return {
      id,
      conversationId: chatInfo.options.conversationId,
      parentMessageId,
      role: 'assistant',
      text: responseText,
    }
  }
}

/**
 * ===== Key ÈÄâÊã©Áõ∏ÂÖ≥ÂáΩÊï∞ =====
 */
async function randomKeyConfig(keys: KeyConfig[]): Promise<KeyConfig | null> {
  if (keys.length <= 0) return null
  _lockedKeys
    .filter(d => d.lockedTime <= Date.now() - 1000 * 20)
    .forEach(d => _lockedKeys.splice(_lockedKeys.indexOf(d), 1))

  let unsedKeys = keys.filter(d => _lockedKeys.filter(l => d.key === l.key).length <= 0)
  const start = Date.now()

  while (unsedKeys.length <= 0) {
    if (Date.now() - start > 3000) break
    await new Promise(resolve => setTimeout(resolve, 1000))
    unsedKeys = keys.filter(d => _lockedKeys.filter(l => d.key === l.key).length <= 0)
  }

  if (unsedKeys.length <= 0) return null
  return unsedKeys[Math.floor(Math.random() * unsedKeys.length)]
}

async function getRandomApiKey(user: UserInfo, chatModel: string, accountId?: string): Promise<KeyConfig | undefined> {
  let keys = (await getCacheApiKeys())
    .filter(d => hasAnyRole(d.userRoles, user.roles))
    .filter(d => d.chatModels.includes(chatModel))

  if (accountId)
    keys = keys.filter(d => d.keyModel === 'ChatGPTUnofficialProxyAPI' && getAccountId(d.key) === accountId)

  const picked = await randomKeyConfig(keys)

  if (API_DEBUG) {
    debugLog('====== [Key Pick Debug] ======')
    debugLog('[chatModel]', chatModel, '[accountId]', accountId ?? '(none)')
    debugLog('[candidateKeyCount]', keys.length)
    debugLog('[picked]', picked ? { keyModel: picked.keyModel, baseUrl: picked.baseUrl, remark: picked.remark } : '(null)')
    debugLog('====== [Key Pick Debug End] ======')
  }

  return picked ?? undefined
}

function getAccountId(accessToken: string): string {
  try {
    const jwt = jwt_decode(accessToken) as JWT
    return jwt['https://api.openai.com/auth'].user_id
  }
  catch {
    return ''
  }
}

export { chatReplyProcess, chatConfig, containsSensitiveWords }
