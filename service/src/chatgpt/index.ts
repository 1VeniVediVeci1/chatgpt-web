import * as dotenv from 'dotenv'
import { generateText, streamText } from 'ai'
import type { CoreMessage } from 'ai'
import { textTokens } from 'gpt-token'
import type { TiktokenModel } from 'gpt-token'
import type { AuditConfig, KeyConfig, UserInfo } from '../storage/model'
import { Status } from '../storage/model'
import { convertImageUrl } from '../utils/image'
import type { TextAuditService } from '../utils/textAudit'
import { textAuditServices } from '../utils/textAudit'
import { getCacheApiKeys, getCacheConfig, getOriginConfig } from '../storage/config'
import { sendResponse } from '../utils'
import { hasAnyRole, isNotEmptyString } from '../utils/is'
import type { ModelConfig } from '../types'
import { getChatByMessageId, updateRoomChatModel } from '../storage/mongo'
import type { ChatMessage, ChatResponse, MessageContent, RequestOptions } from './types'
import * as fs from 'node:fs/promises'
import * as path from 'node:path'
import { generateMessageId } from '../utils/id-generator'
import { isAbortError } from './abortable'
import { webSearch } from '../utils/webSearch'
import { createLanguageModel, normalizeProvider } from '../ai/provider'

dotenv.config()

const API_DEBUG = process.env.API_DEBUG === 'true'
const API_DEBUG_MAX_TEXT = Number(process.env.API_DEBUG_MAX_TEXT ?? 800)

function trunc(s: any, n = API_DEBUG_MAX_TEXT): string {
  const str = typeof s === 'string' ? s : JSON.stringify(s ?? '')
  if (!str) return ''
  return str.length > n ? `${str.slice(0, n)}...(truncated,total=${str.length})` : str
}
function safeJson(obj: any): string { try { return JSON.stringify(obj, null, 2) } catch (e: any) { return `[Unserializable: ${e?.message ?? e}]` } }
function debugLog(...args: any[]) { if (!API_DEBUG) return; console.log(...args) }

const MODEL_CONFIGS: Record<string, { supportTopP: boolean; defaultTemperature?: number }> = {
  'gpt-5-search-api': { supportTopP: false, defaultTemperature: 0.8 },
}

const UPLOAD_DIR = path.resolve(process.cwd(), 'uploads')

async function ensureUploadDir() {
  try { await fs.access(UPLOAD_DIR) } catch { await fs.mkdir(UPLOAD_DIR, { recursive: true }) }
}

function stripTypePrefix(key: string): string { return key.replace(/^(img:|txt:)/, '') }

function isTextFile(filename: string): boolean {
  if (filename.startsWith('txt:')) return true
  if (filename.startsWith('img:')) return false
  const ext = path.extname(stripTypePrefix(filename)).toLowerCase()
  return ['.txt', '.md', '.json', '.csv', '.js', '.ts', '.py', '.java', '.html', '.css', '.xml', '.yml', '.yaml', '.log', '.ini', '.config'].includes(ext)
}

function isImageFile(filename: string): boolean {
  if (filename.startsWith('img:')) return true
  if (filename.startsWith('txt:')) return false
  const ext = path.extname(stripTypePrefix(filename)).toLowerCase()
  return ['.png', '.jpg', '.jpeg', '.webp', '.gif', '.heic', '.bmp'].includes(ext)
}

async function getFileBase64(filename: string): Promise<{ mime: string; data: string } | null> {
  try {
    const realFilename = stripTypePrefix(filename)
    const filePath = path.join(UPLOAD_DIR, realFilename)
    await fs.access(filePath)
    const buffer = await fs.readFile(filePath)
    const ext = path.extname(realFilename).toLowerCase().replace('.', '')
    let mime = 'image/png'
    if (ext === 'jpg' || ext === 'jpeg') mime = 'image/jpeg'
    else if (ext === 'webp') mime = 'image/webp'
    else if (ext === 'gif') mime = 'image/gif'
    else if (ext === 'heic') mime = 'image/heic'
    else if (ext === 'bmp') mime = 'image/bmp'
    return { mime, data: buffer.toString('base64') }
  }
  catch (e) {
    globalThis.console.error(`[File Read Error] ${filename}:`, e)
    return null
  }
}

function estimateTokenCount(messages: Array<{ role: string; content: any }>): number {
  let allText = ''
  try {
    allText = (messages ?? []).map(m => {
      const c = m?.content
      if (typeof c === 'string') return c
      if (Array.isArray(c)) {
        return c.map((p: any) => p?.type === 'text' ? String(p.text || '') : '').join('')
      }
      return ''
    }).join('\n')

    const count = textTokens(allText, 'gpt-3.5-turbo' as TiktokenModel)
    if (count === 0 && allText.length > 0) return Math.ceil(allText.length / 3)
    return count
  }
  catch {
    if (allText && allText.length > 0) return Math.ceil(allText.length / 4)
    return 0
  }
}

function mergeAbortSignals(signals: Array<AbortSignal | undefined>): AbortSignal | undefined {
  const list = signals.filter(Boolean) as AbortSignal[]
  if (!list.length) return undefined
  const anyFn = (AbortSignal as any).any
  if (typeof anyFn === 'function') return anyFn(list)

  const ac = new AbortController()
  const onAbort = () => { try { ac.abort() } catch { } }
  for (const s of list) {
    if (s.aborted) { try { ac.abort() } catch { } break }
    s.addEventListener('abort', onAbort, { once: true })
  }
  return ac.signal
}

function toCoreMessages(messages: Array<{ role: string; content: any }>): CoreMessage[] {
  return (messages || []).map((m) => {
    const role = (m.role === 'system' || m.role === 'user' || m.role === 'assistant')
      ? m.role
      : 'user'
    const c = m.content

    if (typeof c === 'string') {
      return { role, content: c }
    }

    if (Array.isArray(c)) {
      const parts = c.map((p: any) => {
        if (p?.type === 'text')
          return { type: 'text' as const, text: String(p.text ?? '') }
        if (p?.type === 'image_url')
          return { type: 'image' as const, image: String(p.image_url?.url ?? '') }
        return { type: 'text' as const, text: String(p?.text ?? '') }
      })
      return { role, content: parts as any }
    }

    return { role, content: String(c ?? '') }
  })
}

function toUsageResponse(usage: any): any | undefined {
  if (!usage) return undefined
  const input = Number(usage.inputTokens ?? usage.promptTokens ?? usage.prompt_tokens ?? 0)
  const output = Number(usage.outputTokens ?? usage.completionTokens ?? usage.completion_tokens ?? 0)
  const total = Number(usage.totalTokens ?? usage.total_tokens ?? (input + output))
  return {
    prompt_tokens: input,
    completion_tokens: output,
    total_tokens: total,
    estimated: false,
  }
}

const DATA_URL_IMAGE_RE = /data:image\/[a-zA-Z0-9.+-]+;base64,[A-Za-z0-9+/=]+/g

async function loadContextMessages(params: {
  maxContextCount: number
  lastMessageId?: string
  systemMessage?: string
  content: MessageContent
}): Promise<Array<{ role: 'system' | 'user' | 'assistant'; content: any }>> {
  const { maxContextCount, systemMessage, content } = params
  let { lastMessageId } = params

  const messages: Array<{ role: 'system' | 'user' | 'assistant'; content: any }> = []

  for (let i = 0; i < maxContextCount; i++) {
    if (!lastMessageId) break
    const message = await getMessageById(lastMessageId)
    if (!message) break

    let safeContent = message.text as any
    if (typeof safeContent === 'string') {
      safeContent = safeContent.replace(DATA_URL_IMAGE_RE, '[Image Data Removed]')
    }
    messages.push({ role: message.role, content: safeContent })
    lastMessageId = message.parentMessageId
  }

  // ‰øÆÊîπÔºö‰ªÖÂú®ËøôÈáåÂ°ûÂÖ•Á≥ªÁªüÊ∂àÊÅØÔºåÈÅøÂÖçÂíå API Ë∞ÉÁî®ÁöÑ system ÂÜ≤Á™Å
  if (systemMessage)
    messages.push({ role: 'system', content: systemMessage })

  messages.reverse()
  messages.push({ role: 'user', content: content as any })

  return messages
}

type SearchPlan = {
  action: 'search' | 'stop'
  query?: string
  reason?: string
  selected_ids?: string[]
  context_summary?: string
}
type SearchRound = { query: string; items: Array<{ title: string; url: string; content: string }>; note?: string }

function safeParseJsonFromText(text: string): any | null {
  if (!text) return null
  const s = String(text).trim()
  try { return JSON.parse(s) } catch { }
  const i = s.indexOf('{'); const j = s.lastIndexOf('}')
  if (i >= 0 && j > i) {
    try { return JSON.parse(s.slice(i, j + 1)) } catch { }
  }
  return null
}

function removeImagesFromText(text: string): string {
  if (!text) return ''
  let clean = text.replace(/!$$[^$$]*\]\s*$[^)]+?$\s*$/g, '')
  clean = clean.replace(/<img[^>]*>/gi, '')
  clean = clean.replace(/data:image\/[a-zA-Z0-9.+-]+;base64,[A-Za-z0-9+/=]+/g, '')
  return clean.trim()
}

class PlannerTimeoutError extends Error {
  public readonly code = 'PLANNER_TIMEOUT'
  public readonly kind: string
  public readonly original?: any
  constructor(public readonly timeoutMs: number, opts?: { kind?: string; original?: any }) {
    const kind = opts?.kind || 'timeout'
    const original = opts?.original
    const origMsg = original?.message ? String(original.message) : (original ? String(original) : '')
    super(`Planner timeout (${kind}) after ${timeoutMs}ms${origMsg ? `: ${origMsg}` : ''}`)
    this.name = 'PlannerTimeoutError'
    this.kind = kind
    this.original = original
    try { (this as any).cause = original } catch { }
  }
}

function sleep(ms: number) { return new Promise(resolve => setTimeout(resolve, ms)) }

function oneLine(s: any, maxLen = 260): string {
  const str = String(s ?? '').replace(/\s+/g, ' ').trim()
  if (!str) return ''
  return str.length > maxLen ? `${str.slice(0, maxLen)}...(len=${str.length})` : str
}

function getStatusCodeLike(e: any): number | undefined {
  const raw = e?.statusCode ?? e?.status ?? e?.response?.status ?? e?.error?.status ?? e?.error?.statusCode
  const n = typeof raw === 'number' ? raw : Number(raw)
  return Number.isFinite(n) ? n : undefined
}

function getErrCodeLike(e: any): string | undefined {
  const c = e?.code ?? e?.error?.code ?? e?.cause?.code
  return c ? String(c) : undefined
}

function summarizeAnyError(e: any): string {
  if (!e) return 'unknown'
  const status = getStatusCodeLike(e)
  const name = e?.name ? String(e.name) : undefined
  const code = getErrCodeLike(e)
  const msg = oneLine(e?.message ?? e)
  const parts: string[] = []
  if (status) parts.push(`status=${status}`)
  if (name) parts.push(`name=${name}`)
  if (code) parts.push(`code=${code}`)
  if (msg) parts.push(`msg=${msg}`)
  return parts.join(', ') || oneLine(e)
}

function summarizePlannerTimeoutReason(e: any): string {
  if (e instanceof PlannerTimeoutError) {
    const orig = e.original ? summarizeAnyError(e.original) : ''
    return [`kind=${e.kind}`, `timeout=${Math.round(e.timeoutMs / 1000)}s`, orig ? `original={${orig}}` : '']
      .filter(Boolean)
      .join(', ')
  }
  return summarizeAnyError(e)
}

function isLikelySdkOrNetworkTimeout(e: any): boolean {
  const status = getStatusCodeLike(e)
  if (status && (status === 504 || status === 503 || status === 502 || status === 500)) return true
  const name = String(e?.name ?? '')
  if (name === 'TimeoutError' || name === 'AbortError') return true
  const code = String(getErrCodeLike(e) ?? '')
  if (code === 'ETIMEDOUT' || code === 'ESOCKETTIMEDOUT' || code === 'ECONNRESET') return true
  const msg = String(e?.message ?? '')
  if (/timeout|timed out|ETIMEDOUT|ESOCKETTIMEDOUT/i.test(msg)) return true
  if (/\b504\b/.test(msg)) return true
  return false
}

async function aiStreamTextWithIdleTimeout(params: {
  model: any
  system?: string
  messages: CoreMessage[]
  temperature?: number
  topP?: number
  providerOptions?: any
  idleTimeoutMs: number
  parentSignal?: AbortSignal
}): Promise<{ text: string }> {
  const { model, system, messages, temperature, topP, providerOptions, idleTimeoutMs, parentSignal } = params

  const ac = new AbortController()
  let timer: any
  let accumulatedText = ''
  let streamStarted = false

  const onParentAbort = () => { try { ac.abort() } catch { } }
  if (parentSignal) {
    if (parentSignal.aborted) throw new Error('Aborted by parent signal')
    parentSignal.addEventListener('abort', onParentAbort, { once: true })
  }

  const resetWatchdog = () => {
    if (timer) clearTimeout(timer)
    timer = setTimeout(() => {
      try { ac.abort() } catch { }
    }, idleTimeoutMs)
  }

  try {
    resetWatchdog()

    const callSignal = mergeAbortSignals([ac.signal, parentSignal])
    const result = streamText({
      model,
      system,
      messages,
      temperature,
      topP,
      providerOptions,
      abortSignal: callSignal,
    })

    streamStarted = true

    for await (const part of (result as any).fullStream as AsyncIterable<any>) {
      if (part?.type === 'text-delta') {
        resetWatchdog()
        // ÂÖ≥ÈîÆÊîπÂä®: ai-sdk ËøîÂõûÁöÑÊòØ textDelta ËÄå‰∏çÊòØ text
        accumulatedText += String(part.textDelta ?? '')
      }
    }

    clearTimeout(timer)
    return { text: accumulatedText }
  }
  catch (e: any) {
    clearTimeout(timer)
    if (parentSignal?.aborted) throw e
    if (ac.signal.aborted) {
      const kind = streamStarted ? 'stream_idle_timeout' : 'connection_timeout'
      throw new PlannerTimeoutError(idleTimeoutMs, { kind, original: e })
    }
    if (isLikelySdkOrNetworkTimeout(e)) {
      throw new PlannerTimeoutError(idleTimeoutMs, { kind: 'network_error', original: e })
    }
    throw e
  }
  finally {
    clearTimeout(timer)
    parentSignal?.removeEventListener?.('abort', onParentAbort as any)
  }
}

async function aiGenerateJsonWithTimeoutRetry(params: {
  model: any
  system: string
  user: string
  timeoutsMs?: number[]
  parentSignal?: AbortSignal
  providerOptions?: any
  validator?: (text: string) => void | Promise<void>
  onTimeoutRetry?: (info: {
    attempt: number
    timeoutMs: number
    nextAttempt: number
    nextTimeoutMs: number
    reason: string
    error: any
  }) => void
}): Promise<string> {
  const { model, system, user, parentSignal, onTimeoutRetry, validator, providerOptions } = params

  const timeoutsMsRaw = (params.timeoutsMs?.length ? params.timeoutsMs : [20_000, 30_000, 40_000])
    .map(n => Number(n))
    .filter(n => Number.isFinite(n) && n > 0)

  const timeoutsMs = timeoutsMsRaw.length ? timeoutsMsRaw : [20_000]
  const totalAttempts = timeoutsMs.length

  let lastErr: any

  for (let attempt = 1; attempt <= totalAttempts; attempt++) {
    const idleTimeoutMs = timeoutsMs[attempt - 1]
    try {
      const { text } = await aiStreamTextWithIdleTimeout({
        model,
        system,
        messages: [
          { role: 'user', content: user },
        ],
        temperature: 0,
        providerOptions,
        idleTimeoutMs,
        parentSignal,
      })

      if (validator) await validator(text)
      return text
    }
    catch (e: any) {
      lastErr = e
      if (parentSignal?.aborted) throw e
      if (attempt >= totalAttempts) throw e

      const nextAttempt = attempt + 1
      const nextTimeoutMs = timeoutsMs[nextAttempt - 1]
      const reason = summarizePlannerTimeoutReason(e)

      onTimeoutRetry?.({ attempt, timeoutMs: idleTimeoutMs, nextAttempt, nextTimeoutMs, reason, error: e })
      await sleep(250 * Math.pow(2, attempt - 1))
    }
  }

  throw lastErr
}

function parseTimeoutScheduleToMs(input: any): number[] | null {
  if (!input) return null
  const s = String(input).trim()
  if (!s) return null
  const parts = s.split(/[,Ôºå]/).map(x => x.trim()).filter(Boolean)
  const nums = parts.map(p => Number(p)).filter(n => Number.isFinite(n) && n > 0)
  if (!nums.length) return null
  const allLooksLikeSeconds = nums.every(n => n <= 300)
  const out = allLooksLikeSeconds ? nums.map(n => Math.round(n * 1000)) : nums.map(n => Math.round(n))
  return out.filter(n => n > 0)
}

async function buildConversationContext(lastMessageId: string | undefined, maxCount: number): Promise<string> {
  if (!lastMessageId) return ''
  const messages: string[] = []
  let currentId = lastMessageId
  for (let i = 0; i < maxCount; i++) {
    if (!currentId) break
    const msg = await getMessageById(currentId)
    if (!msg) break
    const role = msg.role === 'assistant' ? 'AI' : 'User'
    let content = ''
    if (typeof msg.text === 'string') content = msg.text
    else if (Array.isArray(msg.text)) content = msg.text.map((p: any) => p?.type === 'text' ? p.text : '[Image]').join('')
    else content = '[Complex Content]'
    messages.push(`${role}: ${content}`)
    currentId = msg.parentMessageId
  }
  return messages.reverse().join('\n')
}

function formatSearchRoundsForPlanner(rounds: SearchRound[]): string {
  if (!rounds.length) return 'ÔºàÊó†Ôºâ'
  return rounds.map((r, idx) => {
    const items = (r.items || []).map((it, i) =>
      `- [${idx + 1}.${i + 1}] ${String(it.title || '').trim()}\n  ${String(it.url || '').trim()}\n  ÂÜÖÂÆπ: ${String(it.content || '').replace(/\s+/g, ' ').trim()}`
    ).join('\n\n')
    const note = r.note ? `\nÔºàÊ≥®Ôºö${r.note}Ôºâ` : ''
    return `### Á¨¨${idx + 1}ËΩÆ query="${r.query}"\n${items || 'ÔºàÊó†ÁªìÊûúÔºâ'}${note}`
  }).join('\n\n')
}

async function planNextSearchAction(params: {
  plannerModel: any
  userQuestion: string
  rounds: SearchRound[]
  fullContext: string
  priorContextSummary: string | null
  date: string
  abortSignal?: AbortSignal
  timeoutScheduleMs?: number[]
  onTimeoutRetry?: (info: { attempt: number; timeoutMs: number; nextAttempt: number; nextTimeoutMs: number; reason: string; error: any }) => void
}): Promise<SearchPlan> {
  const {
    plannerModel,
    userQuestion,
    rounds,
    fullContext,
    priorContextSummary,
    date,
    abortSignal,
    timeoutScheduleMs,
    onTimeoutRetry,
  } = params

  const isFirstRound = !priorContextSummary
  const plannerSystem = [
    '‰Ω†ÊòØ"ËÅîÁΩëÊêúÁ¥¢ËßÑÂàíÂô® & ÁªìÊûúÁ≠õÈÄâÂô®"„ÄÇ‰Ω†ÁöÑ‰ªªÂä°ÊòØÂçèÂä©ÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢ò„ÄÇ',
    '',
    `ÂΩìÂâçÊó∂Èó¥Ôºö${date}`,
    '',
    '‰ªªÂä°Ôºö',
    '1. È¶ñÂÖàÂà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅËÅîÁΩëÊêúÁ¥¢„ÄÇ**ËøôÊòØÊúÄÈáçË¶ÅÁöÑÂÜ≥Á≠ñ„ÄÇ**',
    '2. ËØÑ‰º∞"Â∑≤ËøõË°åÁöÑÊêúÁ¥¢‰∏éÁªìÊûú"ÔºåÈÄâÂá∫ÂØπÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢òÊúâ‰ª∑ÂÄºÁöÑÊù°ÁõÆID (Ê†ºÂºèÂ¶Ç "1.1", "2.3")„ÄÇ',
    '',
    '„ÄêÂÜ≥Á≠ñÈÄªËæë„Äë',
    '- **ÂøÖÈ°ªÊêúÁ¥¢**ÔºöÈóÆÈ¢òÊ∂âÂèäËøëÊúüÊñ∞Èóª„ÄÅÁâπÂÆö‰∫ãÂÆûÊü•ËØÅÔºàÂ§©Ê∞î„ÄÅËÇ°‰ª∑Á≠âÔºâ„ÄÅÈùûÂ∏∏ËØÜÊÄßÂÖ∑‰ΩìÊï∞ÊçÆÔºå‰∏î‰∏ä‰∏ãÊñá‰∏≠Ê≤°Êúâ„ÄÇ',
    '- **Á¶ÅÊ≠¢ÊêúÁ¥¢ (action="stop")**Ôºö',
    '  - Á∫ØÈó≤ËÅäÔºàÂ¶Ç‚Äú‰Ω†Â•Ω‚Äù„ÄÅ‚Äú‰Ω†ÊòØË∞Å‚ÄùÔºâ„ÄÇ',
    '  - Â∏∏ËØÜÊÄßÈóÆÈ¢òÔºàÂ¶Ç‚ÄúÂ§™Èò≥‰ªéÂì™ÂçáËµ∑‚Äù„ÄÅ‚Äú1+1Á≠â‰∫éÂá†‚ÄùÔºâ„ÄÇ',
    '  - ÈÄªËæëÊé®ÁêÜ„ÄÅÊï∞Â≠¶ËÆ°ÁÆó„ÄÅ‰ª£Á†ÅÁºñÂÜô„ÄÅÁøªËØë„ÄÅÊ∂¶Ëâ≤‰ªªÂä°„ÄÇ',
    '  - **‰∏ä‰∏ãÊñáÂ∑≤ÂåÖÂê´Á≠îÊ°à**ÔºöÁî®Êà∑ÈóÆÈ¢òÊòØÈíàÂØπÂéÜÂè≤ÂØπËØùÁöÑËøΩÈóÆÔºå‰∏îÂéÜÂè≤‰ø°ÊÅØÂ∑≤Ë∂≥Â§üÂõûÁ≠î„ÄÇ',
    '',
    'Â¶ÇÊûúÂÜ≥ÂÆöÊêúÁ¥¢Ôºöaction="search"ÔºåÂπ∂ÁªôÂá∫ query„ÄÇ',
    'Â¶ÇÊûúÊó†ÈúÄÊêúÁ¥¢Êàñ‰ø°ÊÅØÂ∑≤Ë∂≥Ôºöaction="stop"ÔºàÊ≠§Êó∂ selected_ids ‰æùÁÑ∂ÂèØ‰ª•ËøîÂõûÂ∑≤ÊúâÁªìÊûúÁöÑIDÔºåÂ¶ÇÊûúÊ≤°ÊúâÁªìÊûúÂàô‰∏∫Á©∫Êï∞ÁªÑÔºâ„ÄÇ',
    '',
    isFirstRound
      ? '3. ËØ∑Âä°ÂøÖÈòÖËØªÂÆåÊï¥ÁöÑÂØπËØù‰∏ä‰∏ãÊñáÔºåÂπ∂ÁîüÊàê‰∏Ä‰∏™Á≤æÁÇºÁöÑ"context_summary"Ôºà100-200Â≠óÔºâÔºåÊ¶ÇÊã¨ÂéÜÂè≤ÂØπËØùÁöÑÊ†∏ÂøÉÊÑèÂõæÂíåÂÖ≥ÈîÆ‰ø°ÊÅØÔºå‰ª•‰æøÂêéÁª≠ËΩÆÊ¨°‰ΩøÁî®„ÄÇ'
      : '3. ÂèÇËÄÉÊèê‰æõÁöÑ "context_summary" Êù•ÁêÜËß£Áî®Êà∑ÊÑèÂõæÔºà‰∏çÂÜçÊèê‰æõÂÆåÊï¥‰∏ä‰∏ãÊñáÔºâ„ÄÇ',
    '',
    'ËæìÂá∫‰∏•Ê†º JSONÔºö',
    '{',
    '  "action": "search" | "stop",',
    '  "query": string,',
    '  "reason": string,',
    '  "selected_ids": string[],',
    isFirstRound ? '  "context_summary": string' : null,
    '}'.replace(/, null/g, ''),
    'ËØ∑Âè™ËøîÂõûÁ∫Ø JSON Â≠óÁ¨¶‰∏≤Ôºå‰∏çË¶ÅÂåÖÂê´ Markdown Ê†ºÂºèÔºàÂ¶Ç ```json ... ```Ôºâ„ÄÇ'
  ].filter(Boolean).join('\n')

  const contextBlock = isFirstRound
    ? `„ÄêÂÆåÊï¥ÂØπËØù‰∏ä‰∏ãÊñáÔºàËØ∑ÊÄªÁªìÁîüÊàê context_summaryÔºâ„Äë\n${fullContext || 'ÔºàÊó†Ôºâ'}`
    : `„ÄêÂéÜÂè≤‰∏ä‰∏ãÊñáÊÄªÁªì (context_summary)„Äë\n${priorContextSummary}`

  const plannerUser = [
    '„ÄêÁî®Êà∑ÈóÆÈ¢ò„Äë', userQuestion,
    '',
    contextBlock,
    '',
    '„ÄêÂ∑≤ËøõË°åÁöÑÊêúÁ¥¢‰∏éÁªìÊûú„Äë',
    formatSearchRoundsForPlanner(rounds),
    '',
    'Áé∞Âú®ËØ∑ÂÜ≥ÂÆöÔºöselected_ids ÊòØÂì™‰∫õÔºüÊòØÂê¶ÈúÄË¶ÅÁªßÁª≠ÊêúÁ¥¢Ôºü' + (isFirstRound ? ' ËÆ∞ÂæóÁîüÊàê context_summary„ÄÇ' : '')
  ].join('\n')

  const schedule = (timeoutScheduleMs && timeoutScheduleMs.length ? timeoutScheduleMs : [20_000, 30_000, 40_000])

  const jsonText = await aiGenerateJsonWithTimeoutRetry({
    model: plannerModel,
    system: plannerSystem,
    user: plannerUser,
    timeoutsMs: schedule,
    parentSignal: abortSignal,
    validator: async (text) => {
      const parsed = safeParseJsonFromText(text)
      if (!parsed)
        throw new Error(`JSON parsing failed (len=${text.length}, preview=${trunc(text, 50)})`)
      if (!parsed.action)
        throw new Error('Invalid JSON: missing "action" field')
    },
    onTimeoutRetry,
  })

  return safeParseJsonFromText(jsonText) as SearchPlan
}

async function runIterativeWebSearch(params: {
  plannerModel: any
  userQuestion: string
  maxRounds: number
  maxResults: number
  abortSignal?: AbortSignal
  provider?: 'searxng' | 'tavily'
  searxngApiUrl?: string
  tavilyApiKey?: string
  onProgress?: (status: string) => void
  fullContext: string
  date: string
  plannerTimeoutScheduleMs?: number[]
}): Promise<{ rounds: SearchRound[]; selectedIds: Set<string>; planFailed: boolean }> {
  const {
    plannerModel,
    userQuestion,
    maxRounds,
    maxResults,
    abortSignal,
    provider,
    searxngApiUrl,
    tavilyApiKey,
    onProgress,
    fullContext,
    date,
    plannerTimeoutScheduleMs,
  } = params

  const rounds: SearchRound[] = []
  const usedQueries = new Set<string>()
  const selectedIds = new Set<string>()

  let currentContextSummary: string | null = null
  const schedule = (plannerTimeoutScheduleMs && plannerTimeoutScheduleMs.length ? plannerTimeoutScheduleMs : [20_000, 30_000, 40_000])
  let planFailed = false

  for (let i = 0; i < maxRounds; i++) {
    if (i === 0) onProgress?.('‚è≥ Ê≠£Âú®ÂàÜÊûêÁî®Êà∑ÊÑèÂõæÔºåËßÑÂàíÊêúÁ¥¢Á≠ñÁï•...')

    let plan: SearchPlan | null = null
    let lastPlanError: any = null

    try {
      plan = await planNextSearchAction({
        plannerModel,
        userQuestion,
        rounds,
        abortSignal,
        fullContext,
        priorContextSummary: currentContextSummary,
        date,
        timeoutScheduleMs: schedule,
        onTimeoutRetry: ({ attempt, timeoutMs, nextAttempt, nextTimeoutMs, reason }) => {
          onProgress?.(
            `‚ö†Ô∏è ËßÑÂàíÂô®Á¨¨ ${attempt} Ê¨°ËØ∑Ê±ÇÂ§±Ë¥•ÔºàÁ©∫Èó≤Ë∂ÖÊó∂/Ê†°È™åÂ§±Ë¥• >${Math.round(timeoutMs / 1000)}sÔºâÔºå` +
            `Ê≠£Âú®ÈáçËØïÁ¨¨ ${nextAttempt} Ê¨°ÔºàË∂ÖÊó∂ÈòàÂÄº=${Math.round(nextTimeoutMs / 1000)}sÔºâ...\n` +
            `   ÂéüÂõ†Ôºö${reason}`
          )
        },
      })
    }
    catch (e) {
      lastPlanError = e
      if (API_DEBUG) debugLog('[SearchPlanner] failed:', (e as any)?.message ?? e)
    }

    if (!plan) {
      planFailed = true
      const reason = lastPlanError ? summarizeAnyError(lastPlanError instanceof PlannerTimeoutError ? lastPlanError.original ?? lastPlanError : lastPlanError) : ''
      onProgress?.(`‚ùå ËßÑÂàíÊúçÂä°ÊöÇÊó∂‰∏çÂèØÁî®ÔºåÊµÅÁ®ãÁªìÊùü„ÄÇ${reason ? `\n   ÂéüÂõ†Ôºö${reason}` : ''}`)
      break
    }

    if (plan.context_summary && typeof plan.context_summary === 'string')
      currentContextSummary = plan.context_summary
    if (Array.isArray(plan.selected_ids))
      plan.selected_ids.forEach(id => selectedIds.add(String(id).trim()))

    const reasonText = plan.reason ? `(ÁêÜÁî±: ${plan.reason})` : ''

    if (plan.action !== 'search') {
      if (i === 0) onProgress?.(`üõë Ê®°ÂûãÂà§Êñ≠Êó†ÈúÄÊêúÁ¥¢ ${reasonText}`)
      else onProgress?.(`‚úÖ ‰ø°ÊÅØÊî∂ÈõÜÂÆåÊØï ${reasonText}`)
      break
    }

    const q = String(plan.query || '').trim()
    if (!q) break

    if (usedQueries.has(q)) {
      onProgress?.(`‚ö†Ô∏è ÂÖ≥ÈîÆËØç„Äå${q}„ÄçÂ∑≤‰ΩøÁî®ËøáÔºåË∑≥ËøáÈáçÂ§çÊêúÁ¥¢...`)
      break
    }
    usedQueries.add(q)

    onProgress?.(`üîç Ê≠£Âú®ÊêúÁ¥¢Ôºö„Äå${q}„Äç\n   üß† ${reasonText}`)

    try {
      const r = await webSearch(q, { maxResults, signal: abortSignal, provider, searxngApiUrl, tavilyApiKey })
      const items = (r.results || []).slice(0, maxResults).map(it => ({
        title: String(it.title || ''),
        url: String(it.url || ''),
        content: removeImagesFromText(String(it.content || '')),
      }))
      rounds.push({ query: q, items })
      onProgress?.(`üìÑ ÊêúÁ¥¢ÊàêÂäüÔºåËé∑ÂèñÂà∞ ${items.length} ‰∏™È°µÈù¢ÔºåÊ≠£Âú®Âà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅËøõ‰∏ÄÊ≠•ÊêúÁ¥¢...`)
    }
    catch (e: any) {
      const errMsg = e?.message ?? String(e)
      console.error(`[WebSearch][Round ${i + 1}] Search failed for query "${q}":`, errMsg)
      rounds.push({ query: q, items: [], note: errMsg })
      onProgress?.(`‚ùå ÊêúÁ¥¢ËØ∑Ê±ÇÂ§±Ë¥•Ôºö${errMsg}`)
      break
    }
  }

  return { rounds, selectedIds, planFailed }
}

function formatAggregatedSearchForAnswer(rounds: SearchRound[]): string {
  if (!rounds.length) return ''
  let n = 0
  const lines: string[] = []
  const refLines: string[] = []
  lines.push('„ÄêËÅîÁΩëÊêúÁ¥¢ÁªìÊûúÔºàÂ∑≤Á≠õÈÄâÔºâ„Äë')
  rounds.forEach((r, idx) => {
    if (!r.items?.length) return
    lines.push(`ÔºàÁõ∏ÂÖ≥Êù•Ê∫êÔºö${r.query}Ôºâ`)
    for (const it of r.items) {
      n++
      lines.push(`[${n}] ${String(it.title || '').trim()}`)
      lines.push(`URL: ${String(it.url || '').trim()}`)
      lines.push(`ÂÜÖÂÆπ: ${String(it.content || '').trim()}`)
      lines.push('')
      refLines.push(`[${n}] ${String(it.title || '').trim()} - ${String(it.url || '').trim()}`)
    }
  })
  if (n === 0) return ''

  lines.push('')
  lines.push('„ÄêÂèÇËÄÉÊù•Ê∫êÂàóË°®„Äë')
  lines.push(...refLines)
  lines.push('')
  lines.push('„ÄêÂõûÁ≠îË¶ÅÊ±Ç„Äë')
  lines.push('- Âü∫‰∫é‰ª•‰∏äÊù•Ê∫êÂõûÁ≠îÁî®Êà∑ÈóÆÈ¢ò„ÄÇ')
  lines.push('- ÂºïÁî®Ê†ºÂºèÂøÖÈ°ª‰∏∫ markdown ÈìæÊé•Ôºö[ÁºñÂè∑](url)Ôºå‰æãÂ¶Ç [1](https://example.com)„ÄÇ')
  lines.push('- ÂèØ‰ª•ÂêåÊó∂ÂºïÁî®Â§ö‰∏™Êù•Ê∫êÔºåÁî®ÈÄóÂè∑ÂàÜÈöîÔºö[1](url1), [2](url2)„ÄÇ')
  lines.push('- Âú®ÂõûÁ≠îÊú´Â∞æÔºåÂàóÂá∫ÊâÄÊúâÂºïÁî®ËøáÁöÑÂèÇËÄÉÊù•Ê∫êÔºåÊ†ºÂºèÔºö')
  lines.push('  ## ÂèÇËÄÉÊù•Ê∫ê')
  lines.push('  - [Ê†áÈ¢ò](url)')
  lines.push('- Ëã•Êù•Ê∫ê‰∏çË∂≥‰ª•ÊîØÊåÅÁªìËÆ∫ÔºåËØ∑ÊòéÁ°ÆËØ¥Êòé„ÄÇ')
  return lines.join('\n')
}

function appendTextToMessageContent(content: MessageContent, appendix: string): MessageContent {
  if (!appendix?.trim()) return content
  if (typeof content === 'string') return `${content}\n\n${appendix}`
  if (Array.isArray(content)) {
    const idx = (content as any[]).findIndex(p => p?.type === 'text' && typeof p?.text === 'string')
    if (idx >= 0) {
      const arr = [...(content as any[])]
      arr[idx] = { ...(arr[idx] || {}), text: `${arr[idx].text}\n\n${appendix}` }
      return arr as any
    }
    return [{ type: 'text', text: appendix }, ...(content as any[])] as any
  }
  return content
}
// ===================== ËÅîÁΩëÊêúÁ¥¢ END =====================

const ErrorCodeMessage: Record<string, string> = {
  401: 'Êèê‰æõÈîôËØØÁöÑAPIÂØÜÈí•',
  403: 'ÊúçÂä°Âô®ÊãíÁªùËÆøÈóÆÔºåËØ∑Á®çÂêéÂÜçËØï',
  502: 'ÈîôËØØÁöÑÁΩëÂÖ≥',
  503: 'ÊúçÂä°Âô®ÁπÅÂøôÔºåËØ∑Á®çÂêéÂÜçËØï',
  504: 'ÁΩëÂÖ≥Ë∂ÖÊó∂',
  500: 'ÊúçÂä°Âô®ÁπÅÂøôÔºåËØ∑Á®çÂêéÂÜçËØï',
}

let auditService: TextAuditService
const _lockedKeys: { key: string; lockedTime: number }[] = []

const DATA_URL_IMAGE_CAPTURE_RE = /data:(image\/[a-zA-Z0-9.+-]+);base64,([A-Za-z0-9+/=]+)/g
const MARKDOWN_IMAGE_RE = /!$$[^$$]*\]\s*$[^)]+?$\s*$/g
const UPLOADS_URL_RE = /(\/uploads\/[^)\s>"']+\.(?:png|jpe?g|webp|gif|bmp|heic))/gi
const HTML_IMAGE_RE = /<img[^>]*\ssrc=["']([^"']+)["'][^>]*>/gi

async function replaceDataUrlImagesWithUploads(text: string): Promise<{ text: string; saved: Array<{ mime: string; filename: string; bytes: number }> }> {
  if (!text) return { text: '', saved: [] }
  const saved: Array<{ mime: string; filename: string; bytes: number }> = []
  let out = ''
  let lastIndex = 0
  const matches = text.matchAll(DATA_URL_IMAGE_CAPTURE_RE)
  for (const m of matches) {
    const full = m[0]
    const mime = m[1]
    const base64 = m[2]
    const idx = m.index ?? -1
    if (idx < 0) continue
    out += text.slice(lastIndex, idx)
    const buffer = Buffer.from(base64, 'base64')
    const ext = mime.split('/')[1] || 'png'
    const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`
    const filePath = path.join(UPLOAD_DIR, filename)
    await fs.writeFile(filePath, buffer)
    saved.push({ mime, filename, bytes: buffer.length })
    out += `/uploads/${filename}`
    lastIndex = idx + full.length
  }
  out += text.slice(lastIndex)
  return { text: out, saved }
}

type SavedUpload = { mime: string; filename: string; bytes: number }
type DataUrlCache = Map<string, string>

function parseDataUrlImage(dataUrl: string): { mime: string; base64: string } | null {
  const m = /^data:(image\/[a-zA-Z0-9.+-]+);base64,([A-Za-z0-9+/=\s]+)$/.exec(dataUrl)
  if (!m) return null
  return { mime: m[1] || 'image/png', base64: (m[2] || '').replace(/\s+/g, '') || null } as any
}
function mimeToExt(mime: string): string {
  const t = (mime || '').toLowerCase()
  if (t === 'image/jpeg' || t === 'image/jpg') return 'jpg'
  if (t === 'image/png') return 'png'
  if (t === 'image/webp') return 'webp'
  if (t === 'image/gif') return 'gif'
  if (t === 'image/bmp') return 'bmp'
  if (t === 'image/heic') return 'heic'
  return t.split('/')[1] || 'png'
}

async function saveDataUrlImageToUploads(dataUrl: string, cache?: DataUrlCache): Promise<{ url: string; saved: SavedUpload } | null> {
  try {
    if (!dataUrl?.startsWith('data:image/')) return null
    if (cache?.has(dataUrl)) {
      const url = cache.get(dataUrl)!
      return { url, saved: { mime: 'image/*', filename: path.basename(url), bytes: 0 } }
    }
    const parsed = parseDataUrlImage(dataUrl)
    if (!parsed) return null
    await ensureUploadDir()
    const buffer = Buffer.from(parsed.base64, 'base64')
    const ext = mimeToExt(parsed.mime)
    const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`
    const filePath = path.join(UPLOAD_DIR, filename)
    await fs.writeFile(filePath, buffer)
    const url = `/uploads/${filename}`
    cache?.set(dataUrl, url)
    return { url, saved: { mime: parsed.mime, filename, bytes: buffer.length } }
  }
  catch (e) {
    globalThis.console.error('[saveDataUrlImageToUploads] failed:', e)
    return null
  }
}

async function normalizeMessageContentDataUrlsToUploads(content: MessageContent, cache?: DataUrlCache): Promise<{ content: MessageContent; saved: SavedUpload[] }> {
  const savedAll: SavedUpload[] = []
  if (typeof content === 'string') {
    const replaced = await replaceDataUrlImagesWithUploads(content)
    savedAll.push(...replaced.saved)
    return { content: replaced.text, saved: savedAll }
  }
  if (Array.isArray(content)) {
    const newParts: any[] = []
    for (const p of content as any[]) {
      if (p?.type === 'text' && typeof p.text === 'string') {
        const replaced = await replaceDataUrlImagesWithUploads(p.text)
        savedAll.push(...replaced.saved)
        newParts.push({ ...p, text: replaced.text })
        continue
      }
      if (p?.type === 'image_url' && typeof p.image_url?.url === 'string') {
        const u = p.image_url.url as string
        if (u.startsWith('data:image/')) {
          const r = await saveDataUrlImageToUploads(u, cache)
          if (r?.url) {
            savedAll.push(r.saved)
            newParts.push({ ...p, image_url: { ...p.image_url, url: r.url } })
            continue
          }
        }
        newParts.push(p)
        continue
      }
      newParts.push(p)
    }
    return { content: newParts as any, saved: savedAll }
  }
  return { content, saved: savedAll }
}

async function normalizeUrlsDataUrlsToUploads(urls: string[], cache?: DataUrlCache): Promise<{ urls: string[]; saved: SavedUpload[] }> {
  const out: string[] = []
  const savedAll: SavedUpload[] = []
  for (const u of urls || []) {
    if (typeof u === 'string' && u.startsWith('data:image/')) {
      const r = await saveDataUrlImageToUploads(u, cache)
      if (r?.url) {
        out.push(r.url)
        savedAll.push(r.saved)
      }
      else {
        out.push(u)
      }
    }
    else {
      out.push(u)
    }
  }
  return { urls: out, saved: savedAll }
}

function shortUrlForLog(u: string): string {
  if (!u) return ''
  if (u.startsWith('data:image/')) {
    return `dataUrl(${u.match(/^data:(image\/[a-zA-Z0-9.+-]+);base64,/)?.[1] ?? 'image/*'},len=${u.length})`
  }
  return u.length > 200 ? `${u.slice(0, 200)}...(len=${u.length})` : u
}

function extractImageUrlsFromText(text: string): { cleanedText: string; urls: string[] } {
  if (!text) return { cleanedText: '', urls: [] }
  const urls: string[] = []
  let cleaned = text

  cleaned = cleaned.replace(MARKDOWN_IMAGE_RE, (_m, inside) => {
    const raw = String(inside ?? '').trim()
    if (raw) {
      const url = raw.split(/\s+/)[0]?.replace(/^<|>$/g, '').trim()
      if (url) urls.push(url)
    }
    return '[Image]'
  })
  cleaned = cleaned.replace(HTML_IMAGE_RE, (_m, url) => {
    if (url) urls.push(url)
    return '[Image]'
  })
  const rawDataUrls = cleaned.match(DATA_URL_IMAGE_RE)
  if (rawDataUrls?.length) urls.push(...rawDataUrls)
  cleaned = cleaned.replace(DATA_URL_IMAGE_RE, '[Image]')

  const uploadUrls = cleaned.match(UPLOADS_URL_RE)
  if (uploadUrls?.length) urls.push(...uploadUrls)
  cleaned = cleaned.replace(UPLOADS_URL_RE, '[Image]')

  return { cleanedText: cleaned, urls }
}

async function extractImageUrlsFromMessageContent(content: MessageContent): Promise<{ cleanedText: string; urls: string[] }> {
  const urls: string[] = []
  let cleanedText = ''
  if (typeof content === 'string') {
    const r = extractImageUrlsFromText(content)
    cleanedText = r.cleanedText
    urls.push(...r.urls)
    if (!cleanedText?.trim() && urls.length) cleanedText = '[Image]'
    return { cleanedText, urls }
  }
  if (Array.isArray(content)) {
    for (const p of content as any[]) {
      if (p?.type === 'text' && p.text) {
        const r = extractImageUrlsFromText(p.text)
        if (r.cleanedText) cleanedText += (cleanedText ? '\n' : '') + r.cleanedText
        if (r.urls.length) urls.push(...r.urls)
      }
      else if (p?.type === 'image_url' && p.image_url?.url) {
        urls.push(p.image_url.url)
        cleanedText += (cleanedText ? '\n' : '') + '[Image]'
      }
    }
    if (!cleanedText?.trim() && urls.length) cleanedText = '[Image]'
    return { cleanedText, urls }
  }
  return { cleanedText: '', urls: [] }
}

function dedupeUrlsPreserveOrder(urls: string[]): string[] {
  const seen = new Set<string>()
  const out: string[] = []
  for (const u of urls) {
    if (!u || seen.has(u)) continue
    seen.add(u)
    out.push(u)
  }
  return out
}

type ImageBinding = { tag: string; source: 'current_user' | 'last_ai' | 'prev_user' | 'prev_ai'; url: string }
type HistoryMessageMeta = { role: 'user' | 'model'; cleanedText: string; urls: string[]; messageId: string }

function applyImageBindingsToCleanedText(cleanedText: string, urls: string[], bindings: ImageBinding[]): string {
  const map = new Map<string, string>()
  for (const b of bindings) map.set(b.url, b.tag)
  let out = cleanedText || ''
  for (const u of urls) {
    const tag = map.get(u)
    out = out.replace('[Image]', tag ? `[${tag}]` : '[Image]')
  }
  if (!out.trim() && urls.length) out = urls.map(u => (map.get(u) ? `[${map.get(u)}]` : '[Image]')).join(' ')
  return out
}

async function buildGeminiHistoryFromLastMessageId(params: {
  lastMessageId?: string
  maxContextCount: number
  forGeminiImageModel: boolean
}): Promise<{ metas: HistoryMessageMeta[]; allUrls: string[] }> {
  const { lastMessageId: startId, maxContextCount, forGeminiImageModel } = params
  const metasRev: HistoryMessageMeta[] = []
  const urlsRev: string[] = []
  let lastMessageId = startId
  for (let i = 0; i < maxContextCount; i++) {
    if (!lastMessageId) break
    const msg = await getMessageById(lastMessageId)
    if (!msg) break
    const role = (msg.role === 'assistant' ? 'model' : 'user') as 'user' | 'model'
    if (forGeminiImageModel) {
      const { cleanedText, urls } = await extractImageUrlsFromMessageContent(msg.text)
      if (urls.length) urlsRev.push(...urls)
      metasRev.push({
        role,
        cleanedText: cleanedText?.trim() ? cleanedText : (urls.length ? '[Image]' : '[Empty]'),
        urls,
        messageId: msg.id,
      })
    }
    else {
      metasRev.push({
        role,
        cleanedText: typeof msg.text === 'string' ? msg.text : '[Complex Content]',
        urls: [],
        messageId: msg.id,
      })
    }
    lastMessageId = msg.parentMessageId
  }
  return { metas: metasRev.reverse(), allUrls: dedupeUrlsPreserveOrder(urlsRev.reverse()) }
}

function getLastNByRole(metas: HistoryMessageMeta[], role: 'user' | 'model', n: number): HistoryMessageMeta[] {
  const out: HistoryMessageMeta[] = []
  for (let i = metas.length - 1; i >= 0; i--) {
    if (metas[i].role !== role) continue
    out.push(metas[i])
    if (out.length >= n) break
  }
  return out
}

function selectRecentTwoRoundsImages(metas: HistoryMessageMeta[], currentUrls: string[]): ImageBinding[] {
  const lastModels = getLastNByRole(metas, 'model', 2)
  const lastUsers = getLastNByRole(metas, 'user', 1)
  const groups = [
    { source: 'current_user' as const, tagPrefix: 'U0', urls: currentUrls },
    { source: 'last_ai' as const, tagPrefix: 'A0', urls: lastModels[0]?.urls ?? [] },
    { source: 'prev_user' as const, tagPrefix: 'U1', urls: lastUsers[0]?.urls ?? [] },
    { source: 'prev_ai' as const, tagPrefix: 'A1', urls: lastModels[1]?.urls ?? [] },
  ]
  const seen = new Set<string>()
  const bindings: ImageBinding[] = []
  for (const g of groups) {
    let idx = 0
    for (const u of g.urls) {
      if (!u || seen.has(u)) continue
      seen.add(u)
      idx += 1
      bindings.push({ tag: `${g.tagPrefix}_${idx}`, source: g.source, url: u })
    }
  }
  return bindings
}

const IMAGE_SOURCE_LABEL: Record<ImageBinding['source'], string> = {
  current_user: 'Êú¨Ê¨°Áî®Êà∑Ê∂àÊÅØ',
  last_ai: 'ÊúÄËøë‰∏ÄÊù°AIÂõûÂ§ç',
  prev_user: '‰∏ä‰∏ÄÊ¨°Áî®Êà∑Ê∂àÊÅØ',
  prev_ai: 'ÂÄíÊï∞Á¨¨‰∫åÊù°AIÂõûÂ§ç',
}

type AiPart = { type: 'text'; text: string } | { type: 'image'; image: string } | { inlineData: { mimeType: string, data: string } }

async function imageUrlToAiSdkImagePart(urlStr: string): Promise<AiPart | null> {
  if (!urlStr) return null
  if (urlStr.startsWith('data:image/')) {
    const match = urlStr.match(/^data:(image\/[a-zA-Z0-9.+-]+);base64,(.+)$/);
    if (match) return { inlineData: { mimeType: match[1], data: match[2] } };
    return { type: 'image', image: urlStr }
  }
  if (urlStr.includes('/uploads/')) {
    const fileData = await getFileBase64(path.basename(urlStr))
    if (!fileData) return null
    return { inlineData: { mimeType: fileData.mime, data: fileData.data } };
  }
  return null
}

type ProcessThread = { key: string; userId: string; roomId: number; abort: AbortController; messageId: string }
const processThreads: ProcessThread[] = []
const makeThreadKey = (userId: string, roomId: number) => `${userId}:${roomId}`

async function chatReplyProcess(options: RequestOptions): Promise<{ message: string; data: ChatResponse; status: string }> {
  const userId = options.user._id.toString()
  const messageId = options.messageId
  const roomId = options.room.roomId
  const abort = new AbortController()
  const customMessageId = generateMessageId()
  const threadKey = makeThreadKey(userId, roomId)

  const existingIdx = processThreads.findIndex(t => t.key === threadKey)
  if (existingIdx > -1) {
    processThreads[existingIdx].abort.abort()
    processThreads.splice(existingIdx, 1)
  }
  processThreads.push({ key: threadKey, userId, abort, messageId, roomId })

  await ensureUploadDir()

  const model = options.room.chatModel
  const maxContextCount = options.user.advanced.maxContextCount ?? 20

  updateRoomChatModel(userId, options.room.roomId, model)

  const { message, uploadFileKeys, lastContext, process: processCb, systemMessage, temperature, top_p } = options

  processCb?.({
    id: customMessageId,
    text: '',
    role: 'assistant',
    conversationId: lastContext?.conversationId,
    parentMessageId: lastContext?.parentMessageId,
    detail: undefined,
  })

  let content: MessageContent = message
  let fileContext = ''

  const globalConfig = await getCacheConfig()
  const imageModelsStr = globalConfig.siteConfig.imageModels || ''
  const imageModelList = imageModelsStr.split(/[,Ôºå]/).map(s => s.trim()).filter(Boolean)
  const isImage = imageModelList.some(m => model.includes(m))

  if (uploadFileKeys && uploadFileKeys.length > 0) {
    const textFiles = uploadFileKeys.filter(k => isTextFile(k))
    const imageFiles = uploadFileKeys.filter(k => isImageFile(k))

    if (textFiles.length > 0) {
      for (const fileKey of textFiles) {
        try {
          const filePath = path.join(UPLOAD_DIR, stripTypePrefix(fileKey))
          await fs.access(filePath)
          const fileContent = await fs.readFile(filePath, 'utf-8')
          fileContext += `\n\n--- File Start: ${stripTypePrefix(fileKey)} ---\n${fileContent}\n--- File End ---\n`
        }
        catch (e) {
          globalThis.console.error(`Error reading text file ${fileKey}`, e)
          fileContext += `\n\n[System Error: File ${fileKey} not found or unreadable]\n`
        }
      }
    }

    const finalMessage = message + (fileContext ? `\n\nAttached Files content:\n${fileContext}` : '')
    if (imageFiles.length > 0) {
      content = [{ type: 'text', text: finalMessage }] as any
      for (const uploadFileKey of imageFiles) {
        ;(content as any[]).push({ type: 'image_url', image_url: { url: await convertImageUrl(stripTypePrefix(uploadFileKey)) } })
      }
    }
    else {
      content = finalMessage
    }
  }

  let searchProcessLog = ''
  const allowSearch = globalConfig.siteConfig?.webSearchEnabled === true
  const finalSearchMode = allowSearch && options.searchMode === true && !isImage

  if (finalSearchMode) {
    try {
      const preContext = await loadContextMessages({
        maxContextCount,
        lastMessageId: lastContext?.parentMessageId,
        systemMessage,
        content,
      })
      const preTokens = estimateTokenCount(preContext)

      const plannerModelCfg = String(globalConfig.siteConfig?.webSearchPlannerModel ?? '').trim()
      const plannerModelEnv = String(process.env.WEB_SEARCH_PLANNER_MODEL ?? '').trim()
      const plannerModelName = plannerModelCfg || plannerModelEnv || model

      let plannerKey = await getRandomApiKey(options.user, model, undefined, preTokens)
      if (!plannerKey) throw new Error('Ê≤°ÊúâÂØπÂ∫îÁöÑ apikeys ÈÖçÁΩÆ (Planner)')

      let actualPlannerModel = plannerModelName
      if (plannerModelName !== model) {
        const candidateKey = await getRandomApiKey(options.user, plannerModelName, undefined, preTokens)
        if (candidateKey) plannerKey = candidateKey
        else actualPlannerModel = model
      }

      const plannerProvider = normalizeProvider((plannerKey as any).keyModel)
      const plannerBaseUrl = isNotEmptyString(plannerKey.baseUrl)
        ? plannerKey.baseUrl
        : (isNotEmptyString(globalConfig.apiBaseUrl) ? globalConfig.apiBaseUrl : undefined)

      const maxRounds = Math.max(1, Math.min(6, Number(globalConfig.siteConfig?.webSearchMaxRounds ?? process.env.WEB_SEARCH_MAX_ROUNDS ?? 3)))
      const maxResults = Math.max(1, Math.min(10, Number(globalConfig.siteConfig?.webSearchMaxResults ?? process.env.WEB_SEARCH_MAX_RESULTS ?? 5)))

      const searchProvider = globalConfig.siteConfig?.webSearchProvider as any
      const searchSearxngUrl = String(globalConfig.siteConfig?.searxngApiUrl ?? '').trim() || undefined
      const searchTavilyKey = String(globalConfig.siteConfig?.tavilyApiKey ?? '').trim() || undefined

      const progressMessages: string[] = []
      const onProgressLocal = (status: string) => {
        progressMessages.push(status)
        searchProcessLog = progressMessages.join('\n')
        const isFinishing = status.includes('ÂÆåÊØï') || status.includes('Êó†ÈúÄ')
        const suffix = isFinishing ? '\n\n‚ö°Ô∏è ÂáÜÂ§áÁîüÊàê...' : '\n\n‚è≥ Ê≠£Âú®ÊâßË°å...'
        processCb?.({
          id: customMessageId,
          text: searchProcessLog + suffix,
          role: 'assistant',
          conversationId: lastContext?.conversationId,
          parentMessageId: lastContext?.parentMessageId,
          detail: undefined,
        })
      }

      const historyContextStr = await buildConversationContext(lastContext?.parentMessageId, maxContextCount)
      const currentDate = new Date().toLocaleString()

      const plannerTimeoutScheduleMs =
        parseTimeoutScheduleToMs((globalConfig.siteConfig as any)?.webSearchPlannerTimeoutScheduleMs ?? process.env.WEB_SEARCH_PLANNER_TIMEOUT_SCHEDULE_MS)
        ?? [20_000, 30_000, 40_000]

      const plannerModel = createLanguageModel({
        provider: plannerProvider,
        apiKey: plannerKey.key,
        baseUrl: plannerBaseUrl,
        model: actualPlannerModel,
      })

      const { rounds, selectedIds, planFailed } = await runIterativeWebSearch({
        plannerModel,
        userQuestion: message,
        maxRounds,
        maxResults,
        abortSignal: abort.signal,
        provider: searchProvider,
        searxngApiUrl: searchSearxngUrl,
        tavilyApiKey: searchTavilyKey,
        onProgress: onProgressLocal,
        fullContext: historyContextStr,
        date: currentDate,
        plannerTimeoutScheduleMs,
      })

      if (progressMessages.length > 0) searchProcessLog = progressMessages.join('\n')

      const filteredRounds = rounds.map((r, rIdx) => ({
        query: r.query,
        note: r.note,
        items: planFailed
          ? r.items
          : r.items.filter((_, iIdx) => selectedIds.has(`${rIdx + 1}.${iIdx + 1}`)),
      })).filter(r => r.items.length > 0 || r.note)

      const ctx = formatAggregatedSearchForAnswer(filteredRounds)

      let finalStatusMessage = '‚úÖ ËµÑÊñôÊï¥ÁêÜÂÆåÊØïÔºåÊ≠£Âú®ÁîüÊàêÂõûÁ≠î...'
      if (planFailed && rounds.length > 0) finalStatusMessage = '‚ö†Ô∏è ËµÑÊñôÊï¥ÁêÜÂèëÁîüÂºÇÂ∏∏Ôºå‰øùÁïôÁé∞Â≠òÊêúÁ¥¢ËµÑÊñôËøõË°åÂõûÁ≠î...'
      else if (!ctx && rounds.length > 0) finalStatusMessage = '‚ö†Ô∏è Êú™ËÉΩÁ≠õÈÄâÂá∫ÊúâÊïàÂºïÁî®ÔºåÂ∞ùËØïÁõ¥Êé•ÂõûÁ≠î...'

      processCb?.({
        id: customMessageId,
        text: (searchProcessLog ? searchProcessLog + '\n\n---\n\n' : '') + `‚ö°Ô∏è ${finalStatusMessage}\n(Ê®°ÂûãÊ≠£Âú®ÈòÖËØª ${ctx.length > 5000 ? 'Â§ßÈáè' : ''}ËµÑÊñôÂπ∂ÊûÑÊÄùÊúÄÁªàÂõûÁ≠îÔºåËØ∑Á®çÂÄô...)`,
        role: 'assistant',
        conversationId: lastContext?.conversationId,
        parentMessageId: lastContext?.parentMessageId,
        detail: undefined,
      })

      if (ctx) content = appendTextToMessageContent(content, ctx)
    }
    catch (e: any) {
      if (isAbortError(e, abort.signal)) throw e
      globalThis.console.error('[WebSearch] failed:', e?.message ?? e)
      searchProcessLog += `\n‚ùå ËÅîÁΩëÊêúÁ¥¢Ê®°ÂùóÈÅáÂà∞ÈóÆÈ¢òÔºö${e?.message ?? 'Êú™Áü•ÈîôËØØ'}`
      processCb?.({
        id: customMessageId,
        text: searchProcessLog + '\n\nÂ∞ùËØï‰ΩøÁî®Â∑≤ÊúâÁü•ËØÜÂõûÁ≠î...',
        role: 'assistant',
        conversationId: lastContext?.conversationId,
        parentMessageId: lastContext?.parentMessageId,
        detail: undefined,
      })
    }
  }

  const finalMessages = await loadContextMessages({
    maxContextCount,
    lastMessageId: lastContext?.parentMessageId,
    systemMessage,
    content,
  })

  const finalTokenCount = estimateTokenCount(finalMessages)
  const key = await getRandomApiKey(options.user, model, undefined, finalTokenCount)

  try {
    if (!key) {
      throw new Error(`Ê≤°ÊúâÂØπÂ∫îÁöÑ apikeys ÈÖçÁΩÆ (Token: ${finalTokenCount} / Model: ${model})ÔºåËØ∑Ê£ÄÊü• Key ÈÖçÁΩÆ„ÄÇ`)
    }

    const resolvedBaseUrl = isNotEmptyString(key.baseUrl)
      ? key.baseUrl
      : (isNotEmptyString(globalConfig.apiBaseUrl) ? globalConfig.apiBaseUrl : undefined)

    const provider = normalizeProvider((key as any).keyModel)
    const lm = createLanguageModel({
      provider,
      apiKey: key.key,
      baseUrl: resolvedBaseUrl,
      model,
    })

    const modelConfig = MODEL_CONFIGS[model] || { supportTopP: true }
    const finalTemperature = modelConfig.defaultTemperature ?? temperature
    const shouldUseTopP = modelConfig.supportTopP

    const getCombineStreamText = (currentAnswerText: string) => {
      if (!searchProcessLog) return currentAnswerText
      return `${searchProcessLog}\n\n---\n\n${currentAnswerText}`
    }

    // ÈíàÂØπË¢´Êã¶Êà™ÂèÇÊï∞ÁöÑÊúÄÁªà‰øÆÂ§çÔºöÊã¶Êà™ÊâÄÊúâÁöÑ Gemini Image ÈÄªËæëÁõ¥Êé•Áî®ÂéüÁîü fetch Ôºà‰∏çÂÜçËµ∞ AI SDK ÁöÑÊñáÊú¨ÁîüÊàêÔºâ
    const isGeminiImageModel = isImage && provider === 'google' && model.includes('gemini')

    if (isGeminiImageModel) {
      const dataUrlCache: DataUrlCache = new Map()
      const normalizedCurrent = await normalizeMessageContentDataUrlsToUploads(content, dataUrlCache)
      content = normalizedCurrent.content

      const { metas } = await buildGeminiHistoryFromLastMessageId({
        lastMessageId: lastContext?.parentMessageId,
        maxContextCount,
        forGeminiImageModel: true,
      })

      const metasNormalized: HistoryMessageMeta[] = []
      for (const m of metas) {
        const nu = await normalizeUrlsDataUrlsToUploads(m.urls || [], dataUrlCache)
        metasNormalized.push({ ...m, urls: nu.urls })
      }

      const { cleanedText: currentCleanedText, urls: currentUrlsRaw } = await extractImageUrlsFromMessageContent(content)
      const currentUrlsNorm = await normalizeUrlsDataUrlsToUploads(currentUrlsRaw || [], dataUrlCache)
      const currentUrls = currentUrlsNorm.urls

      const bindings = selectRecentTwoRoundsImages(metasNormalized, currentUrls)

      // ‰ΩøÁî®ÂéüÁîüÁöÑ contents ÁªìÊûÑÔºåÂÆåÂÖ®ÈÅøÂºÄ AI SDK ÁöÑ Zod Parser
      const historyNative = metasNormalized.map(m => ({
        role: m.role === 'model' ? 'model' : 'user',
        parts: [{ text: applyImageBindingsToCleanedText(m.cleanedText, m.urls, bindings) || '[Empty]' }]
      }))

      const userInstructionBase = (currentCleanedText && currentCleanedText.trim())
        ? currentCleanedText.trim()
        : 'ËØ∑ÁªßÁª≠ÁîüÊàê/‰øÆÊîπÂõæÁâá„ÄÇ'
      const labeledUserInstruction = applyImageBindingsToCleanedText(userInstructionBase, currentUrls, bindings)

      const nativeUserParts: any[] = []
      if (bindings.length) {
        nativeUserParts.push({ text: `„ÄêÊúÄËøë‰∏§ËΩÆÂõæÁâáÊò†Â∞ÑË°®„Äë\n${bindings.map(b => `${b.tag}=${IMAGE_SOURCE_LABEL[b.source]}(${shortUrlForLog(b.url)})`).join('\n')}\n` })
      }

      for (const b of bindings) {
        nativeUserParts.push({ text: `„Äê${b.tag}ÔΩú${IMAGE_SOURCE_LABEL[b.source]}„Äë` })
        const img = await imageUrlToAiSdkImagePart(b.url)
        if (img) {
            // Áõ¥Êé•Ââ•Á¶ªÂá∫ inlineData ÁªìÊûÑÁªôÂéüÁîü Payload ÁªÑË£Ö
            if ('inlineData' in img) {
                nativeUserParts.push({ inlineData: img.inlineData });
            } else if (img.type === 'text') {
                nativeUserParts.push({ text: img.text });
            }
        } 
        else nativeUserParts.push({ text: `ÔºàËØ•ÂõæÁâáÊó†Ê≥ï‰∏ä‰º†Ôºö${shortUrlForLog(b.url)}Ôºâ` })
      }

      nativeUserParts.push({ text: `„ÄêÁºñËæëÊåá‰ª§„Äë${labeledUserInstruction}` })

      const callSignal = mergeAbortSignals([
        abort.signal,
        globalConfig.timeoutMs ? AbortSignal.timeout(globalConfig.timeoutMs) : undefined,
      ])

      // === Áõ¥Êé•ÂèëËµ∑ÂéüÁîü FETCH ÈÄö‰ø°ÁªïÂºÄ SDK === //
      let fetchUrl = `${resolvedBaseUrl ? resolvedBaseUrl.replace(/\/+$/, '') : 'https://generativelanguage.googleapis.com/v1beta'}`;
      if (!fetchUrl.includes('/models/')) {
        fetchUrl += `/models/${model}:generateContent`;
      }
      
      const isGemini3ProImageModel = model.includes('gemini-3-pro-image');
      const requestBody = {
        contents: [...historyNative, { role: 'user', parts: nativeUserParts }],
        generationConfig: {
          temperature: finalTemperature,
          topP: shouldUseTopP ? top_p : undefined,
          ...(isGemini3ProImageModel ? {
             responseModalities: ['TEXT', 'IMAGE'],
             // ÂÆåÁæéÈÄè‰º†ÁªôÂ∫ïÂ±ÇÁöÑÂèÇÊï∞ÔºåËøôÈáåÊòØÂøÖÈ°ªËÉΩÂ§üËß¶ËææÂ∫ïÈÉ®ÁöÑÂÖ≥ÈîÆ
             imageConfig: {
               imageSize: '4K',
               //aspectRatio: '16:9'
             }
          } : {})
        }
      };

      const res = await fetch(fetchUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'x-goog-api-key': key.key,
          'Authorization': `Bearer ${key.key}`  // ‰∏∫ÊîØÊåÅ OneAPI Á±ªÁ≥ªÁªüÁöÑÂ§öÈáçËÆ§ËØÅÂ§¥‰øùÊåÅÂÖºÂÆπ
        },
        body: JSON.stringify(requestBody),
        signal: callSignal
      });

      if (!res.ok) {
        const errText = await res.text().catch(() => 'No Content Formatted Error');
        throw new Error(`Downstream API Error (${res.status}): ${errText}`);
      }

      const jsonRes = await res.json();
      let answerText = '';
      let outputParts = jsonRes.candidates?.[0]?.content?.parts || [];

      // ÂéüÁîüÊÄÅËß£ÂåÖËøîÂõûÁöÑÂõæÁâáÁºñÁ†ÅÂπ∂ËøõË°åÊú¨Âú∞Â≠òÁõòÊõøÊç¢
      for (const part of outputParts) {
        if (part.text) {
          answerText += part.text;
        }
        if (part.inlineData && part.inlineData.data) {
          const mime = part.inlineData.mimeType || 'image/png';
          const ext = mime.split('/')[1] || 'png';
          const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`;
          
          await fs.writeFile(path.join(UPLOAD_DIR, filename), Buffer.from(part.inlineData.data, 'base64'));
          answerText += `${answerText ? '\n\n' : ''}![Generated Image](/uploads/${filename})`;
        }
      }

      if (!answerText) {
        if (jsonRes.promptFeedback && jsonRes.promptFeedback.blockReason) {
             answerText = `[Gemini] Á≥ªÁªüÊã¶Êà™‰∫ÜÊ≠§ËØ∑Ê±ÇÔºåÂéüÂõ†: ${jsonRes.promptFeedback.blockReason}`;
        } else {
             answerText = '[Gemini] Success but no content returned. Check generation configuration and token.';
             globalThis.console.error('Google API empty inner content return detail:', JSON.stringify(jsonRes));
        }
      }

      let usageRes: any = undefined;
      if (jsonRes.usageMetadata) {
        usageRes = {
          prompt_tokens: jsonRes.usageMetadata.promptTokenCount || 0,
          completion_tokens: jsonRes.usageMetadata.candidatesTokenCount || 0,
          total_tokens: jsonRes.usageMetadata.totalTokenCount || 0,
          estimated: false,
        };
      }

      processCb?.({
        id: customMessageId,
        text: getCombineStreamText(answerText),
        role: 'assistant',
        conversationId: lastContext?.conversationId,
        parentMessageId: lastContext?.parentMessageId,
        detail: { usage: usageRes },
      })

      return sendResponse({
        type: 'Success',
        data: {
          object: 'chat.completion',
          choices: [{ message: { role: 'assistant', content: answerText }, finish_reason: 'stop', index: 0, logprobs: null }],
          created: Date.now(),
          conversationId: lastContext?.conversationId,
          model,
          text: answerText,
          id: customMessageId,
          detail: { usage: usageRes },
        },
      })
    }
    // ============== ÂéüÁîüÂØπÊé•Ââ•Á¶ª‰øÆÂ§çÊ®°Âùó END ===============

    const coreMessages = toCoreMessages(finalMessages)

    const callSignal = mergeAbortSignals([
      abort.signal,
      globalConfig.timeoutMs ? AbortSignal.timeout(globalConfig.timeoutMs) : undefined,
    ])

    // Âõ†‰∏∫ÊâÄÊúâÁöÑ google gemini ÁîüÂõæÂ∑≤ÁªèË¢´‰∏äÈù¢ isGeminiImageModel Êã¶Êà™Â§ÑÁêÜÂÆåÊØï
    // Â¶ÇÊûúËøòËµ∞Âà∞ËøôÈáåÔºåËØ¥ÊòéÊòØÂÖ∂‰ªñÂéÇÂïÜÂ¶Ç OpenAI ÁöÑ DALL-E ÈÄöÁî®ÁîüÂõæÂ§ÑÁêÜÈÄªËæë
    if (isImage) {
      const result: any = await generateText({
        model: lm,
        messages: coreMessages,
        temperature: finalTemperature,
        topP: shouldUseTopP ? top_p : undefined,
        abortSignal: callSignal,
      })

      let answerText = result.text || ''

      if (result.files?.length) {
        for (const f of result.files) {
          if (!f?.mediaType?.startsWith('image/')) continue
          const ext = f.mediaType.split('/')[1] || 'png'
          const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`
          await fs.writeFile(path.join(UPLOAD_DIR, filename), Buffer.from(f.uint8Array))
          answerText += `${answerText ? '\n\n' : ''}![Generated Image](/uploads/${filename})`
        }
      }

      if (answerText && !answerText.startsWith('![') && (answerText.startsWith('http') || answerText.startsWith('data:image')))
        answerText = `![Generated Image](${answerText})`

      const usageRes = toUsageResponse(result.usage)

      processCb?.({
        id: customMessageId,
        text: getCombineStreamText(answerText),
        role: 'assistant',
        conversationId: lastContext?.conversationId,
        parentMessageId: lastContext?.parentMessageId,
        detail: { usage: usageRes },
      })

      return sendResponse({
        type: 'Success',
        data: {
          object: 'chat.completion',
          choices: [{ message: { role: 'assistant', content: answerText }, finish_reason: 'stop', index: 0, logprobs: null }],
          created: Date.now(),
          conversationId: lastContext?.conversationId,
          model,
          text: answerText,
          id: customMessageId,
          detail: { usage: usageRes },
        },
      })
    }

    const result: any = streamText({
      model: lm,
      messages: coreMessages,
      temperature: finalTemperature,
      topP: shouldUseTopP ? top_p : undefined,
      abortSignal: callSignal,
      providerOptions: provider === 'openai-compatible'
        ? {
            openai: (() => {
              const siteCfg = globalConfig.siteConfig
              const reasoningModelsStr = siteCfg?.reasoningModels || ''
              const reasoningEffort = siteCfg?.reasoningEffort || 'medium'
              const reasoningModelList = reasoningModelsStr.split(/[,Ôºå]/).map(s => s.trim()).filter(Boolean)
              if (reasoningModelList.includes(model) && reasoningEffort && reasoningEffort !== 'none') {
                return { reasoning_effort: reasoningEffort }
              }
              return {}
            })(),
          }
        : undefined,
    })

    let answerText = ''
    for await (const part of (result as any).fullStream as AsyncIterable<any>) {
      if (part?.type === 'text-delta') {
        const delta = String(part.textDelta ?? '')
        answerText += delta
        processCb?.({
          id: customMessageId,
          text: getCombineStreamText(answerText),
          role: 'assistant',
          conversationId: lastContext?.conversationId,
          parentMessageId: lastContext?.parentMessageId,
          detail: undefined,
        })
      }
      else if (part?.type === 'error') {
        globalThis.console.error('[Stream Error Part]', part.error)
      }
    }

    let usageRes: any
    try {
      const usage = await (result.usage as Promise<any> | undefined)
      usageRes = toUsageResponse(usage)
    }
    catch { }

    return sendResponse({
      type: 'Success',
      data: {
        object: 'chat.completion',
        choices: [{ message: { role: 'assistant', content: answerText }, finish_reason: 'stop', index: 0, logprobs: null }],
        created: Date.now(),
        conversationId: lastContext?.conversationId,
        model,
        text: answerText,
        id: customMessageId,
        detail: { usage: usageRes && { ...usageRes, estimated: false } },
      },
    })
  }
  catch (error: any) {
    if (isAbortError(error, abort.signal)) throw error

    const code = error.statusCode || error.status || error.response?.status
    const errorMsgRaw = error.message ?? String(error)

    if (code === 429 && (errorMsgRaw.includes('Too Many Requests') || errorMsgRaw.includes('Rate limit'))) {
      if (key && options.tryCount++ < 3) {
        _lockedKeys.push({ key: key.key, lockedTime: Date.now() })
        await new Promise(resolve => setTimeout(resolve, 2000))
        const index = processThreads.findIndex(d => d.key === threadKey)
        if (index > -1) processThreads.splice(index, 1)
        return await chatReplyProcess(options)
      }
    }

    globalThis.console.error('[ChatReply Process Error]:', error)

    let displayErrorMsg = errorMsgRaw
    if (code && Reflect.has(ErrorCodeMessage, code)) {
      displayErrorMsg = `${ErrorCodeMessage[code]} (${errorMsgRaw})`
    }
    else if (code) {
      displayErrorMsg = `[Status ${code}] ${errorMsgRaw}`
    }

    const finalErrorText = searchProcessLog
      ? `${searchProcessLog}\n\n---\n\n‚ùå Ê®°ÂûãËØ∑Ê±ÇÂ§±Ë¥•Ôºö${displayErrorMsg}`
      : `‚ùå Ê®°ÂûãËØ∑Ê±ÇÂ§±Ë¥•Ôºö${displayErrorMsg}`

    processCb?.({
      id: customMessageId,
      text: finalErrorText,
      role: 'assistant',
      conversationId: lastContext?.conversationId,
      parentMessageId: lastContext?.parentMessageId,
      detail: undefined,
    })

    return sendResponse({ type: 'Fail', message: displayErrorMsg })
  }
  finally {
    const index = processThreads.findIndex(d => d.key === threadKey)
    if (index > -1) processThreads.splice(index, 1)
  }
}

export function abortChatProcess(userId: string, roomId: number) {
  const key = makeThreadKey(userId, roomId)
  const index = processThreads.findIndex(d => d.key === key)
  if (index <= -1) return
  const messageId = processThreads[index].messageId
  processThreads[index].abort.abort()
  processThreads.splice(index, 1)
  if (API_DEBUG) {
    debugLog('====== [Abort Debug] ======')
    debugLog('[userId]', userId, '[roomId]', roomId, '[messageId]', messageId)
    debugLog('====== [Abort Debug End] ======')
  }
  return messageId
}

export function initAuditService(audit: AuditConfig) {
  if (!audit || !audit.options || !audit.options.apiKey || !audit.options.apiSecret) return
  const Service = textAuditServices[audit.provider]
  auditService = new Service(audit.options)
}

async function containsSensitiveWords(audit: AuditConfig, text: string): Promise<boolean> {
  if (audit.customizeEnabled && isNotEmptyString(audit.sensitiveWords)) {
    const textLower = text.toLowerCase()
    if (audit.sensitiveWords.split('\n').filter(d => textLower.includes(d.trim().toLowerCase())).length > 0) return true
  }
  if (audit.enabled) {
    if (!auditService) initAuditService(audit)
    return await auditService.containsSensitiveWords(text)
  }
  return false
}

async function chatConfig() {
  const config = await getOriginConfig() as ModelConfig
  return sendResponse<ModelConfig>({ type: 'Success', data: config })
}

async function getMessageById(id: string): Promise<ChatMessage | undefined> {
  const isPrompt = id.startsWith('prompt_')
  const chatInfo = await getChatByMessageId(isPrompt ? id.substring(7) : id)
  if (!chatInfo) return undefined
  const parentMessageId = isPrompt ? chatInfo.options.parentMessageId : `prompt_${id}`
  if (chatInfo.status !== Status.Normal) return parentMessageId ? getMessageById(parentMessageId) : undefined

  if (isPrompt) {
    let promptText = chatInfo.prompt
    const allFileKeys = chatInfo.images || []
    const textFiles = allFileKeys.filter(k => isTextFile(k))
    const imageFiles = allFileKeys.filter(k => isImageFile(k))

    if (textFiles.length > 0) {
      let fileContext = ''
      for (const fileKey of textFiles) {
        try {
          const filePath = path.join(UPLOAD_DIR, stripTypePrefix(fileKey))
          const fileContent = await fs.readFile(filePath, 'utf-8')
          fileContext += `\n\n--- Context File: ${stripTypePrefix(fileKey)} ---\n${fileContent}\n--- End File ---\n`
        }
        catch { }
      }
      promptText += (fileContext ? `\n\n[Attached Files History]:\n${fileContext}` : '')
    }

    if (promptText && typeof promptText === 'string')
      promptText = promptText.replace(DATA_URL_IMAGE_RE, '[Image Data Removed]')

    let content: MessageContent = promptText
    if (imageFiles.length > 0) {
      content = [{ type: 'text', text: promptText }] as any
      for (const image of imageFiles) {
        ;(content as any[]).push({ type: 'image_url', image_url: { url: await convertImageUrl(stripTypePrefix(image)) } })
      }
    }

    return {
      id,
      conversationId: chatInfo.options.conversationId,
      parentMessageId,
      role: 'user',
      text: content,
    }
  }
  else {
    let responseText = chatInfo.response || ''
    if (responseText && typeof responseText === 'string')
      responseText = responseText.replace(DATA_URL_IMAGE_RE, '[Image History]')
    return {
      id,
      conversationId: chatInfo.options.conversationId,
      parentMessageId,
      role: 'assistant',
      text: responseText,
    }
  }
}

async function randomKeyConfig(keys: KeyConfig[]): Promise<KeyConfig | null> {
  if (keys.length <= 0) return null
  _lockedKeys.filter(d => d.lockedTime <= Date.now() - 1000 * 20).forEach(d => _lockedKeys.splice(_lockedKeys.indexOf(d), 1))
  let unsedKeys = keys.filter(d => _lockedKeys.filter(l => d.key === l.key).length <= 0)
  const start = Date.now()
  while (unsedKeys.length <= 0) {
    if (Date.now() - start > 3000) break
    await new Promise(resolve => setTimeout(resolve, 1000))
    unsedKeys = keys.filter(d => _lockedKeys.filter(l => d.key === l.key).length <= 0)
  }
  if (unsedKeys.length <= 0) return null
  return unsedKeys[Math.floor(Math.random() * unsedKeys.length)]
}

async function getRandomApiKey(user: UserInfo, chatModel: string, _accountId?: string, tokenCount?: number): Promise<KeyConfig | undefined> {
  let keys = (await getCacheApiKeys())
    .filter(d => hasAnyRole(d.userRoles, user.roles))
    .filter(d => d.chatModels.includes(chatModel))

  if (tokenCount !== undefined && keys.length > 0) {
    keys = keys.filter(k => {
      const remark = k.remark || ''
      const maxMatch = remark.match(/MAX_TOKENS?[:=]\s*(\d+)/i)
      const minMatch = remark.match(/MIN_TOKENS?[:=]\s*(\d+)/i)

      let valid = true
      if (maxMatch) {
        const max = parseInt(maxMatch[1], 10)
        if (tokenCount > max) valid = false
      }
      if (minMatch) {
        const min = parseInt(minMatch[1], 10)
        if (tokenCount <= min) valid = false
      }
      return valid
    })
  }

  const picked = await randomKeyConfig(keys)
  if (API_DEBUG) {
    debugLog('====== [Key Pick Debug] ======')
    debugLog('[chatModel]', chatModel, '[tokens]', tokenCount)
    debugLog('[candidateKeyCount]', keys.length)
    debugLog('[picked]', picked ? { keyModel: (picked as any).keyModel, baseUrl: picked.baseUrl, remark: picked.remark } : '(null)')
    debugLog('====== [Key Pick Debug End] ======')
  }
  return picked ?? undefined
}

export { chatReplyProcess, chatConfig, containsSensitiveWords }
