import * as dotenv from 'dotenv'
import OpenAI from 'openai'
import jwt_decode from 'jwt-decode'
import { GoogleGenAI } from '@google/genai'
import { textTokens } from 'gpt-token'
import type { TiktokenModel } from 'gpt-token'
import type { AuditConfig, KeyConfig, UserInfo } from '../storage/model'
import { Status } from '../storage/model'
import { convertImageUrl } from '../utils/image'
import type { TextAuditService } from '../utils/textAudit'
import { textAuditServices } from '../utils/textAudit'
import { getCacheApiKeys, getCacheConfig, getOriginConfig } from '../storage/config'
import { sendResponse } from '../utils'
import { hasAnyRole, isNotEmptyString } from '../utils/is'
import type { JWT, ModelConfig } from '../types'
import { getChatByMessageId, updateRoomChatModel } from '../storage/mongo'
import type { ChatMessage, ChatResponse, MessageContent, RequestOptions } from './types'
import * as fs from 'node:fs/promises'
import * as path from 'node:path'
import { generateMessageId } from '../utils/id-generator'
import { abortablePromise, isAbortError } from './abortable'
import { webSearch } from '../utils/webSearch'

type GeminiPart = { text?: string; inlineData?: { mimeType: string; data: string } }

const MODEL_CONFIGS: Record<string, { supportTopP: boolean; defaultTemperature?: number }> = {
  'gpt-5-search-api': { supportTopP: false, defaultTemperature: 0.8 },
}

const UPLOAD_DIR = path.resolve(process.cwd(), 'uploads')

async function ensureUploadDir() { try { await fs.access(UPLOAD_DIR) } catch { await fs.mkdir(UPLOAD_DIR, { recursive: true }) } }
function stripTypePrefix(key: string): string { return key.replace(/^(img:|txt:)/, '') }
function isTextFile(filename: string): boolean {
  if (filename.startsWith('txt:')) return true; if (filename.startsWith('img:')) return false
  const ext = path.extname(stripTypePrefix(filename)).toLowerCase()
  return ['.txt', '.md', '.json', '.csv', '.js', '.ts', '.py', '.java', '.html', '.css', '.xml', '.yml', '.yaml', '.log', '.ini', '.config'].includes(ext)
}
function isImageFile(filename: string): boolean {
  if (filename.startsWith('img:')) return true; if (filename.startsWith('txt:')) return false
  const ext = path.extname(stripTypePrefix(filename)).toLowerCase()
  return ['.png', '.jpg', '.jpeg', '.webp', '.gif', '.heic', '.bmp'].includes(ext)
}
async function getFileBase64(filename: string): Promise<{ mime: string; data: string } | null> {
  try {
    const realFilename = stripTypePrefix(filename); const filePath = path.join(UPLOAD_DIR, realFilename)
    await fs.access(filePath); const buffer = await fs.readFile(filePath)
    const ext = path.extname(realFilename).toLowerCase().replace('.', '')
    let mime = 'image/png'
    if (ext === 'jpg' || ext === 'jpeg') mime = 'image/jpeg'
    else if (ext === 'webp') mime = 'image/webp'
    else if (ext === 'gif') mime = 'image/gif'
    else if (ext === 'heic') mime = 'image/heic'
    else if (ext === 'bmp') mime = 'image/bmp'
    return { mime, data: buffer.toString('base64') }
  } catch (e) { globalThis.console.error(`[File Read Error] ${filename}:`, e); return null }
}

dotenv.config()

const API_DEBUG = process.env.API_DEBUG === 'true'
const API_DEBUG_MAX_TEXT = Number(process.env.API_DEBUG_MAX_TEXT ?? 800)

function trunc(s: any, n = API_DEBUG_MAX_TEXT): string { const str = typeof s === 'string' ? s : JSON.stringify(s ?? ''); if (!str) return ''; return str.length > n ? `${str.slice(0, n)}...(truncated,total=${str.length})` : str }
function safeJson(obj: any): string { try { return JSON.stringify(obj, null, 2) } catch (e: any) { return `[Unserializable: ${e?.message ?? e}]` } }
function summarizeOpenAIMessages(messages: any[]) {
  return (messages ?? []).map((m, idx) => {
    const content = m?.content; let contentType: string = typeof content; let contentLen = 0; let contentPreview: string | undefined
    if (typeof content === 'string') { contentLen = content.length; contentPreview = trunc(content) }
    else if (Array.isArray(content)) { contentType = 'array'; contentLen = content.length; contentPreview = trunc(content.map((p: any) => ({ type: p?.type, textLen: typeof p?.text === 'string' ? p.text.length : undefined, hasImageUrl: !!p?.image_url?.url }))) }
    else if (content === null) { contentType = 'null'; contentPreview = 'null' }
    else { contentType = 'object'; contentPreview = trunc(content) }
    return { idx, role: m?.role, contentType, contentLen, contentPreview }
  })
}
function debugLog(...args: any[]) { if (!API_DEBUG) return; console.log(...args) }

// ===================== [æ–°å¢ Helper] åŠ è½½ä¸Šä¸‹æ–‡æ¶ˆæ¯ =====================
/**
 * æå‰åŠ è½½å¹¶æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œç”¨äº Token è®¡ç®—å’Œä¼ é€’ç»™ API
 */
async function loadContextMessages(params: {
  maxContextCount: number
  lastMessageId?: string
  systemMessage?: string
  content: MessageContent
}): Promise<OpenAI.ChatCompletionMessageParam[]> {
  const { maxContextCount, systemMessage, content } = params
  let { lastMessageId } = params

  const messages: OpenAI.ChatCompletionMessageParam[] = []

  // 1. è·å–å†å²æ¶ˆæ¯
  for (let i = 0; i < maxContextCount; i++) {
    if (!lastMessageId) break
    const message = await getMessageById(lastMessageId)
    if (!message) break

    let safeContent = message.text as string
    if (typeof safeContent === 'string') {
      safeContent = safeContent.replace(DATA_URL_IMAGE_RE, '[Image Data Removed]')
    }

    messages.push({ role: message.role as any, content: safeContent })
    lastMessageId = message.parentMessageId
  }

  // 2. æ·»åŠ ç³»ç»Ÿæç¤ºè¯
  if (systemMessage) {
    messages.push({ role: 'system', content: systemMessage })
  }

  // 3. ç¿»è½¬å¹¶æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
  messages.reverse()
  // æ³¨æ„ï¼šOpenAI SDK ç±»å‹å®šä¹‰å¯¹äº content æ¯”è¾ƒä¸¥æ ¼ï¼Œè¿™é‡Œä½¿ç”¨ as any ç®€åŒ–å…¼å®¹ Text/Image æ··åˆå†…å®¹
  messages.push({ role: 'user', content: content as any })

  return messages
}

/**
 * ä¼°ç®— Token æ•°é‡ (å¢åŠ é™çº§ç­–ç•¥)
 */
function estimateTokenCount(messages: OpenAI.ChatCompletionMessageParam[]): number {
  let allText = ''
  try {
    allText = messages.map(m => {
      if (typeof m.content === 'string') return m.content
      if (Array.isArray(m.content)) {
        return m.content.map((c: any) => c.type === 'text' ? c.text : '').join('')
      }
      return ''
    }).join('\n')

    // ä½¿ç”¨ gpt-3.5-turbo ä½œä¸ºåŸºå‡† tokenizer
    const count = textTokens(allText, 'gpt-3.5-turbo' as TiktokenModel)

    // å¦‚æœè®¡ç®—å‡º 0 ä½†æ–‡æœ¬ä¸ä¸ºç©ºï¼Œè¯´æ˜å¯èƒ½è®¡ç®—å¤±è´¥ï¼Œé™çº§åˆ°å­—ç¬¦ç²—ä¼°
    if (count === 0 && allText.length > 0) {
      return Math.ceil(allText.length / 3)
    }
    return count
  } catch (e) {
    // é™çº§ç­–ç•¥: å­—ç¬¦æ•° / 4
    if (allText && allText.length > 0) {
      return Math.ceil(allText.length / 4)
    }
    return 0
  }
}
// ===================== [End Helper] =====================

// ===================== è”ç½‘æœç´¢ =====================
type SearchPlan = {
  action: 'search' | 'stop'
  query?: string
  reason?: string
  selected_ids?: string[] // e.g. ["1.1", "2.3"]
  context_summary?: string // å¯¹ä¸Šä¸‹æ–‡çš„æ€»ç»“
}
type SearchRound = { query: string; items: Array<{ title: string; url: string; content: string }>; note?: string }

function safeParseJsonFromText(text: string): any | null {
  if (!text) return null; const s = String(text).trim()
  try { return JSON.parse(s) } catch { }
  const i = s.indexOf('{'); const j = s.lastIndexOf('}')
  if (i >= 0 && j > i) { try { return JSON.parse(s.slice(i, j + 1)) } catch { } }
  return null
}

// ===== Planner timeout (dynamic schedule) + retry helpers =====
class PlannerTimeoutError extends Error {
  public readonly code = 'PLANNER_TIMEOUT'
  constructor(public readonly timeoutMs: number) {
    super(`Planner request timeout after ${timeoutMs}ms`)
  }
}

function sleep(ms: number) {
  return new Promise(resolve => setTimeout(resolve, ms))
}

/**
 * å•æ¬¡è¯·æ±‚ï¼šæ”¯æŒçˆ¶ abort + è¶…æ—¶ abort
 * - parentSignal abortï¼šç«‹åˆ»æŠ›å‡ºï¼ˆä¸è§†ä¸º timeoutï¼Œä¸é‡è¯•ï¼‰
 * - è¶…æ—¶ï¼šæŠ› PlannerTimeoutError
 */
async function openaiChatCreateWithTimeout<T>(params: {
  openai: OpenAI
  request: any
  timeoutMs: number
  parentSignal?: AbortSignal
}): Promise<T> {
  const { openai, request, timeoutMs, parentSignal } = params

  const ac = new AbortController()
  let didTimeout = false
  let timer: any

  const onParentAbort = () => {
    try { ac.abort() } catch { }
  }

  try {
    if (parentSignal) {
      if (parentSignal.aborted) {
        ac.abort()
      } else {
        parentSignal.addEventListener('abort', onParentAbort, { once: true })
      }
    }

    timer = setTimeout(() => {
      didTimeout = true
      try { ac.abort() } catch { }
    }, timeoutMs)

    return await openai.chat.completions.create(request, { signal: ac.signal }) as T
  } catch (e: any) {
    // ç”¨æˆ·/ä¸Šå±‚ abortï¼šä¸è§†ä¸º timeout
    if (parentSignal?.aborted) throw e

    // æˆ‘ä»¬è§¦å‘çš„è¶…æ—¶
    if (didTimeout) throw new PlannerTimeoutError(timeoutMs)

    throw e
  } finally {
    clearTimeout(timer)
    parentSignal?.removeEventListener?.('abort', onParentAbort as any)
  }
}

/**
 * ä»…å½“â€œè¶…æ—¶â€æ—¶è‡ªåŠ¨é‡è¯•ï¼ˆåŠ¨æ€é€’å¢è¶…æ—¶ï¼‰
 * timeoutsMs = [10s, 15s, 20s] => æœ€å¤š 3 æ¬¡å°è¯•
 */
async function openaiChatCreateWithTimeoutRetry<T>(params: {
  openai: OpenAI
  request: any
  timeoutsMs?: number[] // e.g. [10000,15000,20000]
  parentSignal?: AbortSignal
  onTimeoutRetry?: (info: {
    attempt: number       // å½“å‰æ˜¯ç¬¬å‡ æ¬¡è¯·æ±‚ï¼ˆä»1å¼€å§‹ï¼‰
    timeoutMs: number     // å½“å‰è¿™æ¬¡è¯·æ±‚çš„è¶…æ—¶
    nextAttempt: number   // å³å°†è¿›è¡Œçš„ä¸‹ä¸€æ¬¡è¯·æ±‚åºå·
    nextTimeoutMs: number // ä¸‹ä¸€æ¬¡è¯·æ±‚çš„è¶…æ—¶
  }) => void
}): Promise<T> {
  const { openai, request, parentSignal, onTimeoutRetry } = params

  const timeoutsMsRaw = (params.timeoutsMs?.length ? params.timeoutsMs : [10_000, 15_000, 20_000])
    .map(n => Number(n))
    .filter(n => Number.isFinite(n) && n > 0)

  const timeoutsMs = timeoutsMsRaw.length ? timeoutsMsRaw : [20_000]
  const totalAttempts = timeoutsMs.length

  let lastErr: any

  for (let attempt = 1; attempt <= totalAttempts; attempt++) {
    const timeoutMs = timeoutsMs[attempt - 1]

    try {
      return await openaiChatCreateWithTimeout<T>({
        openai,
        request,
        timeoutMs,
        parentSignal,
      })
    } catch (e: any) {
      lastErr = e

      const isTimeout = e?.code === 'PLANNER_TIMEOUT' || e instanceof PlannerTimeoutError
      if (!isTimeout) throw e
      if (attempt >= totalAttempts) throw e

      const nextAttempt = attempt + 1
      const nextTimeoutMs = timeoutsMs[nextAttempt - 1]

      onTimeoutRetry?.({ attempt, timeoutMs, nextAttempt, nextTimeoutMs })

      // ç®€å•é€€é¿ï¼Œé¿å…ç«‹åˆ»é‡æ‰“
      await sleep(250 * Math.pow(2, attempt - 1))
    }
  }

  throw lastErr
}

// å¯é€‰ï¼šè§£æ "10,15,20" / "10000,15000,20000" => ms
function parseTimeoutScheduleToMs(input: any): number[] | null {
  if (!input) return null
  const s = String(input).trim()
  if (!s) return null
  const parts = s.split(/[,ï¼Œ]/).map(x => x.trim()).filter(Boolean)
  const nums = parts.map(p => Number(p)).filter(n => Number.isFinite(n) && n > 0)
  if (!nums.length) return null

  // å¦‚æœçœ‹èµ·æ¥åƒç§’ï¼ˆ<= 300ï¼‰ï¼Œè½¬æˆ ms
  const allLooksLikeSeconds = nums.every(n => n <= 300)
  const out = allLooksLikeSeconds ? nums.map(n => Math.round(n * 1000)) : nums.map(n => Math.round(n))

  return out.filter(n => n > 0)
}
// ===== Planner timeout (dynamic schedule) + retry helpers end =====

async function buildConversationContext(lastMessageId: string | undefined, maxCount: number): Promise<string> {
  if (!lastMessageId) return ''
  const messages: string[] = []
  let currentId = lastMessageId
  for (let i = 0; i < maxCount; i++) {
    if (!currentId) break
    const msg = await getMessageById(currentId)
    if (!msg) break
    const role = msg.role === 'assistant' ? 'AI' : 'User'
    let content = ''
    if (typeof msg.text === 'string') content = msg.text
    else if (Array.isArray(msg.text)) content = msg.text.map((p: any) => p?.type === 'text' ? p.text : '[Image]').join('')
    else content = '[Complex Content]'
    messages.push(`${role}: ${content}`)
    currentId = msg.parentMessageId
  }
  return messages.reverse().join('\n')
}

function formatSearchRoundsForPlanner(rounds: SearchRound[]): string {
  if (!rounds.length) return 'ï¼ˆæ— ï¼‰'
  return rounds.map((r, idx) => {
    const items = (r.items || []).map((it, i) =>
      `- [${idx + 1}.${i + 1}] ${String(it.title || '').trim()}\n  ${String(it.url || '').trim()}\n  å†…å®¹: ${String(it.content || '').replace(/\s+/g, ' ').trim()}`
    ).join('\n\n')
    const note = r.note ? `\nï¼ˆæ³¨ï¼š${r.note}ï¼‰` : ''
    return `### ç¬¬${idx + 1}è½® query="${r.query}"\n${items || 'ï¼ˆæ— ç»“æœï¼‰'}${note}`
  }).join('\n\n')
}

async function planNextSearchAction(params: {
  openai: OpenAI
  model: string
  userQuestion: string
  rounds: SearchRound[]
  fullContext: string
  priorContextSummary: string | null
  date: string
  abortSignal?: AbortSignal

  // NEW: dynamic timeout schedule
  timeoutScheduleMs?: number[] // default [10_000, 15_000, 20_000]
  onTimeoutRetry?: (info: { attempt: number; timeoutMs: number; nextAttempt: number; nextTimeoutMs: number }) => void
}): Promise<SearchPlan> {
  const {
    openai,
    model,
    userQuestion,
    rounds,
    fullContext,
    priorContextSummary,
    date,
    abortSignal,
    timeoutScheduleMs,
    onTimeoutRetry,
  } = params

  const isFirstRound = !priorContextSummary
  const plannerSystem = [
    'ä½ æ˜¯"è”ç½‘æœç´¢è§„åˆ’å™¨ & ç»“æœç­›é€‰å™¨"ã€‚ä½ çš„ä»»åŠ¡æ˜¯ååŠ©å›ç­”ç”¨æˆ·é—®é¢˜ã€‚',
    '',
    `å½“å‰æ—¶é—´ï¼š${date}`,
    '',
    'ä»»åŠ¡ï¼š',
    '1. é¦–å…ˆåˆ¤æ–­æ˜¯å¦éœ€è¦è”ç½‘æœç´¢ã€‚**è¿™æ˜¯æœ€é‡è¦çš„å†³ç­–ã€‚**',
    '2. è¯„ä¼°"å·²è¿›è¡Œçš„æœç´¢ä¸ç»“æœ"ï¼Œé€‰å‡ºå¯¹å›ç­”é—®é¢˜æœ‰ä»·å€¼çš„æ¡ç›®ID (æ ¼å¼å¦‚ "1.1", "2.3")ã€‚',
    '',
    'ã€å†³ç­–é€»è¾‘ã€‘',
    '- **å¿…é¡»æœç´¢**ï¼šé—®é¢˜æ¶‰åŠè¿‘æœŸæ–°é—»ã€ç‰¹å®šäº‹å®æŸ¥è¯ï¼ˆå¤©æ°”ã€è‚¡ä»·ç­‰ï¼‰ã€éå¸¸è¯†æ€§å…·ä½“æ•°æ®ï¼Œä¸”ä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ã€‚',
    '- **ç¦æ­¢æœç´¢ (action="stop")**ï¼š',
    '  - çº¯é—²èŠï¼ˆå¦‚â€œä½ å¥½â€ã€â€œä½ æ˜¯è°â€ï¼‰ã€‚',
    '  - å¸¸è¯†æ€§é—®é¢˜ï¼ˆå¦‚â€œå¤ªé˜³ä»å“ªå‡èµ·â€ã€â€œ1+1ç­‰äºå‡ â€ï¼‰ã€‚',
    '  - é€»è¾‘æ¨ç†ã€æ•°å­¦è®¡ç®—ã€ä»£ç ç¼–å†™ã€ç¿»è¯‘ã€æ¶¦è‰²ä»»åŠ¡ã€‚',
    '  - **ä¸Šä¸‹æ–‡å·²åŒ…å«ç­”æ¡ˆ**ï¼šç”¨æˆ·é—®é¢˜æ˜¯é’ˆå¯¹å†å²å¯¹è¯çš„è¿½é—®ï¼Œä¸”å†å²ä¿¡æ¯å·²è¶³å¤Ÿå›ç­”ã€‚',
    '',
    'å¦‚æœå†³å®šæœç´¢ï¼šaction="search"ï¼Œå¹¶ç»™å‡º queryã€‚',
    'å¦‚æœæ— éœ€æœç´¢æˆ–ä¿¡æ¯å·²è¶³ï¼šaction="stop"ï¼ˆæ­¤æ—¶ selected_ids ä¾ç„¶å¯ä»¥è¿”å›å·²æœ‰ç»“æœçš„IDï¼Œå¦‚æœæ²¡æœ‰ç»“æœåˆ™ä¸ºç©ºæ•°ç»„ï¼‰ã€‚',
    '',
    isFirstRound
      ? '3. è¯·åŠ¡å¿…é˜…è¯»å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªç²¾ç‚¼çš„"context_summary"ï¼ˆ100-200å­—ï¼‰ï¼Œæ¦‚æ‹¬å†å²å¯¹è¯çš„æ ¸å¿ƒæ„å›¾å’Œå…³é”®ä¿¡æ¯ï¼Œä»¥ä¾¿åç»­è½®æ¬¡ä½¿ç”¨ã€‚'
      : '3. å‚è€ƒæä¾›çš„ "context_summary" æ¥ç†è§£ç”¨æˆ·æ„å›¾ï¼ˆä¸å†æä¾›å®Œæ•´ä¸Šä¸‹æ–‡ï¼‰ã€‚',
    '',
    'è¾“å‡ºä¸¥æ ¼ JSONï¼š',
    '{',
    '  "action": "search" | "stop",',
    '  "query": string, // å¦‚æœ action=search',
    '  "reason": string,',
    '  "selected_ids": string[], // é€‰å‡ºçš„é«˜è´¨é‡ç»“æœIDåˆ—è¡¨ï¼Œä¾‹å¦‚ ["1.1", "2.1"]',
    isFirstRound ? '  "context_summary": string // å¯¹å†å²ä¸Šä¸‹æ–‡çš„ç²¾ç‚¼æ€»ç»“' : null,
    '}'.replace(/, null/g, ''),
  ].filter(Boolean).join('\n')

  const contextBlock = isFirstRound
    ? `ã€å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆè¯·æ€»ç»“ç”Ÿæˆ context_summaryï¼‰ã€‘\n${fullContext || 'ï¼ˆæ— ï¼‰'}`
    : `ã€å†å²ä¸Šä¸‹æ–‡æ€»ç»“ (context_summary)ã€‘\n${priorContextSummary}`

  const plannerUser = [
    'ã€ç”¨æˆ·é—®é¢˜ã€‘', userQuestion,
    '',
    contextBlock,
    '',
    'ã€å·²è¿›è¡Œçš„æœç´¢ä¸ç»“æœã€‘',
    formatSearchRoundsForPlanner(rounds),
    '',
    'ç°åœ¨è¯·å†³å®šï¼šselected_ids æ˜¯å“ªäº›ï¼Ÿæ˜¯å¦éœ€è¦ç»§ç»­æœç´¢ï¼Ÿ' + (isFirstRound ? ' è®°å¾—ç”Ÿæˆ context_summaryã€‚' : '')
  ].join('\n')

  const schedule = (timeoutScheduleMs && timeoutScheduleMs.length ? timeoutScheduleMs : [10_000, 15_000, 20_000])

  try {
    const resp = await openaiChatCreateWithTimeoutRetry<any>({
      openai,
      request: {
        model,
        temperature: 0,
        messages: [{ role: 'system', content: plannerSystem }, { role: 'user', content: plannerUser }],
        response_format: { type: 'json_object' } as any,
        stream: false
      } as any,
      timeoutsMs: schedule,
      parentSignal: abortSignal,
      onTimeoutRetry,
    })

    const obj = safeParseJsonFromText(resp.choices?.[0]?.message?.content ?? '')
    return obj ? obj as SearchPlan : { action: 'stop', reason: 'planner json parse failed' }
  } catch (e: any) {
    // å¦‚æœå·²ç»æ˜¯â€œè¶…æ—¶é‡è¯•åä»å¤±è´¥â€ï¼Œä¸è¦å†è·‘ fallbackï¼ˆé¿å…æ€»æ—¶é•¿ç¿»å€ï¼‰
    if (e?.code === 'PLANNER_TIMEOUT' || e instanceof PlannerTimeoutError) throw e

    const resp = await openaiChatCreateWithTimeoutRetry<any>({
      openai,
      request: {
        model,
        temperature: 0,
        messages: [{ role: 'system', content: plannerSystem }, { role: 'user', content: `${plannerUser}\n\nåªè¾“å‡º JSONï¼Œä¸è¦è¾“å‡ºå…¶å®ƒæ–‡æœ¬ã€‚` }],
        stream: false
      } as any,
      timeoutsMs: schedule,
      parentSignal: abortSignal,
      onTimeoutRetry,
    })

    const obj = safeParseJsonFromText(resp.choices?.[0]?.message?.content ?? '')
    return obj ? obj as SearchPlan : { action: 'stop', reason: 'planner json parse failed' }
  }
}

async function runIterativeWebSearch(params: {
  openai: OpenAI; plannerModels: string[]; userQuestion: string; maxRounds: number; maxResults: number
  abortSignal?: AbortSignal; provider?: 'searxng' | 'tavily'; searxngApiUrl?: string; tavilyApiKey?: string
  onProgress?: (status: string) => void
  fullContext: string; date: string

  // NEW:
  plannerTimeoutScheduleMs?: number[] // default [10_000, 15_000, 20_000]
}): Promise<{ rounds: SearchRound[]; selectedIds: Set<string> }> {
  const {
    openai,
    plannerModels,
    userQuestion,
    maxRounds,
    maxResults,
    abortSignal,
    provider,
    searxngApiUrl,
    tavilyApiKey,
    onProgress,
    fullContext,
    date,
    plannerTimeoutScheduleMs
  } = params

  const rounds: SearchRound[] = []
  const usedQueries = new Set<string>()
  const selectedIds = new Set<string>()

  let currentContextSummary: string | null = null

  const schedule = (plannerTimeoutScheduleMs && plannerTimeoutScheduleMs.length ? plannerTimeoutScheduleMs : [10_000, 15_000, 20_000])

  for (let i = 0; i < maxRounds; i++) {
    // ä¿®æ­£ï¼š2. ç¬¬äºŒè½®åŠä»¥åä¸å†è¾“å‡ºâ€œæ­£åœ¨è§„åˆ’â€ï¼Œé™é»˜å¤„ç†ï¼Œè®©ç”¨æˆ·åªçœ‹åˆ°ä¸Šä¸€è½®çš„â€œæ­£åœ¨åˆ¤æ–­â€
    if (i === 0) {
      onProgress?.(`â³ æ­£åœ¨åˆ†æç”¨æˆ·æ„å›¾ï¼Œè§„åˆ’æœç´¢ç­–ç•¥...`)
    }

    let plan: SearchPlan | null = null
    for (const m of plannerModels) {
      try {
        plan = await planNextSearchAction({
          openai,
          model: m,
          userQuestion,
          rounds,
          abortSignal,
          fullContext,
          priorContextSummary: currentContextSummary,
          date,
          timeoutScheduleMs: schedule,
          onTimeoutRetry: ({ attempt, timeoutMs, nextAttempt, nextTimeoutMs }) => {
            onProgress?.(
              `âš ï¸ è§„åˆ’å™¨ç¬¬ ${attempt} æ¬¡è¯·æ±‚è¶…æ—¶ï¼ˆ>${Math.round(timeoutMs / 1000)}sï¼‰ï¼Œ` +
              `æ­£åœ¨é‡è¯•ç¬¬ ${nextAttempt} æ¬¡ï¼ˆè¶…æ—¶=${Math.round(nextTimeoutMs / 1000)}sï¼‰...`
            )
          },
        })
        break
      } catch (e) {
        if (API_DEBUG) debugLog('[SearchPlanner] model failed:', m, (e as any)?.message ?? e)
      }
    }

    if (!plan) {
      onProgress?.('âŒ è§„åˆ’æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œæµç¨‹ç»“æŸã€‚')
      break
    }

    if (plan.context_summary && typeof plan.context_summary === 'string') currentContextSummary = plan.context_summary
    if (Array.isArray(plan.selected_ids)) plan.selected_ids.forEach(id => selectedIds.add(String(id).trim()))

    const reasonText = plan.reason ? `(ç†ç”±: ${plan.reason})` : ''

    if (plan.action !== 'search') {
      if (i === 0) onProgress?.(`ğŸ›‘ æ¨¡å‹åˆ¤æ–­æ— éœ€æœç´¢ ${reasonText}`)
      // ä¿®æ­£ï¼šç›´æ¥æ˜¾ç¤ºå®Œæ¯•ï¼Œä¸å¸¦ä»»ä½•â€œæ­£åœ¨æ‰§è¡Œâ€çš„åç¼€(ç”±onProgressLocalæ§åˆ¶)
      else onProgress?.(`âœ… ä¿¡æ¯æ”¶é›†å®Œæ¯• ${reasonText}`)
      break
    }

    const q = String(plan.query || '').trim()
    if (!q) break

    if (usedQueries.has(q)) {
      onProgress?.(`âš ï¸ å…³é”®è¯ã€Œ${q}ã€å·²ä½¿ç”¨è¿‡ï¼Œè·³è¿‡é‡å¤æœç´¢...`)
      break
    };
    usedQueries.add(q)

    onProgress?.(`ğŸ” æ­£åœ¨æœç´¢ï¼šã€Œ${q}ã€\n   ğŸ§  ${reasonText}`)

    try {
      const r = await webSearch(q, { maxResults, signal: abortSignal, provider, searxngApiUrl, tavilyApiKey })
      const items = (r.results || []).slice(0, maxResults).map(it => ({ title: String(it.title || ''), url: String(it.url || ''), content: String(it.content || '') }))
      rounds.push({ query: q, items });

      // ä¿®æ­£ï¼š1. ä¿®æ”¹æ–‡æ¡ˆï¼Œæç¤ºç”¨æˆ·ç³»ç»Ÿæ­£åœ¨æ€è€ƒä¸‹ä¸€æ­¥
      onProgress?.(`ğŸ“„ æœç´¢æˆåŠŸï¼Œè·å–åˆ° ${items.length} ä¸ªé¡µé¢ï¼Œæ­£åœ¨åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›ä¸€æ­¥æœç´¢...`)
    } catch (e: any) {
      const errMsg = e?.message ?? String(e)
      console.error(`[WebSearch][Round ${i + 1}] Search failed for query "${q}":`, errMsg)
      rounds.push({ query: q, items: [], note: errMsg })
      onProgress?.(`âŒ æœç´¢è¯·æ±‚å¤±è´¥ï¼š${errMsg}`)
      break
    }
  }

  // ä¿®æ­£ï¼š3. ç§»é™¤æœ«å°¾æ—¥å¿—ï¼Œè®© ChatReplyProcess çš„â€œæ­£åœ¨ç”Ÿæˆâ€ç›´æ¥è¡”æ¥
  return { rounds, selectedIds }
}

function formatAggregatedSearchForAnswer(rounds: SearchRound[]): string {
  if (!rounds.length) return ''
  let n = 0; const lines: string[] = []; const refLines: string[] = []
  lines.push('ã€è”ç½‘æœç´¢ç»“æœï¼ˆå·²ç­›é€‰ï¼‰ã€‘')
  rounds.forEach((r, idx) => {
    if (!r.items?.length) return
    lines.push(`ï¼ˆç›¸å…³æ¥æºï¼š${r.query}ï¼‰`)
    for (const it of r.items) {
      n++
      lines.push(`[${n}] ${String(it.title || '').trim()}`)
      lines.push(`URL: ${String(it.url || '').trim()}`)
      lines.push(`å†…å®¹: ${String(it.content || '').trim()}`)
      lines.push('')
      refLines.push(`[${n}] ${String(it.title || '').trim()} - ${String(it.url || '').trim()}`)
    }
  })
  if (n === 0) return ''

  lines.push('')
  lines.push('ã€å‚è€ƒæ¥æºåˆ—è¡¨ã€‘')
  lines.push(...refLines)
  lines.push('')
  lines.push('ã€å›ç­”è¦æ±‚ã€‘')
  lines.push('- åŸºäºä»¥ä¸Šæ¥æºå›ç­”ç”¨æˆ·é—®é¢˜ã€‚')
  lines.push('- å¼•ç”¨æ ¼å¼å¿…é¡»ä¸º markdown é“¾æ¥ï¼š[ç¼–å·](url)ï¼Œä¾‹å¦‚ [1](https://example.com)ã€‚')
  lines.push('- å¯ä»¥åŒæ—¶å¼•ç”¨å¤šä¸ªæ¥æºï¼Œç”¨é€—å·åˆ†éš”ï¼š[1](url1), [2](url2)ã€‚')
  lines.push('- åœ¨å›ç­”æœ«å°¾ï¼Œåˆ—å‡ºæ‰€æœ‰å¼•ç”¨è¿‡çš„å‚è€ƒæ¥æºï¼Œæ ¼å¼ï¼š')
  lines.push('  ## å‚è€ƒæ¥æº')
  lines.push('  - [æ ‡é¢˜](url)')
  lines.push('- è‹¥æ¥æºä¸è¶³ä»¥æ”¯æŒç»“è®ºï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚')
  return lines.join('\n')
}

function appendTextToMessageContent(content: MessageContent, appendix: string): MessageContent {
  if (!appendix?.trim()) return content
  if (typeof content === 'string') return `${content}\n\n${appendix}`
  if (Array.isArray(content)) {
    const idx = (content as any[]).findIndex(p => p?.type === 'text' && typeof p?.text === 'string')
    if (idx >= 0) { const arr = [...(content as any[])]; arr[idx] = { ...(arr[idx] || {}), text: `${arr[idx].text}\n\n${appendix}` }; return arr as any }
    return [{ type: 'text', text: appendix }, ...(content as any[])] as any
  }
  return content
}
// ===================== è”ç½‘æœç´¢ END =====================

const ErrorCodeMessage: Record<string, string> = { 401: 'æä¾›é”™è¯¯çš„APIå¯†é’¥', 403: 'æœåŠ¡å™¨æ‹’ç»è®¿é—®ï¼Œè¯·ç¨åå†è¯•', 502: 'é”™è¯¯çš„ç½‘å…³', 503: 'æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åå†è¯•', 504: 'ç½‘å…³è¶…æ—¶', 500: 'æœåŠ¡å™¨ç¹å¿™ï¼Œè¯·ç¨åå†è¯•' }

let auditService: TextAuditService
const _lockedKeys: { key: string; lockedTime: number }[] = []

const DATA_URL_IMAGE_CAPTURE_RE = /data:(image\/[a-zA-Z0-9.+-]+);base64,([A-Za-z0-9+/=]+)/g
const MARKDOWN_IMAGE_RE = /!$$[^$$]*]$\s*([^)]+?)\s*$/g
const UPLOADS_URL_RE = /(\/uploads\/[^)\s>"']+\.(?:png|jpe?g|webp|gif|bmp|heic))/gi
const HTML_IMAGE_RE = /<img[^>]*\ssrc=["']([^"']+)["'][^>]*>/gi
const DATA_URL_IMAGE_RE = /data:image\/[a-zA-Z0-9.+-]+;base64,[A-Za-z0-9+/=]+/g

async function replaceDataUrlImagesWithUploads(text: string): Promise<{ text: string; saved: Array<{ mime: string; filename: string; bytes: number }> }> {
  if (!text) return { text: '', saved: [] }; const saved: Array<{ mime: string; filename: string; bytes: number }> = []; let out = ''; let lastIndex = 0
  const matches = text.matchAll(DATA_URL_IMAGE_CAPTURE_RE)
  for (const m of matches) { const full = m[0]; const mime = m[1]; const base64 = m[2]; const idx = m.index ?? -1; if (idx < 0) continue; out += text.slice(lastIndex, idx); const buffer = Buffer.from(base64, 'base64'); const ext = mime.split('/')[1] || 'png'; const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`; const filePath = path.join(UPLOAD_DIR, filename); await fs.writeFile(filePath, buffer); saved.push({ mime, filename, bytes: buffer.length }); out += `/uploads/${filename}`; lastIndex = idx + full.length }
  out += text.slice(lastIndex); return { text: out, saved }
}

type SavedUpload = { mime: string; filename: string; bytes: number }
type DataUrlCache = Map<string, string>
function parseDataUrlImage(dataUrl: string): { mime: string; base64: string } | null { const m = /^data:(image\/[a-zA-Z0-9.+-]+);base64,([A-Za-z0-9+/=\s]+)$/.exec(dataUrl); if (!m) return null; return { mime: m[1] || 'image/png', base64: (m[2] || '').replace(/\s+/g, '') || null } as any }
function mimeToExt(mime: string): string { const t = (mime || '').toLowerCase(); if (t === 'image/jpeg' || t === 'image/jpg') return 'jpg'; if (t === 'image/png') return 'png'; if (t === 'image/webp') return 'webp'; if (t === 'image/gif') return 'gif'; if (t === 'image/bmp') return 'bmp'; if (t === 'image/heic') return 'heic'; return t.split('/')[1] || 'png' }
async function saveDataUrlImageToUploads(dataUrl: string, cache?: DataUrlCache): Promise<{ url: string; saved: SavedUpload } | null> { try { if (!dataUrl?.startsWith('data:image/')) return null; if (cache?.has(dataUrl)) { const url = cache.get(dataUrl)!; return { url, saved: { mime: 'image/*', filename: path.basename(url), bytes: 0 } } }; const parsed = parseDataUrlImage(dataUrl); if (!parsed) return null; await ensureUploadDir(); const buffer = Buffer.from(parsed.base64, 'base64'); const ext = mimeToExt(parsed.mime); const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`; const filePath = path.join(UPLOAD_DIR, filename); await fs.writeFile(filePath, buffer); const url = `/uploads/${filename}`; cache?.set(dataUrl, url); return { url, saved: { mime: parsed.mime, filename, bytes: buffer.length } } } catch (e) { globalThis.console.error('[saveDataUrlImageToUploads] failed:', e); return null } }
async function normalizeMessageContentDataUrlsToUploads(content: MessageContent, cache?: DataUrlCache): Promise<{ content: MessageContent; saved: SavedUpload[] }> { const savedAll: SavedUpload[] = []; if (typeof content === 'string') { const replaced = await replaceDataUrlImagesWithUploads(content); savedAll.push(...replaced.saved); return { content: replaced.text, saved: savedAll } }; if (Array.isArray(content)) { const newParts: any[] = []; for (const p of content as any[]) { if (p?.type === 'text' && typeof p.text === 'string') { const replaced = await replaceDataUrlImagesWithUploads(p.text); savedAll.push(...replaced.saved); newParts.push({ ...p, text: replaced.text }); continue }; if (p?.type === 'image_url' && typeof p.image_url?.url === 'string') { const u = p.image_url.url as string; if (u.startsWith('data:image/')) { const r = await saveDataUrlImageToUploads(u, cache); if (r?.url) { savedAll.push(r.saved); newParts.push({ ...p, image_url: { ...p.image_url, url: r.url } }); continue } }; newParts.push(p); continue }; newParts.push(p) }; return { content: newParts as any, saved: savedAll } }; return { content, saved: savedAll } }
async function normalizeUrlsDataUrlsToUploads(urls: string[], cache?: DataUrlCache): Promise<{ urls: string[]; saved: SavedUpload[] }> { const out: string[] = []; const savedAll: SavedUpload[] = []; for (const u of urls || []) { if (typeof u === 'string' && u.startsWith('data:image/')) { const r = await saveDataUrlImageToUploads(u, cache); if (r?.url) { out.push(r.url); savedAll.push(r.saved) } else { out.push(u) } } else { out.push(u) } }; return { urls: out, saved: savedAll } }
function shortUrlForLog(u: string): string { if (!u) return ''; if (u.startsWith('data:image/')) { return `dataUrl(${u.match(/^data:(image\/[a-zA-Z0-9.+-]+);base64,/)?.[1] ?? 'image/*'},len=${u.length})` }; return u.length > 200 ? `${u.slice(0, 200)}...(len=${u.length})` : u }
function extractImageUrlsFromText(text: string): { cleanedText: string; urls: string[] } { if (!text) return { cleanedText: '', urls: [] }; const urls: string[] = []; let cleaned = text; cleaned = cleaned.replace(MARKDOWN_IMAGE_RE, (_m, inside) => { const raw = String(inside ?? '').trim(); if (raw) { const url = raw.split(/\s+/)[0]?.replace(/^<|>$/g, '').trim(); if (url) urls.push(url) }; return '[Image]' }); cleaned = cleaned.replace(HTML_IMAGE_RE, (_m, url) => { if (url) urls.push(url); return '[Image]' }); const rawDataUrls = cleaned.match(DATA_URL_IMAGE_RE); if (rawDataUrls?.length) urls.push(...rawDataUrls); cleaned = cleaned.replace(DATA_URL_IMAGE_RE, '[Image]'); const uploadUrls = cleaned.match(UPLOADS_URL_RE); if (uploadUrls?.length) urls.push(...uploadUrls); cleaned = cleaned.replace(UPLOADS_URL_RE, '[Image]'); return { cleanedText: cleaned, urls } }
async function extractImageUrlsFromMessageContent(content: MessageContent): Promise<{ cleanedText: string; urls: string[] }> { const urls: string[] = []; let cleanedText = ''; if (typeof content === 'string') { const r = extractImageUrlsFromText(content); cleanedText = r.cleanedText; urls.push(...r.urls); if (!cleanedText?.trim() && urls.length) cleanedText = '[Image]'; return { cleanedText, urls } }; if (Array.isArray(content)) { for (const p of content as any[]) { if (p?.type === 'text' && p.text) { const r = extractImageUrlsFromText(p.text); if (r.cleanedText) cleanedText += (cleanedText ? '\n' : '') + r.cleanedText; if (r.urls.length) urls.push(...r.urls) } else if (p?.type === 'image_url' && p.image_url?.url) { urls.push(p.image_url.url); cleanedText += (cleanedText ? '\n' : '') + '[Image]' } }; if (!cleanedText?.trim() && urls.length) cleanedText = '[Image]'; return { cleanedText, urls } }; return { cleanedText: '', urls: [] } }
function dedupeUrlsPreserveOrder(urls: string[]): string[] { const seen = new Set<string>(); const out: string[] = []; for (const u of urls) { if (!u || seen.has(u)) continue; seen.add(u); out.push(u) }; return out }
async function imageUrlToGeminiInlinePart(urlStr: string): Promise<GeminiPart | null> { if (urlStr.startsWith('data:')) { const [header, base64Data] = urlStr.split(','); if (!header || !base64Data) return null; const mimeMatch = header.match(/:(.*?);/); return { inlineData: { mimeType: mimeMatch ? mimeMatch[1] : 'image/png', data: base64Data } } }; if (urlStr.includes('/uploads/')) { const fileData = await getFileBase64(path.basename(urlStr)); if (!fileData) return null; return { inlineData: { mimeType: fileData.mime, data: fileData.data } } }; return null }

type ImageBinding = { tag: string; source: 'current_user' | 'last_ai' | 'prev_user' | 'prev_ai'; url: string }
type HistoryMessageMeta = { role: 'user' | 'model'; cleanedText: string; urls: string[]; messageId: string }
function applyImageBindingsToCleanedText(cleanedText: string, urls: string[], bindings: ImageBinding[]): string { const map = new Map<string, string>(); for (const b of bindings) map.set(b.url, b.tag); let out = cleanedText || ''; for (const u of urls) { const tag = map.get(u); out = out.replace('[Image]', tag ? `[${tag}]` : '[Image]') }; if (!out.trim() && urls.length) out = urls.map(u => (map.get(u) ? `[${map.get(u)}]` : '[Image]')).join(' '); return out }
async function buildGeminiHistoryFromLastMessageId(params: { lastMessageId?: string; maxContextCount: number; forGeminiImageModel: boolean }): Promise<{ metas: HistoryMessageMeta[]; allUrls: string[] }> { const { lastMessageId: startId, maxContextCount, forGeminiImageModel } = params; const metasRev: HistoryMessageMeta[] = []; const urlsRev: string[] = []; let lastMessageId = startId; for (let i = 0; i < maxContextCount; i++) { if (!lastMessageId) break; const msg = await getMessageById(lastMessageId); if (!msg) break; const role = (msg.role === 'assistant' ? 'model' : 'user') as 'user' | 'model'; if (forGeminiImageModel) { const { cleanedText, urls } = await extractImageUrlsFromMessageContent(msg.text); if (urls.length) urlsRev.push(...urls); metasRev.push({ role, cleanedText: cleanedText?.trim() ? cleanedText : (urls.length ? '[Image]' : '[Empty]'), urls, messageId: msg.id }) } else { metasRev.push({ role, cleanedText: typeof msg.text === 'string' ? msg.text : '[Complex Content]', urls: [], messageId: msg.id }) }; lastMessageId = msg.parentMessageId }; return { metas: metasRev.reverse(), allUrls: dedupeUrlsPreserveOrder(urlsRev.reverse()) } }
function getLastNByRole(metas: HistoryMessageMeta[], role: 'user' | 'model', n: number): HistoryMessageMeta[] { const out: HistoryMessageMeta[] = []; for (let i = metas.length - 1; i >= 0; i--) { if (metas[i].role !== role) continue; out.push(metas[i]); if (out.length >= n) break }; return out }
function selectRecentTwoRoundsImages(metas: HistoryMessageMeta[], currentUrls: string[]): ImageBinding[] { const lastModels = getLastNByRole(metas, 'model', 2); const lastUsers = getLastNByRole(metas, 'user', 1); const groups = [{ source: 'current_user' as const, tagPrefix: 'U0', urls: currentUrls }, { source: 'last_ai' as const, tagPrefix: 'A0', urls: lastModels[0]?.urls ?? [] }, { source: 'prev_user' as const, tagPrefix: 'U1', urls: lastUsers[0]?.urls ?? [] }, { source: 'prev_ai' as const, tagPrefix: 'A1', urls: lastModels[1]?.urls ?? [] }]; const seen = new Set<string>(); const bindings: ImageBinding[] = []; for (const g of groups) { let idx = 0; for (const u of g.urls) { if (!u || seen.has(u)) continue; seen.add(u); idx += 1; bindings.push({ tag: `${g.tagPrefix}_${idx}`, source: g.source, url: u }) } }; return bindings }
const IMAGE_SOURCE_LABEL: Record<ImageBinding['source'], string> = { current_user: 'æœ¬æ¬¡ç”¨æˆ·æ¶ˆæ¯', last_ai: 'æœ€è¿‘ä¸€æ¡AIå›å¤', prev_user: 'ä¸Šä¸€æ¬¡ç”¨æˆ·æ¶ˆæ¯', prev_ai: 'å€’æ•°ç¬¬äºŒæ¡AIå›å¤' }

export async function initApi(key: KeyConfig, { model, messages, temperature, top_p, abortSignal, isImageModel }: any) {
  const config = await getCacheConfig()
  const OPENAI_API_BASE_URL = isNotEmptyString(key.baseUrl) ? key.baseUrl : config.apiBaseUrl
  const openai = new OpenAI({ baseURL: OPENAI_API_BASE_URL, apiKey: key.key, maxRetries: 0, timeout: config.timeoutMs })

  const modelConfig = MODEL_CONFIGS[model] || { supportTopP: true }
  const finalTemperature = modelConfig.defaultTemperature ?? temperature
  const shouldUseTopP = modelConfig.supportTopP

  // Note: messages ç°å·²ç”±å¤–éƒ¨ä¼ å…¥ï¼Œä¸å†åœ¨å‡½æ•°å†…æŸ¥è¯¢ DB

  const enableStream = !isImageModel
  const options: OpenAI.ChatCompletionCreateParams = {
    model,
    stream: enableStream,
    stream_options: enableStream ? { include_usage: true } : undefined,
    messages
  }
  options.temperature = finalTemperature
  if (shouldUseTopP) options.top_p = top_p

  try { const siteCfg = config.siteConfig; const reasoningModelsStr = siteCfg?.reasoningModels || ''; const reasoningEffort = siteCfg?.reasoningEffort || 'medium'; const reasoningModelList = reasoningModelsStr.split(/[,ï¼Œ]/).map(s => s.trim()).filter(Boolean); if (reasoningModelList.includes(model) && reasoningEffort && reasoningEffort !== 'none') (options as any).reasoning_effort = reasoningEffort } catch (e) { globalThis.console.error('[OpenAI] set reasoning_effort failed:', e) }

  if (API_DEBUG) { debugLog('====== [OpenAI Request Debug] ======'); debugLog('[baseURL]', OPENAI_API_BASE_URL); debugLog('[model]', model); debugLog('[messagesSummary]', safeJson(summarizeOpenAIMessages(messages))); debugLog('====== [OpenAI Request Debug End] ======') }
  return await openai.chat.completions.create(options, { signal: abortSignal })
}

type ProcessThread = { key: string; userId: string; roomId: number; abort: AbortController; messageId: string }
const processThreads: ProcessThread[] = []
const makeThreadKey = (userId: string, roomId: number) => `${userId}:${roomId}`

async function chatReplyProcess(options: RequestOptions): Promise<{ message: string; data: ChatResponse; status: string }> {
  const userId = options.user._id.toString(); const messageId = options.messageId; const roomId = options.room.roomId; const abort = new AbortController(); const customMessageId = generateMessageId(); const threadKey = makeThreadKey(userId, roomId)
  const existingIdx = processThreads.findIndex(t => t.key === threadKey); if (existingIdx > -1) { processThreads[existingIdx].abort.abort(); processThreads.splice(existingIdx, 1) }
  processThreads.push({ key: threadKey, userId, abort, messageId, roomId })

  await ensureUploadDir();
  const model = options.room.chatModel;
  const maxContextCount = options.user.advanced.maxContextCount ?? 20

  updateRoomChatModel(userId, options.room.roomId, model)

  const { message, uploadFileKeys, lastContext, process: processCb, systemMessage, temperature, top_p } = options
  processCb?.({ id: customMessageId, text: '', role: 'assistant', conversationId: lastContext?.conversationId, parentMessageId: lastContext?.parentMessageId, detail: undefined })

  let content: MessageContent = message; let fileContext = ''
  const globalConfig = await getCacheConfig(); const imageModelsStr = globalConfig.siteConfig.imageModels || ''; const imageModelList = imageModelsStr.split(/[,ï¼Œ]/).map(s => s.trim()).filter(Boolean)
  const isImage = imageModelList.some(m => model.includes(m)); const isGeminiImageModel = isImage && model.includes('gemini')

  // 1. å¤„ç†æ–‡ä»¶å†…å®¹åˆå¹¶
  if (uploadFileKeys && uploadFileKeys.length > 0) {
    const textFiles = uploadFileKeys.filter(k => isTextFile(k)); const imageFiles = uploadFileKeys.filter(k => isImageFile(k))
    if (textFiles.length > 0) { for (const fileKey of textFiles) { try { const filePath = path.join(UPLOAD_DIR, stripTypePrefix(fileKey)); await fs.access(filePath); const fileContent = await fs.readFile(filePath, 'utf-8'); fileContext += `\n\n--- File Start: ${stripTypePrefix(fileKey)} ---\n${fileContent}\n--- File End ---\n` } catch (e) { globalThis.console.error(`Error reading text file ${fileKey}`, e); fileContext += `\n\n[System Error: File ${fileKey} not found or unreadable]\n` } } }
    const finalMessage = message + (fileContext ? `\n\nAttached Files content:\n${fileContext}` : '')
    if (imageFiles.length > 0) { content = [{ type: 'text', text: finalMessage }]; for (const uploadFileKey of imageFiles) { content.push({ type: 'image_url', image_url: { url: await convertImageUrl(stripTypePrefix(uploadFileKey)) } }) } }
    else { content = finalMessage }
  }

  let searchProcessLog = ''
  const allowSearch = globalConfig.siteConfig?.webSearchEnabled === true
  const finalSearchMode = allowSearch && options.searchMode === true && !isImage

  // 2. å¦‚æœå¼€å¯è”ç½‘æœç´¢ï¼Œæ‰§è¡Œæœç´¢é€»è¾‘
  if (finalSearchMode) {
    try {
      // è®¡ç®—åˆæ­¥ Token ä»¥è·å– Planner Key
      const preContext = await loadContextMessages({ maxContextCount, lastMessageId: lastContext?.parentMessageId, systemMessage, content })
      const preTokens = estimateTokenCount(preContext)

      const plannerModelCfg = String(globalConfig.siteConfig?.webSearchPlannerModel ?? '').trim()
      const plannerModelEnv = String(process.env.WEB_SEARCH_PLANNER_MODEL ?? '').trim()
      const plannerModelName = plannerModelCfg || plannerModelEnv || model

      // è·å– Planner Key (ä¼ å…¥ tokenæ•°)
      let plannerKey = await getRandomApiKey(options.user, model, options.room.accountId, preTokens)

      if (!plannerKey) throw new Error('æ²¡æœ‰å¯¹åº”çš„ apikeys é…ç½® (Planner)')

      let actualPlannerModel = plannerModelName
      if (plannerModelName !== model) {
        // å¦‚æœ Planner æ¨¡å‹ä¸åŒï¼Œå°è¯•è·å–å…¶ä¸“ç”¨ Key
        const candidateKey = await getRandomApiKey(options.user, plannerModelName) // Planneré€šå¸¸ Token è¾ƒå°‘ï¼Œå¯ä¸ä¼  count
        if (candidateKey) {
          plannerKey = candidateKey
        } else {
          // fallback
          actualPlannerModel = model
        }
      }

      const PLANNER_BASE_URL = isNotEmptyString(plannerKey.baseUrl) ? plannerKey.baseUrl : globalConfig.apiBaseUrl
      const plannerOpenai = new OpenAI({ baseURL: PLANNER_BASE_URL, apiKey: plannerKey.key, maxRetries: 0, timeout: globalConfig.timeoutMs })

      const maxRounds = Math.max(1, Math.min(6, Number(globalConfig.siteConfig?.webSearchMaxRounds ?? process.env.WEB_SEARCH_MAX_ROUNDS ?? 3)))
      const maxResults = Math.max(1, Math.min(10, Number(globalConfig.siteConfig?.webSearchMaxResults ?? process.env.WEB_SEARCH_MAX_RESULTS ?? 5)))
      const plannerModels = [actualPlannerModel, model].filter((v, i, arr) => Boolean(v) && arr.indexOf(v) === i)
      const searchProvider = globalConfig.siteConfig?.webSearchProvider as any
      const searchSearxngUrl = String(globalConfig.siteConfig?.searxngApiUrl ?? '').trim() || undefined
      const searchTavilyKey = String(globalConfig.siteConfig?.tavilyApiKey ?? '').trim() || undefined

      const progressMessages: string[] = []
      const onProgressLocal = (status: string) => {
        progressMessages.push(status)
        const displayLog = progressMessages.join('\n')
        const isFinishing = status.includes('å®Œæ¯•') || status.includes('æ— éœ€');
        const suffix = isFinishing ? '\n\nâš¡ï¸ å‡†å¤‡ç”Ÿæˆ...' : '\n\nâ³ æ­£åœ¨æ‰§è¡Œ...'
        processCb?.({
          id: customMessageId, text: displayLog + suffix, role: 'assistant',
          conversationId: lastContext?.conversationId, parentMessageId: lastContext?.parentMessageId, detail: undefined,
        })
      }

      const historyContextStr = await buildConversationContext(lastContext?.parentMessageId, maxContextCount)
      const currentDate = new Date().toLocaleString()

      const plannerTimeoutScheduleMs =
        parseTimeoutScheduleToMs((globalConfig.siteConfig as any)?.webSearchPlannerTimeoutScheduleMs ?? process.env.WEB_SEARCH_PLANNER_TIMEOUT_SCHEDULE_MS)
        ?? [10_000, 15_000, 20_000]

      const { rounds, selectedIds } = await runIterativeWebSearch({
        openai: plannerOpenai, plannerModels, userQuestion: message, maxRounds, maxResults,
        abortSignal: abort.signal, provider: searchProvider, searxngApiUrl: searchSearxngUrl, tavilyApiKey: searchTavilyKey,
        onProgress: onProgressLocal,
        fullContext: historyContextStr, date: currentDate,
        plannerTimeoutScheduleMs,
      })

      if (progressMessages.length > 0) {
        searchProcessLog = progressMessages.join('\n') + '\n\n---\n\n'
      }

      const filteredRounds = rounds.map((r, rIdx) => ({
        query: r.query,
        note: r.note,
        items: r.items.filter((_, iIdx) => selectedIds.has(`${rIdx + 1}.${iIdx + 1}`))
      })).filter(r => r.items.length > 0 || r.note)

      const ctx = formatAggregatedSearchForAnswer(filteredRounds)

      let finalStatusMessage = 'âœ… èµ„æ–™æ•´ç†å®Œæ¯•ï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”...'
      if (!ctx && rounds.length > 0) finalStatusMessage = 'âš ï¸ æœªèƒ½ç­›é€‰å‡ºæœ‰æ•ˆå¼•ç”¨ï¼Œå°è¯•ç›´æ¥å›ç­”...'

      processCb?.({
        id: customMessageId,
        text: searchProcessLog + `âš¡ï¸ ${finalStatusMessage}\n(æ¨¡å‹æ­£åœ¨é˜…è¯» ${ctx.length > 5000 ? 'å¤§é‡' : ''}èµ„æ–™å¹¶æ„æ€æœ€ç»ˆå›ç­”ï¼Œè¯·ç¨å€™...)`,
        role: 'assistant',
        conversationId: lastContext?.conversationId,
        parentMessageId: lastContext?.parentMessageId,
        detail: undefined,
      })

      // æ›´æ–° context (è¿½åŠ å…¥ context)
      if (ctx) content = appendTextToMessageContent(content, ctx)

    } catch (e: any) {
      if (isAbortError(e, abort.signal)) throw e;
      globalThis.console.error('[WebSearch] failed:', e?.message ?? e);
      searchProcessLog += `\nâŒ è”ç½‘æœç´¢æ¨¡å—é‡åˆ°é—®é¢˜ï¼š${e?.message ?? 'æœªçŸ¥é”™è¯¯'}\n\n---\n\n`
      processCb?.({
        id: customMessageId, text: searchProcessLog + 'å°è¯•ä½¿ç”¨å·²æœ‰çŸ¥è¯†å›ç­”...', role: 'assistant',
        conversationId: lastContext?.conversationId, parentMessageId: lastContext?.parentMessageId, detail: undefined
      })
    }
  }

  // 3. å‡†å¤‡æœ€ç»ˆç”Ÿæˆ
  const finalMessages = await loadContextMessages({
    maxContextCount,
    lastMessageId: lastContext?.parentMessageId,
    systemMessage,
    content
  })

  // 4. è®¡ç®—æœ€ç»ˆ Input Token
  const finalTokenCount = estimateTokenCount(finalMessages)

  // 5. æ ¹æ® Token é€‰æ‹©ç”Ÿæˆçš„ Key
  const key = await getRandomApiKey(options.user, model, options.room.accountId, finalTokenCount)
  if (!key) {
    const idx = processThreads.findIndex(d => d.key === threadKey); if (idx > -1) processThreads.splice(idx, 1);
    throw new Error(`æ²¡æœ‰å¯¹åº”çš„ apikeys é…ç½® (Token: ${finalTokenCount})ï¼Œè¯·æ£€æŸ¥ Key å¤‡æ³¨é…ç½®ã€‚`)
  }

  try {
    if (isGeminiImageModel) {
      // Gemini é€»è¾‘ä½¿ç”¨æ–° Key
      const baseUrl = isNotEmptyString(key.baseUrl) ? key.baseUrl.replace(/\/+$/, '') : undefined; const dataUrlCache: DataUrlCache = new Map()
      const normalizedCurrent = await normalizeMessageContentDataUrlsToUploads(content, dataUrlCache); content = normalizedCurrent.content
      const { metas } = await buildGeminiHistoryFromLastMessageId({ lastMessageId: lastContext.parentMessageId, maxContextCount, forGeminiImageModel: true })
      const metasNormalized: HistoryMessageMeta[] = []; for (const m of metas) { const nu = await normalizeUrlsDataUrlsToUploads(m.urls || [], dataUrlCache); metasNormalized.push({ ...m, urls: nu.urls }) }
      const { cleanedText: currentCleanedText, urls: currentUrlsRaw } = await extractImageUrlsFromMessageContent(content); const currentUrlsNorm = await normalizeUrlsDataUrlsToUploads(currentUrlsRaw || [], dataUrlCache); const currentUrls = currentUrlsNorm.urls
      const bindings = selectRecentTwoRoundsImages(metasNormalized, currentUrls)
      const history = metasNormalized.map(m => ({ role: m.role, parts: [{ text: applyImageBindingsToCleanedText(m.cleanedText, m.urls, bindings) || '[Empty]' }] }))
      const userInstructionBase = (currentCleanedText && currentCleanedText.trim()) ? currentCleanedText.trim() : 'è¯·ç»§ç»­ç”Ÿæˆ/ä¿®æ”¹å›¾ç‰‡ã€‚'
      const labeledUserInstruction = applyImageBindingsToCleanedText(userInstructionBase, currentUrls, bindings)
      const inputParts: GeminiPart[] = []
      if (bindings.length) { inputParts.push({ text: `ã€æœ€è¿‘ä¸¤è½®å›¾ç‰‡æ˜ å°„è¡¨ã€‘\n${bindings.map(b => `${b.tag}=${IMAGE_SOURCE_LABEL[b.source]}(${shortUrlForLog(b.url)})`).join('\n')}\n` }) }
      for (const b of bindings) { inputParts.push({ text: `ã€${b.tag}ï½œ${IMAGE_SOURCE_LABEL[b.source]}ã€‘` }); const imgPart = await imageUrlToGeminiInlinePart(b.url); if (imgPart) inputParts.push(imgPart); else inputParts.push({ text: `ï¼ˆè¯¥å›¾ç‰‡æ— æ³•ä»¥å†…è”æ–¹å¼ä¸Šä¼ ï¼š${shortUrlForLog(b.url)}ï¼‰` }) }
      inputParts.push({ text: `ã€ç¼–è¾‘æŒ‡ä»¤ã€‘${labeledUserInstruction}` })
      const ai = new GoogleGenAI({ apiKey: key.key, ...(baseUrl ? { httpOptions: { baseUrl } } : {}) })
      const response = await abortablePromise(ai.models.generateContent({ model, contents: [...history, { role: 'user', parts: inputParts }], config: { responseModalities: ['TEXT', 'IMAGE'], imageConfig: { aspectRatio: '16:9', imageSize: '4K' }, ...(systemMessage ? { systemInstruction: systemMessage } as any : {}) } as any } as any), abort.signal)
      if (!response.candidates || response.candidates.length === 0) throw new Error('[Gemini] Empty candidates.')
      let text = searchProcessLog; // âœ… Keep log
      const parts = response.candidates?.[0]?.content?.parts ?? []
      for (const part of parts as any[]) { if (part?.text) { const replaced = await replaceDataUrlImagesWithUploads(part.text as string); text += replaced.text }; const inline = part?.inlineData; if (inline?.data) { const mime = inline.mimeType || 'image/png'; const buffer = Buffer.from(inline.data as string, 'base64'); const ext = mime.split('/')[1] || 'png'; const filename = `${Date.now()}-${Math.round(Math.random() * 1e9)}.${ext}`; await fs.writeFile(path.join(UPLOAD_DIR, filename), buffer); text += `${text ? '\n\n' : ''}![Generated Image](/uploads/${filename})` } }
      if (!text) text = '[Gemini] Success but no text/image parts returned.'
      processCb?.({ id: customMessageId, text, role: 'assistant', conversationId: lastContext.conversationId, parentMessageId: lastContext.parentMessageId, detail: undefined })
      return sendResponse({ type: 'Success', data: { object: 'chat.completion', choices: [{ message: { role: 'assistant', content: text }, finish_reason: 'stop', index: 0, logprobs: null }], created: Date.now(), conversationId: lastContext.conversationId, model, text, id: customMessageId, detail: {} } })
    }

    // â‘¡ OpenAI
    const api = await initApi(key, {
      model,
      messages: finalMessages,
      temperature,
      top_p,
      content: null, // content is already in messages
      abortSignal: abort.signal,
      systemMessage: null, // systemMessage is already in messages
      lastMessageId: null, // history is already in messages
      isImageModel: isImage
    })

    let text = searchProcessLog;
    let chatIdRes = customMessageId; let modelRes = ''; let usageRes: any
    if (isImage) {
      const response = api as any; const choice = response.choices[0]; let rawContent = choice.message?.content || ''; modelRes = response.model; usageRes = response.usage
      if (rawContent && !rawContent.startsWith('![') && (rawContent.startsWith('http') || rawContent.startsWith('data:image'))) text += `![Generated Image](${rawContent})`; else text += rawContent
      processCb?.({ id: customMessageId, text, role: choice.message.role || 'assistant', conversationId: lastContext.conversationId, parentMessageId: lastContext.parentMessageId, detail: { choices: [{ finish_reason: 'stop', index: 0, logprobs: null, message: choice.message }], created: response.created, id: response.id, model: response.model, object: 'chat.completion', usage: response.usage } as any })
    } else {
      for await (const chunk of api as AsyncIterable<OpenAI.ChatCompletionChunk>) {
        text += chunk.choices[0]?.delta.content ?? '';
        chatIdRes = customMessageId; modelRes = chunk.model; usageRes = usageRes || chunk.usage;
        processCb?.({ ...chunk, id: customMessageId, text, role: chunk.choices[0]?.delta.role || 'assistant', conversationId: lastContext.conversationId, parentMessageId: lastContext.parentMessageId })
      }
    }
    return sendResponse({ type: 'Success', data: { object: 'chat.completion', choices: [{ message: { role: 'assistant', content: text }, finish_reason: 'stop', index: 0, logprobs: null }], created: Date.now(), conversationId: lastContext.conversationId, model: modelRes, text, id: chatIdRes, detail: { usage: usageRes && { ...usageRes, estimated: false } } } })
  } catch (error: any) {
    if (isAbortError(error, abort.signal)) throw error
    const code = error.statusCode
    if (code === 429 && (error.message.includes('Too Many Requests') || error.message.includes('Rate limit'))) { if (options.tryCount++ < 3) { _lockedKeys.push({ key: key.key, lockedTime: Date.now() }); await new Promise(resolve => setTimeout(resolve, 2000)); const index = processThreads.findIndex(d => d.key === threadKey); if (index > -1) processThreads.splice(index, 1); return await chatReplyProcess(options) } }
    globalThis.console.error(error)
    if (Reflect.has(ErrorCodeMessage, code)) return sendResponse({ type: 'Fail', message: ErrorCodeMessage[code] })
    return sendResponse({ type: 'Fail', message: error.message ?? 'Please check the back-end console' })
  } finally { const index = processThreads.findIndex(d => d.key === threadKey); if (index > -1) processThreads.splice(index, 1) }
}

export function abortChatProcess(userId: string, roomId: number) {
  const key = makeThreadKey(userId, roomId); const index = processThreads.findIndex(d => d.key === key); if (index <= -1) return
  const messageId = processThreads[index].messageId; processThreads[index].abort.abort(); processThreads.splice(index, 1)
  if (API_DEBUG) { debugLog('====== [Abort Debug] ======'); debugLog('[userId]', userId, '[roomId]', roomId, '[messageId]', messageId); debugLog('====== [Abort Debug End] ======') }
  return messageId
}

export function initAuditService(audit: AuditConfig) { if (!audit || !audit.options || !audit.options.apiKey || !audit.options.apiSecret) return; const Service = textAuditServices[audit.provider]; auditService = new Service(audit.options) }

async function containsSensitiveWords(audit: AuditConfig, text: string): Promise<boolean> {
  if (audit.customizeEnabled && isNotEmptyString(audit.sensitiveWords)) { const textLower = text.toLowerCase(); if (audit.sensitiveWords.split('\n').filter(d => textLower.includes(d.trim().toLowerCase())).length > 0) return true }
  if (audit.enabled) { if (!auditService) initAuditService(audit); return await auditService.containsSensitiveWords(text) }
  return false
}

async function chatConfig() { const config = await getOriginConfig() as ModelConfig; return sendResponse<ModelConfig>({ type: 'Success', data: config }) }
async function getMessageById(id: string): Promise<ChatMessage | undefined> {
  const isPrompt = id.startsWith('prompt_')
  const chatInfo = await getChatByMessageId(isPrompt ? id.substring(7) : id)
  if (!chatInfo) return undefined
  const parentMessageId = isPrompt ? chatInfo.options.parentMessageId : `prompt_${id}`
  if (chatInfo.status !== Status.Normal) return parentMessageId ? getMessageById(parentMessageId) : undefined

  if (isPrompt) {
    let promptText = chatInfo.prompt
    const allFileKeys = chatInfo.images || []; const textFiles = allFileKeys.filter(k => isTextFile(k)); const imageFiles = allFileKeys.filter(k => isImageFile(k))
    if (textFiles.length > 0) { let fileContext = ''; for (const fileKey of textFiles) { try { const filePath = path.join(UPLOAD_DIR, stripTypePrefix(fileKey)); const fileContent = await fs.readFile(filePath, 'utf-8'); fileContext += `\n\n--- Context File: ${stripTypePrefix(fileKey)} ---\n${fileContent}\n--- End File ---\n` } catch { } }; promptText += (fileContext ? `\n\n[Attached Files History]:\n${fileContext}` : '') }
    if (promptText && typeof promptText === 'string') promptText = promptText.replace(DATA_URL_IMAGE_RE, '[Image Data Removed]')
    let content: MessageContent = promptText
    if (imageFiles.length > 0) { content = [{ type: 'text', text: promptText }]; for (const image of imageFiles) { content.push({ type: 'image_url', image_url: { url: await convertImageUrl(stripTypePrefix(image)) } }) } }
    if (API_DEBUG) { debugLog('------ [getMessageById Prompt Debug] ------'); debugLog('[id]', id, '[parent]', parentMessageId); debugLog('[promptTextLen]', typeof promptText === 'string' ? promptText.length : -1); debugLog('[promptTextPreview]', trunc(promptText)); debugLog('[imageFiles]', imageFiles); debugLog('[textFiles]', textFiles); debugLog('------------------------------------------') }
    return { id, conversationId: chatInfo.options.conversationId, parentMessageId, role: 'user', text: content }
  } else {
    let responseText = chatInfo.response || ''
    if (responseText && typeof responseText === 'string') responseText = responseText.replace(DATA_URL_IMAGE_RE, '[Image History]')
    if (API_DEBUG) { debugLog('------ [getMessageById Assistant Debug] ------'); debugLog('[id]', id, '[parent]', parentMessageId); debugLog('[responseLen]', typeof responseText === 'string' ? responseText.length : -1); debugLog('[responsePreview]', trunc(responseText)); debugLog('---------------------------------------------') }
    return { id, conversationId: chatInfo.options.conversationId, parentMessageId, role: 'assistant', text: responseText }
  }
}

async function randomKeyConfig(keys: KeyConfig[]): Promise<KeyConfig | null> {
  if (keys.length <= 0) return null
  _lockedKeys.filter(d => d.lockedTime <= Date.now() - 1000 * 20).forEach(d => _lockedKeys.splice(_lockedKeys.indexOf(d), 1))
  let unsedKeys = keys.filter(d => _lockedKeys.filter(l => d.key === l.key).length <= 0); const start = Date.now()
  while (unsedKeys.length <= 0) { if (Date.now() - start > 3000) break; await new Promise(resolve => setTimeout(resolve, 1000)); unsedKeys = keys.filter(d => _lockedKeys.filter(l => d.key === l.key).length <= 0) }
  if (unsedKeys.length <= 0) return null; return unsedKeys[Math.floor(Math.random() * unsedKeys.length)]
}

async function getRandomApiKey(user: UserInfo, chatModel: string, accountId?: string, tokenCount?: number): Promise<KeyConfig | undefined> {
  let keys = (await getCacheApiKeys()).filter(d => hasAnyRole(d.userRoles, user.roles)).filter(d => d.chatModels.includes(chatModel))
  if (accountId) keys = keys.filter(d => d.keyModel === 'ChatGPTUnofficialProxyAPI' && getAccountId(d.key) === accountId)

  if (tokenCount !== undefined && keys.length > 0) {
    keys = keys.filter(k => {
      const remark = k.remark || ''
      const maxMatch = remark.match(/MAX_TOKENS?[:=]\s*(\d+)/i)
      const minMatch = remark.match(/MIN_TOKENS?[:=]\s*(\d+)/i)

      let valid = true
      if (maxMatch) {
        const max = parseInt(maxMatch[1], 10)
        if (tokenCount > max) valid = false
      }
      if (minMatch) {
        const min = parseInt(minMatch[1], 10)
        if (tokenCount <= min) valid = false
      }
      return valid
    })
  }

  const picked = await randomKeyConfig(keys)
  if (API_DEBUG) { debugLog('====== [Key Pick Debug] ======'); debugLog('[chatModel]', chatModel, '[tokens]', tokenCount, '[accountId]', accountId ?? '(none)'); debugLog('[candidateKeyCount]', keys.length); debugLog('[picked]', picked ? { keyModel: picked.keyModel, baseUrl: picked.baseUrl, remark: picked.remark } : '(null)'); debugLog('====== [Key Pick Debug End] ======') }
  return picked ?? undefined
}

function getAccountId(accessToken: string): string { try { const jwt = jwt_decode(accessToken) as JWT; return jwt['https://api.openai.com/auth'].user_id } catch { return '' } }

export { chatReplyProcess, chatConfig, containsSensitiveWords }
